{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from string import punctuation\n",
    "custom = stop_words+list(punctuation)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Consumer_Complaints.csv\",encoding = 'ISO-8859-1')\n",
    "df.head()\n",
    "df = df.drop(['Unnamed: 18'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:\n",
      " (1025010, 18) \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025010 entries, 0 to 1025009\n",
      "Data columns (total 18 columns):\n",
      "Date received                   1025010 non-null object\n",
      "Product                         1025010 non-null object\n",
      "Sub-product                     789840 non-null object\n",
      "Issue                           1025010 non-null object\n",
      "Sub-issue                       528853 non-null object\n",
      "Consumer Complaint              277814 non-null object\n",
      "Company Public Response         318364 non-null object\n",
      "Company                         1025010 non-null object\n",
      "State                           1012650 non-null object\n",
      "ZIP code                        1008292 non-null object\n",
      "Tags                            141588 non-null object\n",
      "Consumer consent provided?      491911 non-null object\n",
      "Submitted via                   1025010 non-null object\n",
      "Date Sent to Company            1025010 non-null object\n",
      "Company Response to Consumer    1025007 non-null object\n",
      "Timely response?                1025010 non-null object\n",
      "Consumer disputed?              768554 non-null object\n",
      "Complaint ID                    1025010 non-null int64\n",
      "dtypes: int64(1), object(17)\n",
      "memory usage: 140.8+ MB\n",
      "Info:\n",
      " None \n",
      " \n",
      "\n",
      "Class counts:\n",
      "\n",
      " Mortgage                                                                        254165\n",
      "Debt collection                                                                 196212\n",
      "Credit reporting                                                                140433\n",
      "Credit reporting, credit repair services, or other personal consumer reports    110756\n",
      "Credit card                                                                      89191\n",
      "Bank account or service                                                          86206\n",
      "Student loan                                                                     42969\n",
      "Consumer Loan                                                                    31606\n",
      "Credit card or prepaid card                                                      22913\n",
      "Checking or savings account                                                      18982\n",
      "Money transfer, virtual currency, or money service                                5785\n",
      "Vehicle loan or lease                                                             5628\n",
      "Payday loan                                                                       5546\n",
      "Money transfers                                                                   5354\n",
      "Payday loan, title loan, or personal loan                                         4367\n",
      "Prepaid card                                                                      3819\n",
      "Other financial service                                                           1060\n",
      "Virtual currency                                                                    18\n",
      "Name: Product, dtype: int64 \n",
      "\n",
      "\n",
      "Null Values\n",
      "\n",
      " Date received                        0\n",
      "Product                              0\n",
      "Sub-product                     235170\n",
      "Issue                                0\n",
      "Sub-issue                       496157\n",
      "Consumer Complaint              747196\n",
      "Company Public Response         706646\n",
      "Company                              0\n",
      "State                            12360\n",
      "ZIP code                         16718\n",
      "Tags                            883422\n",
      "Consumer consent provided?      533099\n",
      "Submitted via                        0\n",
      "Date Sent to Company                 0\n",
      "Company Response to Consumer         3\n",
      "Timely response?                     0\n",
      "Consumer disputed?              256456\n",
      "Complaint ID                         0\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Columns:\n",
      " Index(['Date received', 'Product', 'Sub-product', 'Issue', 'Sub-issue',\n",
      "       'Consumer Complaint', 'Company Public Response', 'Company', 'State',\n",
      "       'ZIP code', 'Tags', 'Consumer consent provided?', 'Submitted via',\n",
      "       'Date Sent to Company', 'Company Response to Consumer',\n",
      "       'Timely response?', 'Consumer disputed?', 'Complaint ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Information\n",
    "\n",
    "print('Dataframe shape:\\n',df.shape,'\\n\\n')\n",
    "print('Info:\\n',df.info(),'\\n','\\n')\n",
    "print('Class counts:\\n\\n',df['Product'].value_counts(),'\\n\\n')\n",
    "print('Null Values\\n\\n',df.isnull().sum(),'\\n\\n')\n",
    "print('Columns:\\n',df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer function\n",
    "\n",
    "def my_tokenizer(s):\n",
    "    try:\n",
    "        s = s.lower() # downcase\n",
    "    except:\n",
    "        s = str(s).lower()\n",
    "    tokens = nltk.word_tokenize(s) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # remove short words, they're probably not useful\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [t for t in tokens if t not in custom] # remove stopwords\n",
    "    tokens = [t for t in tokens if not any(c.isdigit() for c in t)] # remove any digits, i.e. \"3rd edition\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(df1, column_1):    #column_1 - reviews/msgs/complaints, column_2 - class/sentiments/Products\n",
    "    \n",
    "    # Remove Null values\n",
    "    df1.dropna(inplace = True)\n",
    "    \n",
    "    # Convert to list and tokenize\n",
    "    text = df1[column_1].tolist()\n",
    "    cleaned_text = []\n",
    "    for x in text:\n",
    "        cleaned_text.append(my_tokenizer(x))\n",
    "\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Preprocessing(df, 'Consumer Complaint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scrapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Collecting beautifulsoup4\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/c8/a55eb6ea11cd7e5ac4bacdf92bac4693b90d3ba79268be16527555e186f0/beautifulsoup4-4.8.1-py3-none-any.whl (101kB)\n",
      "Collecting soupsieve>=1.2\n",
      "  Downloading https://files.pythonhosted.org/packages/81/94/03c0f04471fc245d08d0a99f7946ac228ca98da4fa75796c507f61e688c2/soupsieve-1.9.5-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-cp37-none-any.whl size=1278 sha256=db7a1f84e58ec47bd94250474078751239c5f6f197182b1214d73b8546a1b2ce\n",
      "  Stored in directory: C:\\Users\\Acer\\AppData\\Local\\pip\\Cache\\wheels\\a0\\b0\\b2\\4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.8.1 bs4-0.0.1 soupsieve-1.9.5\n",
      "Enter company name Natural language processing\n",
      "http://www.google.com/search?q=Natural+language+processing\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# !pip install bs4\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "query = input(\"Enter company name \")\n",
    "query = query.replace(\" \",\"+\")\n",
    "url = \"http://www.google.com/search?q=\"+str(query)\n",
    "print (url)\n",
    "req = urllib.request.Request(url, headers={'User-Agent' : \"Magic Browser\"})\n",
    "response = urllib.request.urlopen( req )\n",
    "html = response.read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "import re\n",
    "all_links=[]\n",
    "for link in soup.findAll('a'):\n",
    "    all_links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/?sa=X&ved=0ahUKEwjN37TZ8e3lAhWMo48KHXT0DS0QOwgC'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(all_links))\n",
    "all_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/url?q=https://en.wikipedia.org/wiki/Natural_language_processing&sa=U&ved=2ahUKEwjN37TZ8e3lAhWMo48KHXT0DS0QFnoECAsQBA&usg=AOvVaw0I9ylWLOMIzDgh_2y6RCrh'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_links = []\n",
    "for x in all_links:\n",
    "    if x.startswith(\"/url\"):\n",
    "        imp_links.append(x)\n",
    "print(len(imp_links))\n",
    "imp_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://google.com/url?q=https://en.wikipedia.org/wiki/Natural_language_processing&sa=U&ved=2ahUKEwjN37TZ8e3lAhWMo48KHXT0DS0QFnoECAsQBA&usg=AOvVaw0I9ylWLOMIzDgh_2y6RCrh'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_links = []\n",
    "for x in imp_links:\n",
    "    final_links.append(\"https://google.com\"+x)\n",
    "print(len(final_links))\n",
    "final_links[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[]\n",
    "for i in range(len(final_links)):\n",
    "    req = urllib.request.Request(final_links[i],headers = {'User-Agent' : 'Magic Browser'})\n",
    "    response = urllib.request.urlopen(req)\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    for j in range(len(soup.find_all('p'))):\n",
    "        text.append(soup.find_all('p')[j].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "697"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\\n',\n",
       " 'Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\\n',\n",
       " 'The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods.\\nIn 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence[clarification needed].\\n',\n",
       " 'The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.[2]  However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.  Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\\n',\n",
       " 'Some notably successful natural language processing systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 and 1966.  Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\".\\n',\n",
       " 'During the 1970s, many programmers began to write \"conceptual ontologies\", which structured real-world information into computer-understandable data.  Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).  During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky.\\n',\n",
       " \"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[3] Some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.  However, part-of-speech tagging introduced the use of hidden Markov models to natural language processing, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models.  Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.\\n\",\n",
       " 'Many of the notable early successes occurred in the field of machine translation, due especially to work at IBM Research, where successively more complicated statistical models were developed.  These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.  However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\\n',\n",
       " 'Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.  Such algorithms are able to learn from data that has not been hand-annotated with the desired answers, or using a combination of annotated and non-annotated data.  Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data.  However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the inferior results if the algorithm used has a low enough time complexity to be practical.\\n',\n",
       " 'In the 2010s, representation learning and deep neural network-style machine learning methods became widespread in natural language processing, due in part to a flurry of results showing that such techniques[4][5] can achieve state-of-the-art results in many natural language tasks, for example in language modeling,[6]\\nparsing,[7][8] and many others. Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that were used in statistical machine translation (SMT).\\n',\n",
       " 'In the early days, many language-processing systems were designed by hand-coding a set of rules:[9][10] such as by writing grammars or devising heuristic rules for stemming. \\n',\n",
       " 'Since the so-called \"statistical revolution\"[11][12] in the late 1980s and mid 1990s, much natural language processing research has relied heavily on machine learning. The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus, is a set of documents, possibly with human or computer annotations) of typical real-world examples.\\n',\n",
       " 'Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks. These algorithms take as input a large set of \"features\" that are generated from the input data. Some of the earliest-used algorithms, such as decision trees, produced systems of hard if-then rules similar to the systems of handwritten rules that were then common. Increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature. Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.\\n',\n",
       " 'Systems based on machine-learning algorithms have many advantages over handproduced rules:\\n',\n",
       " 'The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\n',\n",
       " 'Though natural language processing tasks are closely intertwined, they are frequently subdivided into categories for convenience. A coarse division is given below.\\n',\n",
       " 'The first published work by an artificial intelligence was published in 2018, 1 the Road, marketed as a novel, contains sixty million words.\\n',\n",
       " 'Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\\n',\n",
       " 'Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\\n',\n",
       " 'The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods.\\nIn 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence[clarification needed].\\n',\n",
       " 'The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.[2]  However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.  Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\\n',\n",
       " 'Some notably successful natural language processing systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 and 1966.  Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\".\\n',\n",
       " 'During the 1970s, many programmers began to write \"conceptual ontologies\", which structured real-world information into computer-understandable data.  Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).  During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky.\\n',\n",
       " \"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[3] Some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.  However, part-of-speech tagging introduced the use of hidden Markov models to natural language processing, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models.  Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.\\n\",\n",
       " 'Many of the notable early successes occurred in the field of machine translation, due especially to work at IBM Research, where successively more complicated statistical models were developed.  These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.  However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\\n',\n",
       " 'Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.  Such algorithms are able to learn from data that has not been hand-annotated with the desired answers, or using a combination of annotated and non-annotated data.  Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data.  However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the inferior results if the algorithm used has a low enough time complexity to be practical.\\n',\n",
       " 'In the 2010s, representation learning and deep neural network-style machine learning methods became widespread in natural language processing, due in part to a flurry of results showing that such techniques[4][5] can achieve state-of-the-art results in many natural language tasks, for example in language modeling,[6]\\nparsing,[7][8] and many others. Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that were used in statistical machine translation (SMT).\\n',\n",
       " 'In the early days, many language-processing systems were designed by hand-coding a set of rules:[9][10] such as by writing grammars or devising heuristic rules for stemming. \\n',\n",
       " 'Since the so-called \"statistical revolution\"[11][12] in the late 1980s and mid 1990s, much natural language processing research has relied heavily on machine learning. The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus, is a set of documents, possibly with human or computer annotations) of typical real-world examples.\\n',\n",
       " 'Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks. These algorithms take as input a large set of \"features\" that are generated from the input data. Some of the earliest-used algorithms, such as decision trees, produced systems of hard if-then rules similar to the systems of handwritten rules that were then common. Increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature. Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.\\n',\n",
       " 'Systems based on machine-learning algorithms have many advantages over handproduced rules:\\n',\n",
       " 'The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\n',\n",
       " 'Though natural language processing tasks are closely intertwined, they are frequently subdivided into categories for convenience. A coarse division is given below.\\n',\n",
       " 'The first published work by an artificial intelligence was published in 2018, 1 the Road, marketed as a novel, contains sixty million words.\\n',\n",
       " 'Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\\n',\n",
       " 'Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\\n',\n",
       " 'The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods.\\nIn 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence[clarification needed].\\n',\n",
       " 'The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.[2]  However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.  Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\\n',\n",
       " 'Some notably successful natural language processing systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 and 1966.  Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\".\\n',\n",
       " 'During the 1970s, many programmers began to write \"conceptual ontologies\", which structured real-world information into computer-understandable data.  Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).  During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky.\\n',\n",
       " \"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[3] Some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.  However, part-of-speech tagging introduced the use of hidden Markov models to natural language processing, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models.  Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.\\n\",\n",
       " 'Many of the notable early successes occurred in the field of machine translation, due especially to work at IBM Research, where successively more complicated statistical models were developed.  These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.  However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\\n',\n",
       " 'Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.  Such algorithms are able to learn from data that has not been hand-annotated with the desired answers, or using a combination of annotated and non-annotated data.  Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data.  However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the inferior results if the algorithm used has a low enough time complexity to be practical.\\n',\n",
       " 'In the 2010s, representation learning and deep neural network-style machine learning methods became widespread in natural language processing, due in part to a flurry of results showing that such techniques[4][5] can achieve state-of-the-art results in many natural language tasks, for example in language modeling,[6]\\nparsing,[7][8] and many others. Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that were used in statistical machine translation (SMT).\\n',\n",
       " 'In the early days, many language-processing systems were designed by hand-coding a set of rules:[9][10] such as by writing grammars or devising heuristic rules for stemming. \\n',\n",
       " 'Since the so-called \"statistical revolution\"[11][12] in the late 1980s and mid 1990s, much natural language processing research has relied heavily on machine learning. The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus, is a set of documents, possibly with human or computer annotations) of typical real-world examples.\\n',\n",
       " 'Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks. These algorithms take as input a large set of \"features\" that are generated from the input data. Some of the earliest-used algorithms, such as decision trees, produced systems of hard if-then rules similar to the systems of handwritten rules that were then common. Increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature. Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.\\n',\n",
       " 'Systems based on machine-learning algorithms have many advantages over handproduced rules:\\n',\n",
       " 'The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\n',\n",
       " 'Though natural language processing tasks are closely intertwined, they are frequently subdivided into categories for convenience. A coarse division is given below.\\n',\n",
       " 'The first published work by an artificial intelligence was published in 2018, 1 the Road, marketed as a novel, contains sixty million words.\\n',\n",
       " 'Natural-language understanding (NLU) or natural-language interpretation (NLI)[1] is a subtopic  of natural-language processing in artificial intelligence that deals with machine reading comprehension. Natural-language understanding is considered an AI-hard problem.[2]\\n',\n",
       " 'There is considerable commercial interest in the field because of its application to automated reasoning,[3] machine translation,[4] question answering,[5] news-gathering, text categorization, voice-activation, archiving, and large-scale content analysis.\\n',\n",
       " 'NLU is the post-processing of text, after the use of NLP algorithms (identifying parts-of-speech, etc.), that utilizes context from recognition devices (automatic speech recognition [ASR], vision recognition, last conversation, misrecognized words from ASR, personalized profiles, microphone proximity etc.), in all of its forms, to discern meaning of fragmented and run-on sentences to execute an intent from typically voice commands.  NLU has an ontology around the particular product vertical that is used to figure out the probability of some intent.  An NLU has a defined list of known intents that derives the message payload from designated contextual information recognition sources.  The NLU will provide back multiple message outputs to separate services (software) or resources (hardware) from a single derived intent (response to voice command initiator with visual sentence (shown or spoken) and transformed voice command message to different output messages to be consumed for M2M communications and actions).[citation needed]\\n',\n",
       " \"The program STUDENT, written in 1964 by Daniel Bobrow for his PhD dissertation at MIT is one of the earliest known attempts at natural-language understanding by a computer.[6][7][8][9][10]  Eight years after John McCarthy coined the term artificial intelligence, Bobrow's dissertation (titled Natural Language Input for a Computer Problem Solving System) showed how a computer could understand simple natural language input to solve algebra word problems.\\n\",\n",
       " 'A year later, in 1965, Joseph Weizenbaum at MIT wrote ELIZA, an interactive program that carried on a dialogue in English on any topic, the most popular being psychotherapy. ELIZA worked by simple parsing and substitution of key words into canned phrases and Weizenbaum sidestepped the problem of giving the program a database of real-world knowledge or a rich lexicon. Yet ELIZA gained surprising popularity as a toy project and can be seen as a very early precursor to current commercial systems such as those used by Ask.com.[11]\\n',\n",
       " \"In 1969 Roger Schank at Stanford University introduced the conceptual dependency theory for natural-language understanding.[12] This model, partially influenced by the work of Sydney Lamb, was extensively used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert, and Janet Kolodner.\\n\",\n",
       " 'In 1970, William A. Woods introduced the augmented transition network (ATN) to represent natural language input.[13] Instead of phrase structure rules ATNs used an equivalent set of finite state automata that were called recursively. ATNs and their more general format called \"generalized ATNs\" continued to be used for a number of years.\\n',\n",
       " \"In 1971 Terry Winograd finished writing SHRDLU for his PhD thesis at MIT. SHRDLU could understand simple English sentences in a restricted world of children's blocks to direct a robotic arm to move items. The successful demonstration of SHRDLU provided significant momentum for continued research in the field.[14][15] Winograd continued to be a major influence in the field with the publication of his book Language as a Cognitive Process.[16] At Stanford, Winograd would later be the adviser for Larry Page, who co-founded Google.\\n\",\n",
       " 'In the 1970s and 1980s the natural language processing group at SRI International continued research and development in the field. A number of commercial efforts based on the research were undertaken, e.g., in 1982 Gary Hendrix formed Symantec Corporation originally as a company for developing a natural language interface for database queries on personal computers. However, with the advent of mouse driven, graphic user interfaces Symantec changed direction. A number of other commercial efforts were started around the same time, e.g., Larry R. Harris at the Artificial Intelligence Corporation and Roger Schank and his students at Cognitive Systems corp.[17][18] In 1983, Michael Dyer developed the BORIS system at Yale which bore similarities to the work of Roger Schank and W. G. Lehnert.[19]\\n',\n",
       " 'The third millennium saw the introduction of systems using machine learning for text classification, such as the IBM Watson. However, it is debated how much \"understanding\" such systems demonstrate, e.g. according to John Searle, Watson did not even understand the questions.[20]\\n',\n",
       " 'John Ball, cognitive scientist and inventor of Patom Theory supports this assessment. Natural language processing has made inroads for applications to support human productivity in service and ecommerce but this has largely been made possible by narrowing the scope of the application. There are thousands of ways to request something in a human language which still defies conventional natural language processing. \"To have a meaningful conversation with machines is only possible when we match every word to the correct meaning based on the meanings of the other words in the sentence – just like a 3-year-old does without guesswork\" Patom Theory\\n',\n",
       " 'The umbrella term \"natural-language understanding\" can be applied to a diverse set of computer applications, ranging from small, relatively simple tasks such as short commands issued to robots, to highly complex endeavors such as the full comprehension of newspaper articles or poetry passages. Many real world applications fall between the two extremes, for instance text classification for the automatic analysis of emails and their routing to a suitable department in a corporation does not require in depth understanding of the text,[21] but needs to deal with a much larger vocabulary and more diverse syntax than the management of simple queries to database tables with fixed schemata.\\n',\n",
       " 'Throughout the years various attempts at processing natural language or English-like sentences presented to computers have taken place at varying degrees of complexity. Some attempts have not resulted in systems with deep understanding, but have helped overall system usability. For example, Wayne Ratliff originally developed the Vulcan program with an English-like syntax to mimic the English speaking computer in Star Trek. Vulcan later became the dBase system whose easy-to-use syntax effectively launched the personal computer database industry.[22][23] Systems with an easy to use or English like syntax are, however, quite distinct from systems that use a rich lexicon and include an internal representation (often as first order logic) of the semantics of natural language sentences.\\n',\n",
       " 'Hence the breadth and depth of \"understanding\" aimed at by a system determine both the complexity of the system (and the implied challenges) and the types of applications it can deal with.  The \"breadth\" of a system is measured by the sizes of its vocabulary and grammar.  The \"depth\" is measured by the degree to which its understanding approximates that of a fluent native speaker.  At the narrowest and shallowest, English-like command interpreters require minimal complexity, but have a small range of applications.  Narrow but deep systems explore and model mechanisms of understanding,[24] but they still have limited application.  Systems that attempt to understand the contents of a document such as a news release beyond simple keyword matching and to judge its suitability for a user are broader and require significant complexity,[25] but they are still somewhat shallow.  Systems that are both very broad and very deep are beyond the current state of the art.\\n',\n",
       " 'Regardless of the approach used, most natural-language-understanding systems share some common components. The system needs a lexicon of the language and a parser and grammar rules to break sentences into an internal representation. The construction of a rich lexicon with a suitable ontology requires significant effort, e.g., the Wordnet lexicon required many person-years of effort.[26]\\n',\n",
       " 'The system also needs theory from semantics to guide the comprehension. The interpretation capabilities of a language-understanding system depend on the semantic theory it uses. Competing semantic theories of language have specific trade-offs in their suitability as the basis of computer-automated semantic interpretation.[27] These range from naive semantics or stochastic semantic analysis to the use of pragmatics to derive meaning from context.[28][29][30] Semantic parsers convert natural-language texts into formal meaning representations.[31]\\n',\n",
       " 'Advanced applications of natural-language understanding also attempt to incorporate logical inference within their framework. This is generally achieved by mapping the derived meaning into a set of assertions in predicate logic, then using logical deduction to arrive at conclusions. Therefore, systems based on functional languages such as Lisp need to include a subsystem to represent logical assertions, while logic-oriented systems such as those using the language Prolog generally rely on an extension of the built-in logical representation framework.[32][33]\\n',\n",
       " 'The management of context in natural-language understanding can present special challenges. A large variety of examples and counter examples have resulted in multiple approaches to the formal modeling of context, each with specific strengths and weaknesses.[34][35]\\n',\n",
       " 'Natural-language generation (NLG) is a software process that transforms structured data into natural language.  It can be used to produce long form content for organizations to automate custom reports, as well as produce custom content for a web or mobile application. It can also be used to generate short blurbs of text in interactive conversations (a chatbot) which might even be read out  by a text-to-speech system.\\n',\n",
       " 'Automated NLG can be compared to the process humans use when they turn ideas into writing or speech. Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research.  NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging.\\n',\n",
       " 'NLG may be viewed as the opposite of natural-language understanding: whereas in natural-language understanding, the system needs to disambiguate the input sentence to produce the machine representation language, in NLG the system needs to make decisions about how to put a concept into words.  The practical considerations in building NLU vs. NLG systems are not symmetrical.  NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed.[1]\\n',\n",
       " 'NLG has existed for a long time[when?] but commercial NLG technology has only recently[when?] become widely available. NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar.  NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts.[2]\\n',\n",
       " 'The Pollen Forecast for Scotland system[3] is a simple example of a simple NLG system that could essentially be a template.  This system takes as input six numbers, which give predicted pollen levels in different parts of Scotland.  From these numbers, the system generates a short textual summary of pollen levels as its output.\\n',\n",
       " 'For example, using the historical data for July 1, 2005, the software produces:\\n',\n",
       " 'Grass pollen levels for Friday have increased from the moderate to high levels of yesterday with values of around 6 to 7 across most parts of the country. However, in Northern areas, pollen levels will be moderate with values of 4.\\n',\n",
       " 'In contrast, the actual forecast (written by a human meteorologist) from this data was:\\n',\n",
       " 'Pollen counts are expected to remain high at level 6 over most of Scotland, and even level 7 in the south east. The only relief is in the Northern Isles and far northeast of mainland Scotland with medium levels of pollen count.\\n',\n",
       " 'Comparing these two illustrates some of the choices that NLG systems must make; these are further discussed below.\\n',\n",
       " 'The process to generate text can be as simple as keeping a list of canned text that is copied and pasted, possibly linked with some glue text. The results may be satisfactory in simple domains such as horoscope machines or generators of personalised business letters. However, a sophisticated NLG system needs to include stages of planning and merging of information to enable the generation of text that looks natural and does not become repetitive. The typical stages of natural-language generation, as proposed by Dale and Reiter,[1] are:\\n',\n",
       " 'Content determination: Deciding what information to mention in the text.\\nFor instance, in the pollen example above, deciding whether to explicitly mention that pollen\\nlevel is 7 in the south east.\\n',\n",
       " 'Document structuring: Overall organisation of the information to convey.  For example, deciding to\\ndescribe the areas with high pollen levels first, instead of the areas with low pollen levels.\\n',\n",
       " 'Aggregation: Merging of similar sentences to improve readability and naturalness.\\nFor instance, merging the two following sentences:\\n',\n",
       " 'into the following single sentence:\\n',\n",
       " 'Lexical choice: Putting words to the concepts.  For example, deciding whether medium or moderate\\nshould be used when describing a pollen level of 4.\\n',\n",
       " 'Referring expression generation: Creating referring expressions that identify objects and regions.  For example, deciding to use\\nin the Northern Isles and far northeast of mainland Scotland to refer to a certain region in Scotland.\\nThis task also includes making decisions about pronouns and other types of\\nanaphora.\\n',\n",
       " 'Realization: Creating the actual text, which should be correct\\naccording to the rules of\\nsyntax, morphology, and orthography.  For example, using will be for the future\\ntense of to be.\\n',\n",
       " 'An alternative approach to NLG is to use \"end-to-end\" machine learning to build a system, without having separate stages as above.[4]   In other words, we build an NLG system by training a machine learning algorithm (often an LSTM) on a large data set of input data and corresponding (human-written) output texts.  The end-to-end approach has perhaps been most successful in image captioning,[5] that is automatically generating a textual caption for an image.\\n',\n",
       " \"The popular media has paid the most attention to NLG systems which generate jokes (see computational humor), but from a commercial perspective, the most successful NLG applications\\nhave been data-to-text systems which generate textual summaries of databases and data sets; these\\nsystems usually perform data analysis as well as text generation. Research has shown that textual summaries can be more effective than graphs and other visuals for decision support,[6][7][8] and that computer-generated texts can be superior (from the reader's perspective) to human-written texts.[9]\\n\",\n",
       " \"The first commercial data-to-text systems produced weather forecasts from weather data. The earliest such system to be\\ndeployed was FoG,[10] which was used by Environment Canada to generate weather forecasts in French and English in the early 1990s.  The success of FoG triggered other work, both research and commercial.\\nRecent applications include the UK Met Office's text-enhanced forecast.[11]\\n\",\n",
       " 'Currently there is considerable commercial interest in using NLG to summarise financial and business data.  Indeed, Gartner has said that NLG will become a standard feature of 90% of modern BI and analytics platforms.[12]  NLG is also being used commercially in automated journalism, chatbots, generating product descriptions for e-commerce sites, summarising medical records,[13][14] and enhancing accessibility (for example by describing graphs and data sets to blind people[15]).\\n',\n",
       " 'An example of an interactive use of NLG is the WYSIWYM framework. It stands for What you see is what you meant and allows users to see and manipulate the continuously rendered view (NLG output) of an underlying formal language document (NLG input), thereby editing the formal language without learning it.\\n',\n",
       " 'Content generation systems assist human writers and makes writing process more efficient and effective. A content generation tool based on web mining using search engines APIs has been built.[16] The tool imitates the cut-and-paste writing scenario where a writer forms its content from various search results. Relevance verification is essential to filter out irrelevant search results; it is based on matching the parse tree of a query with the parse trees of candidate answers.[17] In an alternative approach, a high-level structure of human-authored text is used to automatically build a template for a new topic for automatically written Wikipedia article.[18]\\n',\n",
       " 'Several companies have been started since 2009 which build systems that transform data into narrative using NLG and AI techniques.  These include Narrative Science, Phrasetech, Arria NLG, Automated Insights, Retresco, Visual NLG, Yseop and United Robots. Open-source NLG solutions exist as well, for instance RosaeNLG and SimpleNLG.\\n',\n",
       " 'As in other scientific fields, NLG researchers need to test how well their systems, modules, and algorithms work.  This is called evaluation. There are three basic techniques for evaluating NLG systems:\\n',\n",
       " 'An ultimate goal is how useful NLG systems are at helping people, which is the first of the above techniques. However, task-based evaluations are time-consuming and expensive, and can be difficult to carry out (especially if they require subjects with specialised expertise, such as doctors).  Hence (as in other areas of NLP) task-based evaluations are the exception, not the norm.\\n',\n",
       " 'Recently researchers are assessing how well human-ratings and metrics correlate with (predict) task-based evaluations.  Work is being conducted in the context of Generation Challenges[19] shared-task events.  Initial results suggest that human ratings are much better than metrics in this regard.  In other words, human ratings usually do predict task-effectiveness at least to some degree (although there are exceptions), while ratings produced by metrics often do not predict task-effectiveness well.  These results are preliminary.  In any case, human ratings are the most popular evaluation technique in NLG; this is contrast to machine translation, where metrics are widely used.\\n',\n",
       " \"1 the Road is an experimental novel composed by artificial intelligence (AI). Emulating Jack Kerouac's On the Road, Ross Goodwin drove from New York to New Orleans in March 2017 with an AI in a laptop hooked up to various sensors, whose output the AI turned into words that were printed on rolls of receipt paper. The novel was published in 2018 by Jean Boîte Éditions.\\n\",\n",
       " 'Goodwin left the text unedited. Although he felt the prose was \"choppy\", and contained typographical errors, he wanted to present the machine-generated text verbatim, for future study. The story begins: \"It was nine seventeen in the morning, and the house was heavy\".[1]\\n',\n",
       " \"Emulating Jack Kerouac's novel On the Road, Ross Goodwin traveled from New York to New Orleans in March 2017[2] with the AI, in the form of a long short-term memory recurrent neural network.[1] Three sensors provided real-world input: a surveillance camera mounted on the trunk[2] was trained on the passing scenery, a microphone picked up conversations inside the car, and the Global Positioning System (GPS) tracked the car's location.[3] Input from these sources, and the time provided by the computer's internal clock,[1] was fed into the AI program, which in turn generated sentences on rolls of receipt paper.[3]\\n\",\n",
       " 'The car was a Cadillac; Goodwin explained later he wanted an \"authoritative\" car (and was unable to get a Crown Vic), and worried that people might think him a terrorist if they saw the car with its electronics and wires. Google paid part of the cost, having become interested in Goodwin\\'s work at New York University. Accompanying him were five other people (including his sister and his fiancee), and the Cadillac was followed by a film crew which documented the four-day journey; the documentary was directed by Lewis Rapkin.[2]\\n',\n",
       " 'The AI program had been trained to sample fiction in preparation for the novel-writing journey.[3] Goodwin fed it three different text corpora, each with about 20 million words--one with poetry, one with science fiction, and one with \"bleak\" writing, in Goodwin\\'s words. It had also been fed a data set from Foursquare; the AI recognized locations from Foursquare, and appended commentaries to them. The conversations captured inside the car were rendered in mutated fashion. The locations provided by the GPS were outputted verbatim, to open the day\\'s writing.[2]\\n',\n",
       " 'The AI generated the novel letter by letter.[2] Due to continual input from the GPS and time clock, the novel often mentions the latitude, longitude, and time of day.[1] It was printed unedited and thus is \"choppy\", according to Goodwin; typos were retained, since he wanted to show the text \"in its most raw form\".[3] He believes the AI is capable of writing literature, but still feels responsible for the guidance and ownership of the content. Goodwin says his main purpose for this novel is to reveal the way machines create words: \"In the future when this text becomes more sophisticated it\\'s a warning. If you see patterns like this, it may not have been written by a human\".[3]\\n',\n",
       " 'Thomas Hornigold, writing for Singularity Hub, concluded that the AI is no Jack Kerouac, but that \"you might see, in the odd line, the flickering ghost of something like consciousness, a deeper understanding\".[1] Brian Merchant, writing in The Atlantic, read the entire novel in one sitting. He could not recognize a coherent plot or story arc, but saw \"plenty of pixelated poetry in its ragtag assemblage of modern American imagery. And there are some striking and memorable lines\".[2]\\n',\n",
       " 'Ross Goodwin, a former ghostwriter for the Obama administration and a creative technologist,[2] has often used neural networks to create poetry and screenplays. Notable works include the short film Sunspring, starring Thomas Middleditch and directed by Goodwin\\'s frequent collaborator Oscar Sharp,[4] and Word.Camera, an 1885 bellows camera that outputs poetry about whatever it is pointed at when the button is pressed.[5] His Master\\'s Thesis at New York University was a project called \"Narrated Reality\",[6] for which he walked around the city with a backpack containing compass, punch clock, and camera; data from these devices was fed into an LSTM neural network whose output was \"weird associative poetry\". A year after 1 the Road, Google hired him to work with their Artists and Machine Intelligence project.[2]\\n',\n",
       " 'Natural Language Processing is the technology used to aid computers to understand the human’s natural language.',\n",
       " 'It’s not an easy task teaching machines to understand how we communicate.',\n",
       " 'Leand Romaf, an experienced software engineer who is passionate at teaching people how artificial intelligence systems work, says that “in recent years, there have been significant breakthroughs in empowering computers to understand language just as we do.”',\n",
       " 'This article will give a simple introduction to Natural Language Processing and how it can be achieved.',\n",
       " 'Natural Language Processing, usually shortened as NLP, is a branch of artificial intelligence that deals with the interaction between computers and humans using the natural language.',\n",
       " 'The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.',\n",
       " 'Most NLP techniques rely on machine learning to derive meaning from human languages.',\n",
       " '1. Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning & Big Data',\n",
       " '2. Data Science Simplified Part 1: Principles and Process',\n",
       " '3. Getting Started with Building Realtime API Infrastructure',\n",
       " '4. AI & NLP Workshop',\n",
       " 'In fact, a typical interaction between humans and machines using Natural Language Processing could go as follows:',\n",
       " '1. A human talks to the machine',\n",
       " '2. The machine captures the audio',\n",
       " '3. Audio to text conversion takes place',\n",
       " '4. Processing of the text’s data',\n",
       " '5. Data to audio conversion takes place',\n",
       " '6. The machine responds to the human by playing the audio file',\n",
       " 'Natural Language Processing is the driving force behind the following common applications:',\n",
       " 'Natural Language processing is considered a difficult problem in computer science. It’s the nature of the human language that makes NLP difficult.',\n",
       " 'The rules that dictate the passing of information using natural languages are not easy for computers to understand.',\n",
       " 'Some of these rules can be high-leveled and abstract; for example, when someone uses a sarcastic remark to pass information.',\n",
       " 'On the other hand, some of these rules can be low-levelled; for example, using the character “s” to signify the plurality of items.',\n",
       " 'Comprehensively understanding the human language requires understanding both the words and how the concepts are connected to deliver the intended message.',\n",
       " 'While humans can easily master a language, the ambiguity and imprecise characteristics of the natural languages are what make NLP difficult for machines to implement.',\n",
       " 'NLP entails applying algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that computers can understand.',\n",
       " 'When the text has been provided, the computer will utilize algorithms to extract meaning associated with every sentence and collect the essential data from them.',\n",
       " 'Sometimes, the computer may fail to understand the meaning of a sentence well, leading to obscure results.',\n",
       " 'For example, a humorous incident occurred in the 1950s during the translation of some words between the English and the Russian languages.',\n",
       " 'Here is the biblical sentence that required translation:',\n",
       " '“The spirit is willing, but the flesh is weak.”',\n",
       " 'Here is the result when the sentence was translated to Russian and back to English:',\n",
       " '“The vodka is good, but the meat is rotten.”',\n",
       " 'Syntactic analysis and semantic analysis are the main techniques used to complete Natural Language Processing tasks.',\n",
       " 'Here is a description on how they can be used.',\n",
       " 'Syntax refers to the arrangement of words in a sentence such that they make grammatical sense.',\n",
       " 'In NLP, syntactic analysis is used to assess how the natural language aligns with the grammatical rules.',\n",
       " 'Computer algorithms are used to apply grammatical rules to a group of words and derive meaning from them.',\n",
       " 'Here are some syntax techniques that can be used:',\n",
       " 'Semantics refers to the meaning that is conveyed by a text. Semantic analysis is one of the difficult aspects of Natural Language Processing that has not been fully resolved yet.',\n",
       " 'It involves applying computer algorithms to understand the meaning and interpretation of words and how sentences are structured.',\n",
       " 'Here are some techniques in semantic analysis:',\n",
       " 'Natural Language Processing plays a critical role in supporting machine-human interactions.',\n",
       " 'As more research is being carried in this field, we expect to see more breakthroughs that will make machines smarter at recognizing and understanding the human language.',\n",
       " 'Have you used any NLP technique in enhancing the functionality of your application?',\n",
       " 'Or, do you have any question or comment?',\n",
       " 'Please share below.',\n",
       " 'Written by',\n",
       " 'Over the past few months, I have been collecting AI cheat sheets. From time to time I share them with friends and colleagues and recently I have been getting asked a lot, so I decided to organize and share the entire collection. To make things more interesting and give context, I added descriptions and/or excerpts for each major topic.',\n",
       " 'This is the most complete list and the Big-O is at the very end, enjoy…',\n",
       " '>>> Update: We have recently redesigned these cheat sheets into a Super High Definition PDF. Check them out below:',\n",
       " 'This machine learning cheat sheet will help you find the right estimator for the job which is the most difficult part. The flowchart will help you check the documentation and rough guide of each estimator that will help you to know more about the problems and how to solve it.',\n",
       " 'Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.',\n",
       " 'This machine learning cheat sheet from Microsoft Azure will help you choose the appropriate machine learning algorithms for your predictive analytics solution. First, the cheat sheet will asks you about the data nature and then suggests the best algorithm for the job.',\n",
       " 'In May 2017 Google announced the second-generation of the TPU, as well as the availability of the TPUs in Google Compute Engine.[12] The second-generation TPUs deliver up to 180 teraflops of performance, and when organized into clusters of 64 TPUs provide up to 11.5 petaflops.',\n",
       " 'In 2017, Google’s TensorFlow team decided to support Keras in TensorFlow’s core library. Chollet explained that Keras was conceived to be an interface rather than an end-to-end machine-learning framework. It presents a higher-level, more intuitive set of abstractions that make it easy to configure neural networks regardless of the backend scientific computing library.',\n",
       " 'NumPy targets the CPython reference implementation of Python, which is a non-optimizing bytecode interpreter. Mathematical algorithms written for this version of Python often run much slower than compiled equivalents. NumPy address the slowness problem partly by providing multidimensional arrays and functions and operators that operate efficiently on arrays, requiring rewriting some code, mostly inner loops using NumPy.',\n",
       " 'The name ‘Pandas’ is derived from the term “panel data”, an econometrics term for multidimensional structured data sets.',\n",
       " 'The term “data wrangler” is starting to infiltrate pop culture. In the 2017 movie Kong: Skull Island, one of the characters, played by actor Marc Evan Jackson is introduced as “Steve Woodward, our data wrangler”.',\n",
       " 'SciPy builds on the NumPy array object and is part of the NumPy stack which includes tools like Matplotlib, pandas and SymPy, and an expanding set of scientific computing libraries. This NumPy stack has similar users to other applications such as MATLAB, GNU Octave, and Scilab. The NumPy stack is also sometimes referred to as the SciPy stack.[3]',\n",
       " 'matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+. There is also a procedural “pylab” interface based on a state machine (like OpenGL), designed to closely resemble that of MATLAB, though its use is discouraged.[2] SciPy makes use of matplotlib.',\n",
       " 'pyplot is a matplotlib module which provides a MATLAB-like interface.[6] matplotlib is designed to be as usable as MATLAB, with the ability to use Python, with the advantage that it is free.',\n",
       " '>>> If you like this list, you can let me know here. <<<',\n",
       " 'Stefan is the founder of Chatbot’s Life, a Chatbot media and consulting firm. Chatbot’s Life has grown to over 150k views per month and has become the premium place to learn about Bots & AI online. Chatbot’s Life has also consulted many of the top Bot companies like Swelly, Instavest, OutBrain, NearGroup and a number of Enterprises.',\n",
       " 'Big-O Algorithm Cheat Sheet: http://bigocheatsheet.com/',\n",
       " 'Bokeh Cheat Sheet: https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Bokeh_Cheat_Sheet.pdf',\n",
       " 'Data Science Cheat Sheet: https://www.datacamp.com/community/tutorials/python-data-science-cheat-sheet-basics',\n",
       " 'Data Wrangling Cheat Sheet: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf',\n",
       " 'Data Wrangling: https://en.wikipedia.org/wiki/Data_wrangling',\n",
       " 'Ggplot Cheat Sheet: https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf',\n",
       " 'Keras Cheat Sheet: https://www.datacamp.com/community/blog/keras-cheat-sheet#gs.DRKeNMs',\n",
       " 'Keras: https://en.wikipedia.org/wiki/Keras',\n",
       " 'Machine Learning Cheat Sheet: https://ai.icymi.email/new-machinelearning-cheat-sheet-by-emily-barry-abdsc/',\n",
       " 'Machine Learning Cheat Sheet: https://docs.microsoft.com/en-in/azure/machine-learning/machine-learning-algorithm-cheat-sheet',\n",
       " 'ML Cheat Sheet:: http://peekaboo-vision.blogspot.com/2013/01/machine-learning-cheat-sheet-for-scikit.html',\n",
       " 'Matplotlib Cheat Sheet: https://www.datacamp.com/community/blog/python-matplotlib-cheat-sheet#gs.uEKySpY',\n",
       " 'Matpotlib: https://en.wikipedia.org/wiki/Matplotlib',\n",
       " 'Neural Networks Cheat Sheet: http://www.asimovinstitute.org/neural-network-zoo/',\n",
       " 'Neural Networks Graph Cheat Sheet: http://www.asimovinstitute.org/blog/',\n",
       " 'Neural Networks: https://www.quora.com/Where-can-find-a-cheat-sheet-for-neural-network',\n",
       " 'Numpy Cheat Sheet: https://www.datacamp.com/community/blog/python-numpy-cheat-sheet#gs.AK5ZBgE',\n",
       " 'NumPy: https://en.wikipedia.org/wiki/NumPy',\n",
       " 'Pandas Cheat Sheet: https://www.datacamp.com/community/blog/python-pandas-cheat-sheet#gs.oundfxM',\n",
       " 'Pandas: https://en.wikipedia.org/wiki/Pandas_(software)',\n",
       " 'Pandas Cheat Sheet: https://www.datacamp.com/community/blog/pandas-cheat-sheet-python#gs.HPFoRIc',\n",
       " 'Pyspark Cheat Sheet: https://www.datacamp.com/community/blog/pyspark-cheat-sheet-python#gs.L=J1zxQ',\n",
       " 'Scikit Cheat Sheet: https://www.datacamp.com/community/blog/scikit-learn-cheat-sheet',\n",
       " 'Scikit-learn: https://en.wikipedia.org/wiki/Scikit-learn',\n",
       " 'Scikit-learn Cheat Sheet: http://peekaboo-vision.blogspot.com/2013/01/machine-learning-cheat-sheet-for-scikit.html',\n",
       " 'Scipy Cheat Sheet: https://www.datacamp.com/community/blog/python-scipy-cheat-sheet#gs.JDSg3OI',\n",
       " 'SciPy: https://en.wikipedia.org/wiki/SciPy',\n",
       " 'TesorFlow Cheat Sheet: https://www.altoros.com/tensorflow-cheat-sheet.html',\n",
       " 'Tensor Flow: https://en.wikipedia.org/wiki/TensorFlow',\n",
       " 'Written by',\n",
       " 'We are happy to announce the upcoming, AI/NLP workshop featuring 3 expert instructors from Rasa and SmartLoop. Workshop starts on September 19th and is a full day event!',\n",
       " 'In our workshop, you will be making a customer service Voice bot that can handle your most commonly asked questions. Customer Service bots have seen an explosion lately as they can decrease costs as much as 39% according to Facebook.',\n",
       " 'The workshop starts with a strong focus on bot design, best practices, writing scripts, fallbacks, and other conversational design principles.',\n",
       " 'You will then design your conversational flows, launch your bot and test it using SmartLoop. This quick integration will allow you to gather, NLP requirements so we know what intents and entities are most needed.',\n",
       " 'Next, you learn the basics of NLP, intent clarification, entities extraction and dialogue management using the open source Rasa Stack which is powered by TensorFlow.',\n",
       " 'Making a bot is easy, making a good NLP bot that leads to an ROI can be very hard.',\n",
       " 'Our workshop aims to give you the exact tools and frameworks you will need to in order to make a bot that can delight your customers and business leaders; we will focus on use cases that have a positive ROI.',\n",
       " 'Our instructors are unique positioned to do this. The SmartLoop team has worked with Coke, AOL, Louis Vuitton, Adobe and many other enterprise clients. Rasa is the most popular open source NLP platform and works with clients like BMW, USB, Yellow Pages and many other Fortune 500 companies.',\n",
       " 'This workshop is part of the Chatbot Conference and a great opportunity to network with bot founders, enterprises, and people like you.',\n",
       " 'Additionally, we will sharing of the conference content with our workshop attendees and you’re welcome to go back and forth between the Chatbot Conference and the Workshop. Hope to see you there!',\n",
       " 'Written by',\n",
       " 'In 2006, Clive Humbly, UK Mathematician, and architect of Tesco’s Clubcard coined the phrase “Data is the new oil. He said the following:',\n",
       " '”Data is the new oil. It’s valuable, but if unrefined it cannot be used. It has to be changed into gas, plastic, chemicals, etc. to create a valuable entity that drives profitable activity; so, must data be broken down, analyzed for it to have value.”',\n",
       " 'The iPhone revolution, growth of the mobile economy, advancements in Big Data technology has created a perfect storm. In 2012, HBR published an article that put Data Scientists on the radar. The article Data Scientist: The Sexiest Job of the 21st Century labeled this “new breed” of people; a hybrid of data hacker, analyst, communicator, and trusted adviser.',\n",
       " 'Every organization is now making attempts to be more data-driven. Machine learning techniques have helped them in this endeavor. I realize that a lot of the material out there is too technical and difficult to understand. In this series of articles, my aim is to simplify Data Science. I will take a cue from the Stanford course/book (An Introduction to Statistical Learning). This attempt is to make Data Science easy to understand for everyone.',\n",
       " 'In this article, I will begin by covering fundamental principles, general process and types of problems in Data Science.',\n",
       " 'Data Science is a multi-disciplinary field. It is the intersection between the following domains:',\n",
       " 'The focus of this series will be to simplify the Machine Learning aspect of Data Science. In this article, I will begin by covering principles, general process and types of problems in Data Science.',\n",
       " 'Taking a cue from principle #2, let me now emphasize on the process part of data science. Following are the stages of a typical data science project:',\n",
       " 'Albert Einstein once quoted “Everything should be made as simple as possible, but not simpler”. This quote is the crux of defining the business problem. Problem statements need to be developed and framed. Clear success criteria need to be established. In my experience, business teams are too busy with their operational tasks at hand. It doesn’t mean that they don’t have challenges that need to be addressed. Brainstorming sessions, workshops, and interviews can help to uncover these challenges and develop hypotheses. Let me illustrate this with an example. Let us assume that a telco company has seen a decline in their year-on-year revenue due to a reduction in their customer base. In this scenario, the business problem may be defined as:',\n",
       " 'The business problem, once defined, needs to be decomposed to machine learning tasks. Let’s elaborate on the example that we have set above. If the organization needs to grow our the customer base by targeting new segments and reducing customer churn, how can we decompose it into machine learning problems? Following is an example of decomposition:',\n",
       " 'Once we have defined the business problem and decomposed into machine learning problems, we need to dive deeper into the data. Data understanding should be explicit to the problem at hand. It should help us with to develop right kind of strategies for analysis. Key things to note is the source of data, quality of data, data bias, etc.',\n",
       " 'A cosmonaut traverses through the unknowns of the cosmos. Similarly, a data scientist traverses through the unknowns of the patterns in the data, peeks into the intrigues of its characteristics and formulates the unexplored. Exploratory data analysis (EDA) is an exciting task. We get to understand the data better, investigate the nuances, discover hidden patterns, develop new features and formulate modeling strategies.',\n",
       " 'After EDA, we move on to the modeling phase. Here, based on our specific machine learning problems, we apply useful algorithms like regressions, decision trees, random forests, etc.',\n",
       " 'Finally, the developed models are deployed. They are continuously monitored to observe how they behaved in the real world and calibrated accordingly.',\n",
       " 'Typically, the modeling and deployment part is only 20% of the work. 80% of the work is getting your hands dirty with data, exploring the data and understanding it.',\n",
       " 'In general, machine learning has two kinds of tasks:',\n",
       " 'Supervised learning is a type of machine learning task where there is a defined target. Conceptually, a modeler will supervise the machine learning model to achieve a particular goal. Supervised Learning can be further classified into two types:',\n",
       " 'Regression is the workhorse of machine learning tasks. They are used to estimate or predict a numerical variable. Few examples of regression models can be:',\n",
       " 'As the name suggests, classification models classify something. It is estimated which bucket something is best suited. Classification models are frequently used in all types of applications. Few examples of classification models are:',\n",
       " 'Unsupervised learning is a class of machine learning task where there are no targets. Since unsupervised learning doesn’t have any specified target, the result that they churn out may be sometimes difficult to interpret. There are a lot of types of unsupervised learning tasks. The key ones are:',\n",
       " 'Once we have broken down business problems into machine learning tasks, one or many algorithms can solve a given machine learning task. Typically, the model is trained on multiple algorithms. The algorithm or set of algorithms that provide the best result is chosen for deployment.',\n",
       " 'Azure Machine Learning has more than 30 pre-built algorithms that can be used for training machine learning models.',\n",
       " 'Azure Machine Learning cheat-sheet will help to navigate through it.',\n",
       " 'Data Science is a broad field. It is an exciting field. It is an art. It is a science. In this article, we have just explored the surface of the iceberg. The “hows” will be futile if the “whys” are not known. In the subsequent articles, we will explore the “hows” of machine learning.',\n",
       " 'Written by',\n",
       " 'Last Updated on August 7, 2019',\n",
       " 'Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.',\n",
       " 'The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.',\n",
       " 'In this post, you will discover what natural language processing is and why it is so important.',\n",
       " 'After reading this post, you will know:',\n",
       " 'Discover how to develop deep learning models for text classification, translation, photo captioning and more in my new book, with 30 step-by-step tutorials and full source code.',\n",
       " 'Let’s get started.',\n",
       " 'What Is Natural Language Processing?Photo by pedrik, some rights reserved.',\n",
       " 'Natural language refers to the way we, humans, communicate with each other.',\n",
       " 'Namely, speech and text.',\n",
       " 'We are surrounded by text.',\n",
       " 'Think about how much text you see each day:',\n",
       " 'The list is endless.',\n",
       " 'Now think about speech.',\n",
       " 'We may speak to each other, as a species, more than we write. It may even be easier to learn to speak than to write.',\n",
       " 'Voice and text are how we communicate with each other.',\n",
       " 'Given the importance of this type of data, we must have methods to understand and reason about natural language, just like we do for other types of data.',\n",
       " '',\n",
       " 'Take my free 7-day email crash course now (with code).',\n",
       " 'Click to sign-up and also get a free PDF Ebook version of the course.',\n",
       " 'Start Your FREE Crash-Course Now',\n",
       " '',\n",
       " 'Working with natural language data is not solved.',\n",
       " 'It has been studied for half a century, and it is really hard.',\n",
       " 'It is hard from the standpoint of the child, who must spend many years acquiring a language … it is hard for the adult language learner, it is hard for the scientist who attempts to model the relevant phenomena, and it is hard for the engineer who attempts to build systems that deal with natural language input or output. These tasks are so hard that Turing could rightly make fluent conversation in natural language the centerpiece of his test for intelligence.',\n",
       " '— Page 248, Mathematical Linguistics, 2010.',\n",
       " 'Natural language is primarily hard because it is messy. There are few rules.',\n",
       " 'And yet we can easily understand each other most of the time.',\n",
       " 'Human language is highly ambiguous … It is also ever changing and evolving. People are great at producing language and understanding language, and are capable of expressing, perceiving, and interpreting very elaborate and nuanced meanings. At the same time, while we humans are great users of language, we are also very poor at formally understanding and describing the rules that govern language.',\n",
       " '— Page 1, Neural Network Methods in Natural Language Processing, 2017.',\n",
       " 'Linguistics is the scientific study of language, including its grammar, semantics, and phonetics.',\n",
       " 'Classical linguistics involved devising and evaluating rules of language. Great progress was made on formal methods for syntax and semantics, but for the most part, the interesting problems in natural language understanding resist clean mathematical formalisms.',\n",
       " 'Broadly, a linguist is anyone who studies language, but perhaps more colloquially, a self-defining linguist may be more focused on being out in the field.',\n",
       " 'Mathematics is the tool of science. Mathematicians working on natural language may refer to their study as mathematical linguistics, focusing exclusively on the use of discrete mathematical formalisms and theory for natural language (e.g. formal languages and automata theory).',\n",
       " 'Computational linguistics is the modern study of linguistics using the tools of computer science. Yesterday’s linguistics may be today’s computational linguist as the use of computational tools and thinking has overtaken most fields of study.',\n",
       " 'Computational linguistics is the study of computer systems for understanding and generating natural language. … One natural function for computational linguistics would be the testing of grammars proposed by theoretical linguists.',\n",
       " '— Pages 4-5, Computational Linguistics: An Introduction, 1986.',\n",
       " 'Large data and fast computers mean that new and different things can be discovered from large datasets of text by writing and running software.',\n",
       " 'In the 1990s, statistical methods and statistical machine learning began to and eventually replaced the classical top-down rule-based approaches to language, primarily because of their better results, speed, and robustness. The statistical approach to studying natural language now dominates the field; it may define the field.',\n",
       " 'Data-Drive methods for natural language processing have now become so popular that they must be considered mainstream approaches to computational linguistics. … A strong contributing factor to this development is undoubtedly the increase amount of available electronically stored data to which these methods can be applied; another factor might be a certain disenchantment with approaches relying exclusively on hand-crafted rules, due to their observed brittleness.',\n",
       " '— Page 358, The Oxford Handbook of Computational Linguistics, 2005.',\n",
       " 'The statistical approach to natural language is not limited to statistics per-se, but also to advanced inference methods like those used in applied machine learning.',\n",
       " '… understanding natural language require large amounts of knowledge about morphology, syntax, semantics and pragmatics as well as general knowledge about the world. Acquiring and encoding all of this knowledge is one of the fundamental impediments to developing effective and robust language systems. Like the statistical methods … machine learning methods off the promise of automatic the acquisition of this knowledge from annotated or unannotated language corpora.',\n",
       " '— Page 377, The Oxford Handbook of Computational Linguistics, 2005.',\n",
       " 'Computational linguistics also became known by the name of natural language process, or NLP, to reflect the more engineer-based or empirical approach of the statistical methods.',\n",
       " 'The statistical dominance of the field also often leads to NLP being described as Statistical Natural Language Processing, perhaps to distance it from the classical computational linguistics methods.',\n",
       " 'I view computational linguistics as having both a scientific and an engineering side. The engineering side of computational linguistics, often called natural language processing (NLP), is largely concerned with building computational tools that do useful things with language, e.g., machine translation, summarization, question-answering, etc. Like any engineering discipline, natural language processing draws on a variety of different scientific disciplines.',\n",
       " '— How the statistical revolution changes (computational) linguistics, 2009.',\n",
       " 'Linguistics is a large topic of study, and, although the statistical approach to NLP has shown great success in some areas, there is still room and great benefit from the classical top-down methods.',\n",
       " 'Roughly speaking, statistical NLP associates probabilities with the alternatives encountered in the course of analyzing an utterance or a text and accepts the most probable outcome as the correct one. … Not surprisingly, words that name phenomena that are closely related in the world, or our perception of it, frequently occur close to one another so that crisp facts about the world are reflected in somewhat fuzzier facts about texts. There is much room for debate in this view.',\n",
       " '— Page xix, The Oxford Handbook of Computational Linguistics, 2005.',\n",
       " 'As machine learning practitioners interested in working with text data, we are concerned with the tools and methods from the field of Natural Language Processing.',\n",
       " 'We have seen the path from linguistics to NLP in the previous section. Now, let’s take a look at how modern researchers and practitioners define what NLP is all about.',\n",
       " 'In perhaps one of the more widely textbooks written by top researchers in the field, they refer to the subject as “linguistic science,” permitting discussion of both classical linguistics and modern statistical methods.',\n",
       " 'The aim of a linguistic science is to be able to characterize and explain the multitude of linguistic observations circling around us, in conversations, writing, and other media. Part of that has to do with the cognitive size of how humans acquire, produce and understand language, part of it has to do with understanding the relationship between linguistic utterances and the world, and part of it has to do with understand the linguistic structures by which language communicates.',\n",
       " '— Page 3, Foundations of Statistical Natural Language Processing, 1999.',\n",
       " 'They go on to focus on inference through the use of statistical methods in natural language processing.',\n",
       " 'Statistical NLP aims to do statistical inference for the field of natural language. Statistical inference in general consists of taking some data (generated in accordance with some unknown probability distribution) and then making some inference about this distribution.',\n",
       " '— Page 191, Foundations of Statistical Natural Language Processing, 1999.',\n",
       " 'In their text on applied natural language processing, the authors and contributors to the popular NLTK Python library for NLP describe the field broadly as using computers to work with natural language data.',\n",
       " 'We will take Natural Language Processing — or NLP for short –in a wide sense to cover any kind of computer manipulation of natural language. At one extreme, it could be as simple as counting word frequencies to compare different writing styles. At the other extreme, NLP involves “understanding” complete human utterances, at least to the extent of being able to give useful responses to them.',\n",
       " '— Page ix, Natural Language Processing with Python, 2009.',\n",
       " 'Statistical NLP has turned another corner and is now strongly focused on the use of deep learning neural networks to both perform inference on specific tasks and for developing robust end-to-end systems.',\n",
       " 'In one of the first textbooks dedicated to this emerging topic, Yoav Goldberg succinctly defines NLP as automatic methods that take natural language as input or produce natural language as output.',\n",
       " 'Natural language processing (NLP) is a collective term referring to automatic computational processing of human languages. This includes both algorithms that take human-produced text as input, and algorithms that produce natural looking text as outputs.',\n",
       " '— Page xvii, Neural Network Methods in Natural Language Processing, 2017.',\n",
       " 'Deep learning techniques show a lot of promise for challenging natural language processing problems. Learn more here:',\n",
       " 'For an overview of how deep learning neural networks can be harnessed for natural language, see the post:',\n",
       " 'This section provides more resources on the topic if you are looking go deeper.',\n",
       " 'In this post, you discovered what natural language processing is why it is so important.',\n",
       " 'Specifically, you learned:',\n",
       " 'Do you have any questions?\\nAsk your questions in the comments below and I will do my best to answer.',\n",
       " '...with just a few lines of python code',\n",
       " 'Discover how in my new Ebook:\\nDeep Learning for Natural Language Processing',\n",
       " 'It provides self-study tutorials on topics like:\\nBag-of-Words, Word Embedding, Language Models, Caption Generation, Text Translation and much more...',\n",
       " 'Skip the Academics. Just Results.',\n",
       " 'So do you think Computational Linguistics (CL) is basically the same field as Natural Language Processing (NLP) or do you view them as separate?',\n",
       " 'Hmmm, really it is a matter of the perspective on how to view the problem. ',\n",
       " 'It’s a lot like the way stats and ml can both view predictive modeling problems differently.',\n",
       " 'Really, I’m a pragmatist and I’ll draw knowledge/wisdom from anywhere as long as I can get closer to a viable solution.',\n",
       " 'In your blog on deep learning, you make this statement in response to someone’s question:',\n",
       " '“It seems that the niche for deep learning techniques is when you are working with raw analog data, like audio and image data.”',\n",
       " 'With this in mind, what can be said about deep learning for natural language processing? What are the pros and cons?',\n",
       " 'Nice, I still stand behind that. With text it is the same idea, text is raw analog data.',\n",
       " 'There’s tons of it, it’s full of ambiguity, there are few formal rules for language, etc.',\n",
       " 'a more interesting use case of NLP and deep learning combined is sarcasm detector. check this out. https://www.technologyreview.com/s/602639/how-vector-space-mathematics-helps-machines-spot-sarcasm/',\n",
       " 'Thanks for sharing.',\n",
       " 'Thank you for sharing your writing… ',\n",
       " 'I don’t learn language as a degree or research thing so can I still better use NLTK for projects that involved NLP?',\n",
       " 'Do I need a great mathematical knowledge, specifically statistics and algorithm knowledge to understand NLP and NLTK?',\n",
       " 'What are some examples of real use cases of NLP?',\n",
       " 'I have examples here:\\nhttps://machinelearningmastery.com/applications-of-deep-learning-for-natural-language-processing/',\n",
       " 'What are the practical application of nlp sir',\n",
       " 'NLP is not a problem, it is a field of study. Here are some problems that belong to NLP that deep learning methods are helping to solve:\\nhttps://machinelearningmastery.com/applications-of-deep-learning-for-natural-language-processing/',\n",
       " 'Helpful Article!! I also have written an article on Natural processing language. http://www.nbdigitech.com/resources/what-is-natural-language-processing/',\n",
       " 'Thanks for sharing.',\n",
       " 'It’s too tough.',\n",
       " 'What is James?',\n",
       " 'Comment ',\n",
       " 'Name (required) ',\n",
       " 'Email (will not be published) (required) ',\n",
       " 'Website',\n",
       " ' \\n\\n',\n",
       " '',\n",
       " '',\n",
       " \"Welcome! I'm Jason Brownlee PhD and I help developers get results with machine learning.\\nRead More\",\n",
       " '',\n",
       " 'The Deep Learning for NLP EBook is where I keep the Really Good stuff.',\n",
       " '© 2019 Machine Learning Mastery Pty. Ltd. All Rights Reserved.\\r\\nAddress: PO Box 206, Vermont Victoria 3133, Australia. | ACN: 626 223 336.\\nRSS |\\r\\nTwitter | \\r\\nFacebook | \\r\\nLinkedIn',\n",
       " 'Privacy | \\r\\nDisclaimer | \\r\\nTerms | \\r\\nContact |\\r\\nSitemap |\\r\\nSearch',\n",
       " '\\n\\t\\t\\t\\t\\t\\tBACKGROUND IMAGE: Sergey Nivens/stock.adobe.com\\n\\t\\t\\t\\t\\t',\n",
       " 'Natural language processing (NLP) is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence (AI).',\n",
       " 'The development of NLP applications is challenging because computers traditionally require humans to \"speak\" to them in a programming language that is precise, unambiguous and highly structured, or through a limited number of clearly enunciated voice commands. Human speech, however, is not always precise -- it is often ambiguous and the linguistic structure can depend on many complex variables, including slang, regional dialects and social context.',\n",
       " 'Syntax and semantic analysis are two main techniques used with natural language processing. Syntax is the arrangement of words in a sentence to make grammatical sense. NLP uses syntax to assess meaning from a language based on grammatical rules. Syntax techniques used include parsing (grammatical analysis for a sentence), word segmentation (which divides a large piece of text to units), sentence breaking (which places sentence boundaries in large texts), morphological segmentation (which divides words into groups) and stemming (which divides words with inflection in them to root forms).',\n",
       " 'Semantics involves the use and meaning behind words. NLP applies algorithms to understand the meaning and structure of sentences. Techniques that NLP uses with semantics include word sense disambiguation (which derives meaning of a word based on context), named entity recognition (which determines words that can be categorized into groups), and natural language generation (which will use a database to determine semantics behind words).',\n",
       " \"Current approaches to NLP are based on\\xa0deep learning, a type of AI that examines and uses patterns in data to improve a program's understanding. Deep learning models require massive amounts of labeled data to train on and identify relevant correlations, and assembling this kind of\\xa0big data\\xa0set is one of the main hurdles to NLP currently.\",\n",
       " \"Earlier approaches to NLP involved a more rules-based approach, where simpler machine learning\\xa0algorithms\\xa0were told what words and phrases to look for in text and given specific responses when those phrases appeared. But deep learning is a more flexible, intuitive approach in which algorithms learn to identify speakers' intent from many examples, almost like how a child would learn human language.\",\n",
       " 'Three tools used commonly for NLP include NLTK, Gensim, and Intel NLP Architect. NTLK, Natural Language Toolkit, is an open source python modules with data sets and tutorials. Gensim is a Python library for topic modeling and document indexing. Intel NLP Architect is also another Python library for deep learning topologies and techniques.',\n",
       " ' This video explains how to usedeep learning to build NLP models.',\n",
       " 'Research being done on natural language processing revolves around search, especially\\xa0enterprise search.\\xa0This involves allowing users to query data sets in the form of a question that they might pose to another person. The machine interprets the important elements of the human language sentence, such as those that might correspond to specific features in a data set, and returns an answer.',\n",
       " \"NLP can be used to interpret free text and make it analyzable. There is a tremendous amount of information stored in free text files, like patients' medical records, for example. Before\\xa0deep learning-based NLP models, this information was inaccessible to computer-assisted analysis and could not be analyzed in any systematic way. But NLP allows analysts to sift through massive troves of free text to find relevant information in the files.\",\n",
       " \"Sentiment analysis\\xa0is another primary use case for NLP. Using sentiment analysis, data scientists can assess comments on social media to see how their business's brand is performing, for example, or review notes from customer service teams to identify areas where people want the business to perform better.\",\n",
       " 'Google and other search engines base their machine translation technology on NLP deep learning models. This allows algorithms to read text on a webpage, interpret its meaning and translate it to another language.',\n",
       " 'The advantage of natural language processing can be seen when considering the following two statements: \"Cloud computing insurance should be part of every service level agreement\" and \"A good SLA ensures an easier night\\'s sleep -- even in the cloud.\" If you use natural language processing for search, the program will recognize that\\xa0cloud computing\\xa0is an entity, that\\xa0cloud\\xa0is an abbreviated form of cloud computing and that\\xa0SLA\\xa0is an industry acronym for service level agreement.',\n",
       " 'These are the types of vague elements that frequently appear in human language and that machine learning algorithms have historically been bad at interpreting. Now, with improvements in deep learning and artificial intelligence, algorithms can effectively interpret them.',\n",
       " 'This has implications for the types of data that can be analyzed. More and more information is being created online every day, and a lot of it is natural human language. Until recently, businesses have been unable to analyze this data. But advances in NLP make it possible to analyze and learn from a greater range of data sources.',\n",
       " 'NLP hosts benefits such as:',\n",
       " 'NLP has not yet been wholly perfected. For example, semantic analysis can still be a challenge for NLP.\\xa0Other difficulties include the fact that abstract use of language is typically tricky for programs to understand. For instance, NLP does not pick up sarcasm easily. These topics usually require the understanding of the words being used and the context in which the way they are being used. As another example, a sentence can change meaning depending on which word the speaker puts stress on. NLP is also challenged by the fact that language, and the way people use it, is continually changing. ',\n",
       " 'Margaret Rouse\\xa0asks:',\n",
       " 'Please check the box if you want to proceed.',\n",
       " 'Please check the box if you want to proceed.',\n",
       " 'Enterprise data catalogs record all the databases and files in a corporation, but sometimes it can become out of date. Advances ...',\n",
       " 'Scaling a MySQL database in the cloud is not easy, but the open source Vitess project manages the project at scale for ...',\n",
       " \"Unstructured data makes up a huge portion of most businesses' data volume. But, with data-hungry AI systems coming online, making...\",\n",
       " 'In this book excerpt from \"AWS Certified SysOps Administrator Associate All-in-One Exam Guide,\" review the best practices for OS ...',\n",
       " 'Get ready for data analytics in the cloud. Learn the best ways to handle your data on AWS. Distinguish between data lakes and ...',\n",
       " 'AWS has flooded its catalog with services but enterprises still struggle with the gaps that remain. Find out which pain points ...',\n",
       " \"Acquia's new venture backing and customer experience cloud apps precipitate a need for easier integrations and setup for future ...\",\n",
       " 'The updates include a new home screen and a page for users to track the signing process, the ability to zoom and navigation ...',\n",
       " \"Acquia and Drupal founder Dries Buytaert discusses his company's move into marketing automation, CDPs and what's next after Vista...\",\n",
       " 'This handbook looks at what Oracle Autonomous Database offers to Oracle users and issues that organizations should consider ...',\n",
       " 'Oracle Autonomous Database can automate routine administrative and operational tasks for DBAs and improve productivity, but ...',\n",
       " \"Oracle co-CEO Mark Hurd's abrupt death at 62 has put the software giant in the position of naming his replacement, and the ...\",\n",
       " 'SAP Qualtrics is meant to be a powerful employee experience tool. Discover its features, feedback software and which products are...',\n",
       " 'In this Q&A, SAP chief partner officer Karl Fahrbach discusses why the company has evolved its partner program to reward customer...',\n",
       " \"Medical device startup Enable Injections is small now but intends to be big soon, so it's implementing SAP S/4HANA in phases to ...\",\n",
       " 'Good database design is a must to meet processing needs in SQL Server systems. In a webinar, consultant Koen Verbeeck offered ...',\n",
       " \"SQL Server databases can be moved to the Azure cloud in several different ways. Here's what you'll get from each of the options ...\",\n",
       " \"In this book excerpt, you'll learn LEFT OUTER JOIN vs. RIGHT OUTER JOIN techniques and find various examples for creating SQL ...\",\n",
       " 'All Rights Reserved, \\nCopyright 2010 - 2019, TechTarget\\n',\n",
       " 'Worldwide Sites\\n',\n",
       " 'Worldwide Contacts',\n",
       " \"If you don't find your country/region in the list, see our worldwide contacts list.\\n\",\n",
       " 'SAS Sites',\n",
       " '\\xa0',\n",
       " 'While natural language processing isn’t a new science, the technology is rapidly advancing thanks to an increased interest in human-to-machine communications, plus an availability of big data, powerful computing and enhanced algorithms.\\xa0',\n",
       " 'As a human, you may speak and write in English, Spanish or Chinese. But a computer’s native language – known as machine code or machine language – is largely incomprehensible to most people. At your device’s lowest levels, communication occurs not with words but through millions of zeros and ones that produce logical actions.\\xa0',\n",
       " 'Indeed, programmers used punch cards to communicate with the first computers 70 years ago. This manual and arduous process was understood by a relatively small number of people. Now you can say, “Alexa, I like this song,” and a device playing music in your home will lower the volume and reply, “OK. Rating saved,” in a humanlike voice. Then it adapts its algorithm to play that song – and others like it – the next time you listen to that music station.\\xa0',\n",
       " 'Let’s take a closer look at that interaction. Your device activated when it heard you speak, understood the unspoken intent in the comment, executed an action and provided feedback in a well-formed English sentence, all in the space of about five seconds. The complete interaction was made possible by NLP, along with other AI elements such as machine learning and deep learning.\\xa0',\n",
       " '\\xa0',\n",
       " 'Royal Bank of Scotland uses text analytics, an NLP technique, to extract important trends from customer feedback in many forms. The company analyzes data from emails, surveys and call center conversations to identify the root cause of customer dissatisfaction and implement improvements. Watch the video to learn more about analytics transforming customer relationships.\\n',\n",
       " '\\xa0',\n",
       " 'Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks. For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important.\\xa0',\n",
       " 'Today’s machines can analyze more language-based data than humans, without fatigue and in a consistent, unbiased way. Considering the staggering amount of unstructured data that’s generated every day, from medical records to social media, automation will be critical to fully analyze text and speech data efficiently.',\n",
       " 'Human language is astoundingly complex and diverse. We express ourselves in infinite ways, both verbally and in writing. Not only are there hundreds of languages and dialects, but within each language is a unique set of grammar and syntax rules, terms and slang. When we write, we often misspell or abbreviate words, or omit punctuation. When we speak, we have regional accents, and we mumble, stutter and borrow terms from other languages.\\xa0',\n",
       " 'While supervised and unsupervised learning, and specifically deep learning, are now widely used for modeling human language, there’s also a need for syntactic and semantic understanding and domain expertise that are not necessarily present in these machine learning approaches. NLP is important because it helps resolve ambiguity in language and adds useful numeric structure to the data for many downstream applications, such as\\xa0speech\\xa0recognition or text analytics.\\xa0',\n",
       " 'Learn more about natural language processing in many industries',\n",
       " 'How are organizations around the world using artificial intelligence and NLP? What are the adoption rates and future plans for these technologies? What are the budgets and deployment plans? And what business problems are being solved with NLP algorithms? Find out in this report from TDWI.',\n",
       " 'People’s thoughts, research, opinions, facts and feedback transfer into the digital world through social media feeds, legal case files, electronic health records, contact center logs, warranty claims and more. Natural language processing uncovers the insights hidden in the word streams.',\n",
       " 'Text analytics is a type of natural language processing that turns text into data for analysis. Learn how organizations in banking, health care and life sciences, manufacturing and government are using text analytics to drive better customer experiences, reduce fraud and improve society.',\n",
       " 'Breaking down the elemental pieces of language',\n",
       " 'Natural language processing includes many different techniques for interpreting human language, ranging from statistical and machine learning methods to rules-based and algorithmic approaches. We need a broad array of approaches because the text- and voice-based data varies widely, as do the practical applications.\\xa0',\n",
       " 'Basic NLP tasks include tokenization and parsing, lemmatization/stemming, part-of-speech tagging, language detection and identification of semantic relationships. If you ever diagramed sentences in grade school, you’ve done these tasks manually before.\\xa0',\n",
       " 'In general terms, NLP tasks break down language into shorter, elemental pieces, try to understand relationships between the pieces and explore how the pieces work together to create meaning.',\n",
       " 'These underlying tasks are often used in higher-level NLP capabilities, such as:',\n",
       " '\\nIn all these cases, the overarching goal is to take raw language input and use linguistics and algorithms to transform or enrich the text in such a way that it delivers greater value.\\xa0',\n",
       " 'SAS®\\xa0Visual Text Analytics',\n",
       " 'How can you find answers in large volumes of textual data? By combining machine learning with natural language processing and text analytics. Find out how your unstructured data can be analyzed to identify issues, evaluate sentiment, detect emerging trends and spot hidden opportunities.\\n',\n",
       " 'NLP and text analytics',\n",
       " 'Natural language processing goes hand in hand with text analytics, which counts, groups and categorizes words to extract structure and meaning from large volumes of content. Text analytics is used to explore textual content and derive new variables from raw text that may be visualized, filtered, or used as inputs to predictive models or other statistical methods.',\n",
       " 'NLP and text analytics are used together for many applications, including:',\n",
       " 'Everyday NLP examples\\xa0',\n",
       " 'There are many common and practical applications of NLP in our everyday lives. Beyond conversing with virtual assistants like Alexa or Siri, here are a few more examples:\\xa0',\n",
       " 'A subfield of NLP called natural language understanding (NLU) has begun to rise in popularity because of its potential in cognitive and AI applications. NLU goes beyond the structural understanding of language to interpret intent, resolve context and word ambiguity, and even generate well-formed human language on its own. NLU algorithms must tackle the extremely complex problem of semantic interpretation – that is, understanding the intended meaning of spoken or written language, with all the subtleties, context and inferences that we humans are able to comprehend.',\n",
       " 'The evolution of NLP toward NLU has a lot of important implications for businesses and consumers alike.\\xa0Imagine the power of an algorithm that can understand the meaning and nuance of human language in many contexts, from medicine to law to the classroom. As the volumes of unstructured information continue to grow exponentially, we will benefit from computers’ tireless ability to help us make sense of it all.\\xa0',\n",
       " 'Connect',\n",
       " 'Customer Support',\n",
       " 'Insights On',\n",
       " 'Quick Links',\n",
       " 'Privacy Statement | Terms of Use | © 2019 SAS Institute Inc. All Rights Reserved.\\n',\n",
       " '\\nBack to Top\\n',\n",
       " 'Everything we express (either verbally or in written) carries huge amounts of information. The topic we choose, our tone, our selection of words, everything adds some type of information that can be interpreted and value extracted from it. In theory, we can understand and even predict human behaviour using that information.',\n",
       " 'But there is a problem: one person may generate hundreds or thousands of words in a declaration, each sentence with its corresponding complexity. If you want to scale and analyze several hundreds, thousands or millions of people or declarations in a given geography, then the situation is unmanageable.',\n",
       " 'Data generated from conversations, declarations or even tweets are examples of unstructured data. Unstructured data doesn’t fit neatly into the traditional row and column structure of relational databases, and represent the vast majority of data available in the actual world. It is messy and hard to manipulate. Nevertheless, thanks to the advances in disciplines like machine learning a big revolution is going on regarding this topic. Nowadays it is no longer about trying to interpret a text or speech based on its keywords (the old fashioned mechanical way), but about understanding the meaning behind those words (the cognitive way). This way it is possible to detect figures of speech like irony, or even perform sentiment analysis.',\n",
       " 'Natural Language Processing or NLP is a field of Artificial Intelligence that gives the machines the ability to read, understand and derive meaning from human languages.',\n",
       " 'It is a discipline that focuses on the interaction between data science and human language, and is scaling to lots of industries. Today NLP is booming thanks to the huge improvements in the access to data and the increase in computational power, which are allowing practitioners to achieve meaningful results in areas like healthcare, media, finance and human resources, among others.',\n",
       " 'In simple terms, NLP represents the automatic handling of natural human language like speech or text, and although the concept itself is fascinating, the real value behind this technology comes from the use cases.',\n",
       " 'NLP can help you with lots of tasks and the fields of application just seem to increase on a daily basis. Let’s mention some examples:',\n",
       " 'NLP is particularly booming in the healthcare industry. This technology is improving care delivery, disease diagnosis and bringing costs down while healthcare organizations are going through a growing adoption of electronic health records. The fact that clinical documentation can be improved means that patients can be better understood and benefited through better healthcare. The goal should be to optimize their experience, and several organizations are already working on this.',\n",
       " 'Companies like Winterlight Labs are making huge improvements in the treatment of Alzheimer’s disease by monitoring cognitive impairment through speech and they can also support clinical trials and studies for a wide range of central nervous system disorders. Following a similar approach, Stanford University developed Woebot, a chatbot therapist with the aim of helping people with anxiety and other disorders.',\n",
       " 'But serious controversy is around the subject. A couple of years ago Microsoft demonstrated that by analyzing large samples of search engine queries, they could identify internet users who were suffering from pancreatic cancer even before they have received a diagnosis of the disease. How would users react to such diagnosis? And what would happen if you were tested as a false positive? (meaning that you can be diagnosed with the disease even though you don’t have it). This recalls the case of Google Flu Trends which in 2009 was announced as being able to predict influenza but later on vanished due to its low accuracy and inability to meet its projected rates.',\n",
       " 'NLP may be the key to an effective clinical support in the future, but there are still many challenges to face in the short term.',\n",
       " 'The main drawbacks we face these days with NLP relate to the fact that language is very tricky. The process of understanding and manipulating language is extremely complex, and for this reason it is common to use different techniques to handle different challenges before binding everything together. Programming languages like Python or R are highly used to perform these techniques, but before diving into code lines (that will be the topic of a different article), it’s important to understand the concepts beneath them. Let’s summarize and explain some of the most frequently used algorithms in NLP when defining the vocabulary of terms:',\n",
       " 'Is a commonly used model that allows you to count all words in a piece of text. Basically it creates an occurrence matrix for the sentence or document, disregarding grammar and word order. These word frequencies or occurrences are then used as features for training a classifier.',\n",
       " 'To bring a short example I took the first sentence of the song “Across the Universe” from The Beatles:',\n",
       " 'Words are flowing out like endless rain into a paper cup,',\n",
       " 'They slither while they pass, they slip away across the universe',\n",
       " 'Now let’s count the words:',\n",
       " 'This approach may reflect several downsides like the absence of semantic meaning and context, and the facts that stop words (like “the” or “a”) add noise to the analysis and some words are not weighted accordingly (“universe” weights less than the word “they”).',\n",
       " 'To solve this problem, one approach is to rescale the frequency of words by how often they appear in all texts (not just the one we are analyzing) so that the scores for frequent words like “the”, that are also frequent across other texts, get penalized. This approach to scoring is called “Term Frequency — Inverse Document Frequency” (TFIDF), and improves the bag of words by weights. Through TFIDF frequent terms in the text are “rewarded” (like the word “they” in our example), but they also get “punished” if those terms are frequent in other texts we include in the algorithm too. On the contrary, this method highlights and “rewards” unique or rare terms considering all texts. Nevertheless, this approach still has no context nor semantics.',\n",
       " 'Is the process of segmenting running text into sentences and words. In essence, it’s the task of cutting a text into pieces called tokens, and at the same time throwing away certain characters, such as punctuation. Following our example, the result of tokenization would be:',\n",
       " 'Pretty simple, right? Well, although it may seem quite basic in this case and also in languages like English that separate words by a blank space (called segmented languages) not all languages behave the same, and if you think about it, blank spaces alone are not sufficient enough even for English to perform proper tokenizations. Splitting on blank spaces may break up what should be considered as one token, as in the case of certain names (e.g. San Francisco or New York) or borrowed foreign phrases (e.g. laissez faire).',\n",
       " 'Tokenization can remove punctuation too, easing the path to a proper word segmentation but also triggering possible complications. In the case of periods that follow abbreviation (e.g. dr.), the period following that abbreviation should be considered as part of the same token and not be removed.',\n",
       " 'The tokenization process can be particularly problematic when dealing with biomedical text domains which contain lots of hyphens, parentheses, and other punctuation marks.',\n",
       " 'For deeper details on tokenization, you can find a great explanation in this article.',\n",
       " 'Includes getting rid of common language articles, pronouns and prepositions such as “and”, “the” or “to” in English. In this process some very common words that appear to provide little or no value to the NLP objective are filtered and excluded from the text to be processed, hence removing widespread and frequent terms that are not informative about the corresponding text.',\n",
       " 'Stop words can be safely ignored by carrying out a lookup in a pre-defined list of keywords, freeing up database space and improving processing time.',\n",
       " 'There is no universal list of stop words. These can be pre-selected or built from scratch. A potential approach is to begin by adopting pre-defined stop words and add words to the list later on. Nevertheless it seems that the general trend over the past time has been to go from the use of large standard stop word lists to the use of no lists at all.',\n",
       " 'The thing is stop words removal can wipe out relevant information and modify the context in a given sentence. For example, if we are performing a sentiment analysis we might throw our algorithm off track if we remove a stop word like “not”. Under these conditions, you might select a minimal stop word list and add additional terms depending on your specific objective.',\n",
       " 'Refers to the process of slicing the end or the beginning of words with the intention of removing affixes (lexical additions to the root of the word).',\n",
       " 'Affixes that are attached at the beginning of the word are called prefixes (e.g. “astro” in the word “astrobiology”) and the ones attached at the end of the word are called suffixes (e.g. “ful” in the word “helpful”).',\n",
       " 'The problem is that affixes can create or expand new forms of the same word (called inflectional affixes), or even create new words themselves (called derivational affixes). In English, prefixes are always derivational (the affix creates a new word as in the example of the prefix “eco” in the word “ecosystem”), but suffixes can be derivational (the affix creates a new word as in the example of the suffix “ist” in the word “guitarist”) or inflectional (the affix creates a new form of word as in the example of the suffix “er” in the word “faster”).',\n",
       " 'Ok, so how can we tell the difference and chop the right bit?',\n",
       " 'A possible approach is to consider a list of common affixes and rules (Python and R languages have different libraries containing affixes and methods) and perform stemming based on them, but of course this approach presents limitations. Since stemmers use algorithmics approaches, the result of the stemming process may not be an actual word or even change the word (and sentence) meaning. To offset this effect you can edit those predefined methods by adding or removing affixes and rules, but you must consider that you might be improving the performance in one area while producing a degradation in another one. Always look at the whole picture and test your model’s performance.',\n",
       " 'So if stemming has serious limitations, why do we use it? First of all, it can be used to correct spelling errors from the tokens. Stemmers are simple to use and run very fast (they perform simple operations on a string), and if speed and performance are important in the NLP model, then stemming is certainly the way to go. Remember, we use it with the objective of improving our performance, not as a grammar exercise.',\n",
       " 'Has the objective of reducing a word to its base form and grouping together different forms of the same word. For example, verbs in past tense are changed into present (e.g. “went” is changed to “go”) and synonyms are unified (e.g. “best” is changed to “good”), hence standardizing words with similar meaning to their root. Although it seems closely related to the stemming process, lemmatization uses a different approach to reach the root forms of words.',\n",
       " 'Lemmatization resolves words to their dictionary form (known as lemma) for which it requires detailed dictionaries in which the algorithm can look into and link words to their corresponding lemmas.',\n",
       " 'For example, the words “running”, “runs” and “ran” are all forms of the word “run”, so “run” is the lemma of all the previous words.',\n",
       " 'Lemmatization also takes into consideration the context of the word in order to solve other problems like disambiguation, which means it can discriminate between identical words that have different meanings depending on the specific context. Think about words like “bat” (which can correspond to the animal or to the metal/wooden club used in baseball) or “bank” (corresponding to the financial institution or to the land alongside a body of water). By providing a part-of-speech parameter to a word ( whether it is a noun, a verb, and so on) it’s possible to define a role for that word in the sentence and remove disambiguation.',\n",
       " 'As you might already pictured, lemmatization is a much more resource-intensive task than performing a stemming process. At the same time, since it requires more knowledge about the language structure than a stemming approach, it demands more computational power than setting up or adapting a stemming algorithm.',\n",
       " 'Is as a method for uncovering hidden structures in sets of texts or documents. In essence it clusters texts to discover latent topics based on their contents, processing individual words and assigning them values based on their distribution. This technique is based on the assumptions that each document consists of a mixture of topics and that each topic consists of a set of words, which means that if we can spot these hidden topics we can unlock the meaning of our texts.',\n",
       " 'From the universe of topic modelling techniques, Latent Dirichlet Allocation (LDA) is probably the most commonly used. This relatively new algorithm (invented less than 20 years ago) works as an unsupervised learning method that discovers different topics underlying a collection of documents. In unsupervised learning methods like this one, there is no output variable to guide the learning process and data is explored by algorithms to find patterns. To be more specific, LDA finds groups of related words by:',\n",
       " 'Unlike other clustering algorithms like K-means that perform hard clustering (where topics are disjointed), LDA assigns each document to a mixture of topics, which means that each document can be described by one or more topics (e.g. Document 1 is described by 70% of topic A, 20% of topic B and 10% of topic C) and reflect more realistic results.',\n",
       " 'Topic modeling is extremely useful for classifying texts, building recommender systems (e.g. to recommend you books based on your past readings) or even detecting trends in online publications.',\n",
       " 'At the moment NLP is battling to detect nuances in language meaning, whether due to lack of context, spelling errors or dialectal differences.',\n",
       " 'On March 2016 Microsoft launched Tay, an Artificial Intelligence (AI) chatbot released on Twitter as a NLP experiment. The idea was that as more users conversed with Tay, the smarter it would get. Well, the result was that after 16 hours Tay had to be removed due to its racist and abusive comments:',\n",
       " 'Microsoft learnt from its own experience and some months later released Zo, its second generation English-language chatbot that won’t be caught making the same mistakes as its predecessor. Zo uses a combination of innovative approaches to recognize and generate conversation, and other companies are exploring with bots that can remember details specific to an individual conversation.',\n",
       " 'Although the future looks extremely challenging and full of threats for NLP, the discipline is developing at a very fast pace (probably like never before) and we are likely to reach a level of advancement in the coming years that will make complex applications look possible.',\n",
       " 'Thanks Jesús del Valle , Jannis Busch and Sabrina Steinert for your valuable inputs',\n",
       " 'Interested in these topics? Follow me on Linkedin or Twitter',\n",
       " 'Written by',\n",
       " 'Deploying AI at Scale',\n",
       " '',\n",
       " 'The field of study that focuses on the interactions between human language and computers is called Natural Language Processing, or NLP for short. It sits at the intersection of computer science, artificial intelligence, and computational linguistics (Wikipedia).',\n",
       " '“Nat\\xadur\\xadal Lan\\xadguage Pro\\xadcessing is a field that cov\\xaders com\\xadputer un\\xadder\\xadstand\\xading and ma\\xadnip\\xadu\\xadla\\xadtion of hu\\xadman lan\\xadguage, and it’s ripe with pos\\xadsib\\xadil\\xadit\\xadies for news\\xadgath\\xader\\xading,” Anthony Pesce\\xa0said in Natural Language Processing in the kitchen.\\xa0“You usu\\xadally hear about it in the con\\xadtext of ana\\xadlyz\\xading large pools of legis\\xadla\\xadtion or other doc\\xadu\\xadment sets, at\\xadtempt\\xading to dis\\xadcov\\xader pat\\xadterns or root out cor\\xadrup\\xadtion.”',\n",
       " '',\n",
       " 'NLP is a way for computers to analyze, understand, and derive meaning from human language in a smart and useful way. By utilizing NLP, developers can organize and structure knowledge to perform tasks such as automatic summarization, translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation.',\n",
       " '“Apart from common word processor operations that treat text like a mere sequence of symbols, NLP considers the hierarchical structure of language: several words make a phrase, several phrases make a sentence and, ultimately, sentences convey ideas,” John Rehling,\\xa0an NLP expert at Meltwater Group, said in\\xa0How Natural Language Processing Helps Uncover Social Media Sentiment. “By analyzing language for its meaning, NLP systems have long filled useful roles, such as correcting grammar, converting speech to text and automatically translating between languages.”',\n",
       " 'NLP is used to analyze text, allowing machines to understand how human’s speak. This human-computer interaction enables real-world applications like automatic text summarization, sentiment analysis, topic extraction, named entity recognition, parts-of-speech tagging, relationship extraction, stemming, and more. NLP is commonly used for text mining, machine translation, and automated question answering.',\n",
       " 'NLP is characterized as a difficult problem in computer science. Human language is rarely precise, or plainly spoken. To understand human language is to understand not only the words, but the concepts and how they’re linked together to create meaning. Despite language being one of the easiest things for the human mind to learn, the ambiguity of language is what makes natural language processing a difficult problem for computers to master.',\n",
       " 'NLP algorithms have a variety of uses. Basically, they allow developers to create a software that understands human language. Due to the complicated nature of human language, NLP can be difficult to learn and implement correctly. However, with the knowledge gained from this article, you will be better equipped to use NLP successfully. Some of the projects developers can use NLP algorithms for are:',\n",
       " 'These libraries provide the algorithmic building blocks of NLP in real-world applications. Algorithmia provides a free API endpoint for many of these algorithms, without ever having to setup or provision servers and infrastructure.',\n",
       " 'NLP algorithms can be extremely helpful for web developers, providing them with the turnkey tools needed to create advanced applications, and prototypes.',\n",
       " 'NLP algorithms are typically based on machine learning algorithms. Instead of hand-coding large sets of rules, NLP can rely on machine learning to automatically learn these rules by analyzing a set of examples (i.e. a large corpus, like a book, down to a collection of sentences), and making a statical inference. In general, the more data analyzed, the more accurate the model will be.',\n",
       " 'Social media analysis is a great example of NLP use. Brands track conversations online to understand what customers are saying, and glean insight into user behavior.',\n",
       " '“One of the most compelling ways NLP offers valuable intelligence is by tracking sentiment — the tone of a written message (tweet, Facebook update, etc.) — and tag that text as positive, negative or neutral,” Rehling said.',\n",
       " 'Build your own social media monitoring tool',\n",
       " 'Similarly, Facebook uses NLP to track trending topics and popular hashtags.',\n",
       " '“Hashtags and topics are two different ways of grouping and participating in conversations,” Chris Struhar, a software engineer on News Feed, said in How Facebook Built Trending Topics With Natural Language Processing. “So don’t think Facebook won’t recognize a string as a topic without a hashtag in front of it. Rather, it’s all about NLP: natural language processing. Ain’t nothing natural about a hashtag, so Facebook instead parses strings and figures out which strings are referring to nodes — objects in the network. We look at the text, and we try to understand what that was about.”',\n",
       " 'It’s not just social media that can use NLP to it’s benefit. Publishers are hoping to use NLP to improve the quality of their online communities by leveraging technology to\\xa0“auto-filter the offensive comments on news sites to save moderators from what can be an ‘exhausting process’,” Francis Tseng said in\\xa0Prototype winner using ‘natural language processing’ to solve journalism’s commenting problem.',\n",
       " 'Other practical uses of NLP include monitoring for malicious digital attacks, such as phishing, or detecting when somebody is lying.',\n",
       " 'Use NLP to build your own RSS reader',\n",
       " 'You can build a machine learning RSS reader in less than 30-minutes using the follow algorithms:',\n",
       " 'If you’re interested in learning more, this free introductory course from Stanford University will help you will\\xa0learn the fundamentals of natural language processing, and how you can use it to solve practical problems.',\n",
       " '',\n",
       " 'Once you’ve gotten the fundamentals down, apply what you’ve learned using Python and NLTK, the most popular framework for Python NLP.',\n",
       " '',\n",
       " '',\n",
       " 'var dd_offset_from_content = 60;var dd_top_offset_from_content = 0;var dd_override_start_anchor_id = \"\";var dd_override_top_offset = \"0\";',\n",
       " 'More Posts  - Website ',\n",
       " 'Follow Me:',\n",
       " 'Algorithmia AI Cloud is built to scale. You write the code and compose the workflow. We take care of the rest.',\n",
       " 'Natural Language Processing (NLP) refers to AI method of communicating with an intelligent systems using a natural language such as English.',\n",
       " 'Processing of Natural Language is required when you want an intelligent system like robot to perform as per your instructions, when you want to hear decision from a dialogue based clinical expert system, etc.',\n",
       " 'The field of NLP involves making computers to perform useful tasks with the natural languages humans use. The input and output of an NLP system can be −',\n",
       " 'There are two components of NLP as given −',\n",
       " 'Understanding involves the following tasks −',\n",
       " 'It is the process of producing meaningful phrases and sentences in the form of natural language from some internal representation.',\n",
       " 'It involves −',\n",
       " 'Text planning − It includes retrieving the relevant content from knowledge base.',\n",
       " 'Sentence planning − It includes choosing required words, forming meaningful phrases, setting tone of the sentence.',\n",
       " 'Text Realization − It is mapping sentence plan into sentence structure.',\n",
       " 'The NLU is harder than NLG.',\n",
       " 'NL has an extremely rich form and structure.',\n",
       " 'It is very ambiguous. There can be different levels of ambiguity −',\n",
       " 'Lexical ambiguity − It is at very primitive level such as word-level.',\n",
       " 'For example, treating the word “board” as noun or verb?',\n",
       " 'Syntax Level ambiguity − A sentence can be parsed in different ways.',\n",
       " 'For example, “He lifted the beetle with red cap.” − Did he use cap to lift the beetle or he lifted a beetle that had red cap?',\n",
       " 'Referential ambiguity − Referring to something using pronouns. For example, Rima went to Gauri. She said, “I am tired.” − Exactly who is tired?',\n",
       " 'One input can mean different meanings.',\n",
       " 'Many inputs can mean the same thing.',\n",
       " 'Phonology − It is study of organizing sound systematically.',\n",
       " 'Morphology − It is a study of construction of words from primitive meaningful units.',\n",
       " 'Morpheme − It is primitive unit of meaning in a language.',\n",
       " 'Syntax − It refers to arranging words to make a sentence. It also involves determining the structural role of words in the sentence and in phrases.',\n",
       " 'Semantics − It is concerned with the meaning of words and how to combine words into meaningful phrases and sentences.',\n",
       " 'Pragmatics − It deals with using and understanding sentences in different situations and how the interpretation of the sentence is affected.',\n",
       " 'Discourse − It deals with how the immediately preceding sentence can affect the interpretation of the next sentence.',\n",
       " 'World Knowledge − It includes the general knowledge about the world.',\n",
       " 'There are general five steps −',\n",
       " 'Lexical Analysis − It involves identifying and analyzing the structure of words. Lexicon of a language means the collection of words and phrases in a language. Lexical analysis is dividing the whole chunk of txt into paragraphs, sentences, and words.',\n",
       " 'Syntactic Analysis (Parsing) − It involves analysis of words in the sentence for grammar and arranging words in a manner that shows the relationship among the words. The sentence such as “The school goes to boy” is rejected by English syntactic analyzer.',\n",
       " 'Semantic Analysis − It draws the exact meaning or the dictionary meaning from the text. The text is checked for meaningfulness. It is done by mapping syntactic structures and objects in the task domain. The semantic analyzer disregards sentence such as “hot ice-cream”.',\n",
       " 'Discourse Integration − The meaning of any sentence depends upon the meaning of the sentence just before it. In addition, it also brings about the meaning of immediately succeeding sentence.',\n",
       " 'Pragmatic Analysis − During this, what was said is re-interpreted on what it actually meant. It involves deriving those aspects of language which require real world knowledge.',\n",
       " 'There are a number of algorithms researchers have developed for syntactic analysis, but we consider only the following simple methods −',\n",
       " 'Let us see them in detail −',\n",
       " 'It is the grammar that consists rules with a single symbol on the left-hand side of the rewrite rules. Let us create grammar to parse a sentence −',\n",
       " '“The bird pecks the grains”',\n",
       " 'Articles (DET) − a | an | the',\n",
       " 'Nouns − bird | birds | grain | grains',\n",
       " 'Noun Phrase (NP) − Article &plus; Noun | Article &plus; Adjective &plus; Noun',\n",
       " '= DET N | DET ADJ N',\n",
       " 'Verbs − pecks | pecking | pecked',\n",
       " 'Verb Phrase (VP) − NP V | V NP',\n",
       " 'Adjectives (ADJ) − beautiful | small | chirping',\n",
       " 'The parse tree breaks down the sentence into structured parts so that the computer can easily understand and process it. In order for the parsing algorithm to construct this parse tree, a set of rewrite rules, which describe what tree structures are legal, need to be constructed.',\n",
       " 'These rules say that a certain symbol may be expanded in the tree by a sequence of other symbols. According to first order logic rule, if there are two strings Noun Phrase (NP) and Verb Phrase (VP), then the string combined by NP followed by VP is a sentence. The rewrite rules for the sentence are as follows −',\n",
       " 'S → NP VP',\n",
       " 'NP → DET N | DET ADJ N',\n",
       " 'VP → V NP',\n",
       " 'Lexocon −',\n",
       " 'DET → a | the',\n",
       " 'ADJ → beautiful | perching',\n",
       " 'N → bird | birds | grain | grains',\n",
       " 'V → peck | pecks | pecking',\n",
       " 'The parse tree can be created as shown −',\n",
       " 'Now consider the above rewrite rules. Since V can be replaced by both, \"peck\" or \"pecks\",\\nsentences such as \"The bird peck the grains\" can be wrongly permitted. i. e. the subject-verb\\nagreement error is approved as correct.',\n",
       " 'Merit − The simplest style of grammar, therefore widely used one.',\n",
       " 'Demerits −',\n",
       " 'They are not highly precise. For example, “The grains peck the bird”, is a syntactically correct according to parser, but even if it makes no sense, parser takes it as a correct sentence.',\n",
       " 'To bring out high precision, multiple sets of grammar need to be prepared. It may require a completely different sets of rules for parsing singular and plural variations, passive sentences, etc., which can lead to creation of huge set of rules that are unmanageable.',\n",
       " 'Here, the parser starts with the S symbol and attempts to rewrite it into a sequence of terminal symbols that matches the classes of the words in the input sentence until it consists entirely of terminal symbols.',\n",
       " 'These are then checked with the input sentence to see if it matched. If not, the process is started over again with a different set of rules. This is repeated until a specific rule is found which describes the structure of the sentence.',\n",
       " 'Merit − It is simple to implement.',\n",
       " 'Demerits −',\n",
       " 'This course is part of the Advanced Machine Learning Specialization',\n",
       " 'Offered By',\n",
       " 'This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few. Upon completing, you will be able to recognize NLP tasks in your day-to-day work, propose approaches, and judge what techniques are likely to work well.  The final project is devoted to one of the most hot topics in today’s NLP. You will build your own conversational chat-bot that will assist with search on StackOverflow website. The project will be based on practical assignments of the course, that will give you hands-on experience with such tasks as text classification, named entities recognition, and duplicates detection. \\n\\nThroughout the lectures, we will aim at finding a balance between traditional and deep learning techniques in NLP and cover them in parallel. For example, we will discuss word alignment models in machine translation and see how similar it is to attention mechanism in encoder-decoder neural networks. Core techniques are not treated as black boxes. On the contrary, you will get in-depth understanding of what’s happening inside. To succeed in that, we expect your familiarity with the basics of linear algebra and probability theory, machine learning setup, and deep neural networks. Some materials are based on one-month-old papers and introduce you to the very state-of-the-art in NLP research.\\n\\nDo you have technical problems? Write to us: coursera@hse.ru',\n",
       " 'In this module we will have two parts: first, a broad overview of NLP area and our course goals, and second, a text classification task. It is probably the most popular task that you would deal with in real life. It could be news flows classification, sentiment analysis, spam filtering, etc. You will learn how to go from raw texts to predicted classes both with traditional methods (e.g. linear classifiers) and deep learning techniques (e.g. Convolutional Neural Nets).',\n",
       " 'In this module we will treat texts as sequences of words. You will learn how to predict next words given some previous words. This task is called language modeling and it is used for suggests in search, machine translation, chat-bots, etc. Also you will learn how to predict a sequence of tags for a sequence of words. It could be used to determine part-of-speech tags, named entities or any other tags, e.g. ORIG and DEST in \"flights from Moscow to Zurich\" query. We will cover methods based on probabilistic graphical models and deep learning.',\n",
       " 'This module is devoted to a higher abstraction for texts: we will learn vectors that represent meanings. First, we will discuss traditional models of distributional semantics. They are based on a very intuitive idea: \"you shall know the word by the company it keeps\". Second, we will cover modern tools for word and sentence embeddings, such as word2vec, FastText, StarSpace, etc. Finally, we will discuss how to embed the whole documents with topic models and how these models can be used for search and data exploration.',\n",
       " 'Nearly any task in NLP can be formulates as a sequence to sequence task: machine translation, summarization, question answering, and many more. In this module we will learn a general encoder-decoder-attention architecture that can be used to solve them. We will cover machine translation in more details and you will see how attention technique resembles word alignment task in traditional pipeline.',\n",
       " 'This week we will overview so-called task-oriented dialog systems like Apple Siri or Amazon Alexa. We will look in details at main building blocks of such systems namely Natural Language Understanding (NLU) and Dialog Manager (DM). We hope this week will encourage you to build your own dialog system as a final project!',\n",
       " 'Great thanks to this amazing course! I learned a lot on state-to-art natural language processing techniques! Really like your awesome programming assignments! See you HSE guys in next class!',\n",
       " 'I like this course very much. It is a good introduction for NLP. But if you want to know more about the NLP, you need to search and read a lot of posts during the learning process.',\n",
       " 'When will I have access to the lectures and assignments?',\n",
       " 'Once you enroll for a Certificate, you’ll have access to all videos, quizzes, and programming assignments (if applicable). Peer review assignments can only be submitted and reviewed once your session has begun. If you choose to explore the course without purchasing, you may not be able to access certain assignments.',\n",
       " 'What will I get if I subscribe to this Specialization?',\n",
       " 'When you enroll in the course, you get access to all of the courses in the Specialization, and you earn a certificate when you complete the work. Your electronic Certificate will be added to your Accomplishments page - from there, you can print your Certificate or add it to your LinkedIn profile.  If you only want to read and view the course content, you can audit the course for free.',\n",
       " 'What is the refund policy?',\n",
       " 'Is financial aid available?',\n",
       " 'More questions? Visit the Learner Help Center.',\n",
       " 'This article is part of an on-going series on NLP: Part 1, Part 2, Part 3, Part 4. You can also read a reader-translated version of this article in 普通话.',\n",
       " 'Giant update: I’ve written a new book based on these articles! It not only expands and updates all my articles, but it has tons of brand new content and lots of hands-on coding projects. Check it out now!',\n",
       " 'Computers are great at working with structured data like spreadsheets and database tables. But us humans usually communicate in words, not in tables. That’s unfortunate for computers.',\n",
       " 'A lot of information in the world is unstructured — raw text in English or another human language. How can we get a computer to understand unstructured text and extract data from it?',\n",
       " 'Natural Language Processing, or NLP, is the sub-field of AI that is focused on enabling computers to understand and process human languages. Let’s check out how NLP works and learn how to write programs that can extract information out of raw text using Python!',\n",
       " 'Note: If you don’t care how NLP works and just want to cut and paste some code, skip way down to the section called “Coding the NLP Pipeline in Python”.',\n",
       " 'As long as computers have been around, programmers have been trying to write programs that understand languages like English. The reason is pretty obvious — humans have been writing things down for thousands of years and it would be really helpful if a computer could read and understand all that data.',\n",
       " 'Computers can’t yet truly understand English in the way that humans do — but they can already do a lot! In certain limited areas, what you can do with NLP already seems like magic. You might be able to save a lot of time by applying NLP techniques to your own projects.',\n",
       " 'And even better, the latest advances in NLP are easily accessible through open source Python libraries like spaCy, textacy, and neuralcoref. What you can do with just a few lines of python is amazing.',\n",
       " 'The process of reading and understanding English is very complex — and that’s not even considering that English doesn’t follow logical and consistent rules. For example, what does this news headline mean?',\n",
       " '“Environmental regulators grill business owner over illegal coal fires.”',\n",
       " 'Are the regulators questioning a business owner about burning coal illegally? Or are the regulators literally cooking the business owner? As you can see, parsing English with a computer is going to be complicated.',\n",
       " 'Doing anything complicated in machine learning usually means building a pipeline. The idea is to break up your problem into very small pieces and then use machine learning to solve each smaller piece separately. Then by chaining together several machine learning models that feed into each other, you can do very complicated things.',\n",
       " 'And that’s exactly the strategy we are going to use for NLP. We’ll break down the process of understanding English into small chunks and see how each one works.',\n",
       " 'Let’s look at a piece of text from Wikipedia:',\n",
       " 'London is the capital and most populous city of England and the United Kingdom. Standing on the River Thames in the south east of the island of Great Britain, London has been a major settlement for two millennia. It was founded by the Romans, who named it Londinium.',\n",
       " '(Source: Wikipedia article “London”)',\n",
       " 'This paragraph contains several useful facts. It would be great if a computer could read this text and understand that London is a city, London is located in England, London was settled by Romans and so on. But to get there, we have to first teach our computer the most basic concepts of written language and then move up from there.',\n",
       " 'The first step in the pipeline is to break the text apart into separate sentences. That gives us this:',\n",
       " 'We can assume that each sentence in English is a separate thought or idea. It will be a lot easier to write a program to understand a single sentence than to understand a whole paragraph.',\n",
       " 'Coding a Sentence Segmentation model can be as simple as splitting apart sentences whenever you see a punctuation mark. But modern NLP pipelines often use more complex techniques that work even when a document isn’t formatted cleanly.',\n",
       " 'Now that we’ve split our document into sentences, we can process them one at a time. Let’s start with the first sentence from our document:',\n",
       " '“London is the capital and most populous city of England and the United Kingdom.”',\n",
       " 'The next step in our pipeline is to break this sentence into separate words or tokens. This is called tokenization. This is the result:',\n",
       " '“London”, “is”, “ the”, “capital”, “and”, “most”, “populous”, “city”, “of”, “England”, “and”, “the”, “United”, “Kingdom”, “.”',\n",
       " 'Tokenization is easy to do in English. We’ll just split apart words whenever there’s a space between them. And we’ll also treat punctuation marks as separate tokens since punctuation also has meaning.',\n",
       " 'Next, we’ll look at each token and try to guess its part of speech — whether it is a noun, a verb, an adjective and so on. Knowing the role of each word in the sentence will help us start to figure out what the sentence is talking about.',\n",
       " 'We can do this by feeding each word (and some extra words around it for context) into a pre-trained part-of-speech classification model:',\n",
       " 'The part-of-speech model was originally trained by feeding it millions of English sentences with each word’s part of speech already tagged and having it learn to replicate that behavior.',\n",
       " 'Keep in mind that the model is completely based on statistics — it doesn’t actually understand what the words mean in the same way that humans do. It just knows how to guess a part of speech based on similar sentences and words it has seen before.',\n",
       " 'After processing the whole sentence, we’ll have a result like this:',\n",
       " 'With this information, we can already start to glean some very basic meaning. For example, we can see that the nouns in the sentence include “London” and “capital”, so the sentence is probably talking about London.',\n",
       " 'In English (and most languages), words appear in different forms. Look at these two sentences:',\n",
       " 'I had a pony.',\n",
       " 'I had two ponies.',\n",
       " 'Both sentences talk about the noun pony, but they are using different inflections. When working with text in a computer, it is helpful to know the base form of each word so that you know that both sentences are talking about the same concept. Otherwise the strings “pony” and “ponies” look like two totally different words to a computer.',\n",
       " 'In NLP, we call finding this process lemmatization — figuring out the most basic form or lemma of each word in the sentence.',\n",
       " 'The same thing applies to verbs. We can also lemmatize verbs by finding their root, unconjugated form. So “I had two ponies” becomes “I [have] two [pony].”',\n",
       " 'Lemmatization is typically done by having a look-up table of the lemma forms of words based on their part of speech and possibly having some custom rules to handle words that you’ve never seen before.',\n",
       " 'Here’s what our sentence looks like after lemmatization adds in the root form of our verb:',\n",
       " 'The only change we made was turning “is” into “be”.',\n",
       " 'Next, we want to consider the importance of a each word in the sentence. English has a lot of filler words that appear very frequently like “and”, “the”, and “a”. When doing statistics on text, these words introduce a lot of noise since they appear way more frequently than other words. Some NLP pipelines will flag them as stop words —that is, words that you might want to filter out before doing any statistical analysis.',\n",
       " 'Here’s how our sentence looks with the stop words grayed out:',\n",
       " 'Stop words are usually identified by just by checking a hardcoded list of known stop words. But there’s no standard list of stop words that is appropriate for all applications. The list of words to ignore can vary depending on your application.',\n",
       " 'For example if you are building a rock band search engine, you want to make sure you don’t ignore the word “The”. Because not only does the word “The” appear in a lot of band names, there’s a famous 1980’s rock band called The The!',\n",
       " 'The next step is to figure out how all the words in our sentence relate to each other. This is called dependency parsing.',\n",
       " 'The goal is to build a tree that assigns a single parent word to each word in the sentence. The root of the tree will be the main verb in the sentence. Here’s what the beginning of the parse tree will look like for our sentence:',\n",
       " 'But we can go one step further. In addition to identifying the parent word of each word, we can also predict the type of relationship that exists between those two words:',\n",
       " 'This parse tree shows us that the subject of the sentence is the noun “London” and it has a “be” relationship with “capital”. We finally know something useful — London is a capital! And if we followed the complete parse tree for the sentence (beyond what is shown), we would even found out that London is the capital of the United Kingdom.',\n",
       " 'Just like how we predicted parts of speech earlier using a machine learning model, dependency parsing also works by feeding words into a machine learning model and outputting a result. But parsing word dependencies is particularly complex task and would require an entire article to explain in any detail. If you are curious how it works, a great place to start reading is Matthew Honnibal’s excellent article “Parsing English in 500 Lines of Python”.',\n",
       " 'But despite a note from the author in 2015 saying that this approach is now standard, it’s actually out of date and not even used by the author anymore. In 2016, Google released a new dependency parser called Parsey McParseface which outperformed previous benchmarks using a new deep learning approach which quickly spread throughout the industry. Then a year later, they released an even newer model called ParseySaurus which improved things further. In other words, parsing techniques are still an active area of research and constantly changing and improving.',\n",
       " 'It’s also important to remember that many English sentences are ambiguous and just really hard to parse. In those cases, the model will make a guess based on what parsed version of the sentence seems most likely but it’s not perfect and sometimes the model will be embarrassingly wrong. But over time our NLP models will continue to get better at parsing text in a sensible way.',\n",
       " 'Want to try out dependency parsing on your own sentence? There’s a great interactive demo from the spaCy team here.',\n",
       " 'So far, we’ve treated every word in our sentence as a separate entity. But sometimes it makes more sense to group together the words that represent a single idea or thing. We can use the information from the dependency parse tree to automatically group together words that are all talking about the same thing.',\n",
       " 'For example, instead of this:',\n",
       " 'We can group the noun phrases to generate this:',\n",
       " 'Whether or not we do this step depends on our end goal. But it’s often a quick and easy way to simplify the sentence if we don’t need extra detail about which words are adjectives and instead care more about extracting complete ideas.',\n",
       " 'Now that we’ve done all that hard work, we can finally move beyond grade-school grammar and start actually extracting ideas.',\n",
       " 'In our sentence, we have the following nouns:',\n",
       " 'Some of these nouns present real things in the world. For example, “London”, “England” and “United Kingdom” represent physical places on a map. It would be nice to be able to detect that! With that information, we could automatically extract a list of real-world places mentioned in a document using NLP.',\n",
       " 'The goal of Named Entity Recognition, or NER, is to detect and label these nouns with the real-world concepts that they represent. Here’s what our sentence looks like after running each token through our NER tagging model:',\n",
       " 'But NER systems aren’t just doing a simple dictionary lookup. Instead, they are using the context of how a word appears in the sentence and a statistical model to guess which type of noun a word represents. A good NER system can tell the difference between “Brooklyn Decker” the person and the place “Brooklyn” using context clues.',\n",
       " 'Here are just some of the kinds of objects that a typical NER system can tag:',\n",
       " 'NER has tons of uses since it makes it so easy to grab structured data out of text. It’s one of the easiest ways to quickly get value out of an NLP pipeline.',\n",
       " 'Want to try out Named Entity Recognition yourself? There’s another great interactive demo from spaCy here.',\n",
       " 'At this point, we already have a useful representation of our sentence. We know the parts of speech for each word, how the words relate to each other and which words are talking about named entities.',\n",
       " 'However, we still have one big problem. English is full of pronouns — words like he, she, and it. These are shortcuts that we use instead of writing out names over and over in each sentence. Humans can keep track of what these words represent based on context. But our NLP model doesn’t know what pronouns mean because it only examines one sentence at a time.',\n",
       " 'Let’s look at the third sentence in our document:',\n",
       " '“It was founded by the Romans, who named it Londinium.”',\n",
       " 'If we parse this with our NLP pipeline, we’ll know that “it” was founded by Romans. But it’s a lot more useful to know that “London” was founded by Romans.',\n",
       " 'As a human reading this sentence, you can easily figure out that “it” means “London”. The goal of coreference resolution is to figure out this same mapping by tracking pronouns across sentences. We want to figure out all the words that are referring to the same entity.',\n",
       " 'Here’s the result of running coreference resolution on our document for the word “London”:',\n",
       " 'With coreference information combined with the parse tree and named entity information, we should be able to extract a lot of information out of this document!',\n",
       " 'Coreference resolution is one of the most difficult steps in our pipeline to implement. It’s even more difficult than sentence parsing. Recent advances in deep learning have resulted in new approaches that are more accurate, but it isn’t perfect yet. If you want to learn more about how it works, start here.',\n",
       " 'Want to play with co-reference resolution? Check out this great co-reference resolution demo from Hugging Face.',\n",
       " 'Here’s an overview of our complete NLP pipeline:',\n",
       " 'Whew, that’s a lot of steps!',\n",
       " 'Note: Before we continue, it’s worth mentioning that these are the steps in a typical NLP pipeline, but you will skip steps or re-order steps depending on what you want to do and how your NLP library is implemented. For example, some libraries like spaCy do sentence segmentation much later in the pipeline using the results of the dependency parse.',\n",
       " 'So how do we code this pipeline? Thanks to amazing python libraries like spaCy, it’s already done! The steps are all coded and ready for you to use.',\n",
       " 'First, assuming you have Python 3 installed already, you can install spaCy like this:',\n",
       " 'Then the code to run an NLP pipeline on a piece of text looks like this:',\n",
       " 'If you run that, you’ll get a list of named entities and entity types detected in our document:',\n",
       " 'You can look up what each of those entity codes means here.',\n",
       " 'Notice that it makes a mistake on “Londinium” and thinks it is the name of a person instead of a place. This is probably because there was nothing in the training data set similar to that and it made a best guess. Named Entity Detection often requires a little bit of model fine tuning if you are parsing text that has unique or specialized terms like this.',\n",
       " 'Let’s take the idea of detecting entities and twist it around to build a data scrubber. Let’s say you are trying to comply with the new GDPR privacy regulations and you’ve discovered that you have thousands of documents with personally identifiable information in them like people’s names. You’ve been given the task of removing any and all names from your documents.',\n",
       " 'Going through thousands of documents and trying to redact all the names by hand could take years. But with NLP, it’s a breeze. Here’s a simple scrubber that removes all the names it detects:',\n",
       " 'And if you run that, you’ll see that it works as expected:',\n",
       " 'What you can do with spaCy right out of the box is pretty amazing. But you can also use the parsed output from spaCy as the input to more complex data extraction algorithms. There’s a python library called textacy that implements several common data extraction algorithms on top of spaCy. It’s a great starting point.',\n",
       " 'One of the algorithms it implements is called Semi-structured Statement Extraction. We can use it to search the parse tree for simple statements where the subject is “London” and the verb is a form of “be”. That should help us find facts about London.',\n",
       " 'Here’s how that looks in code:',\n",
       " 'And here’s what it prints:',\n",
       " 'Maybe that’s not too impressive. But if you run that same code on the entire London wikipedia article text instead of just three sentences, you’ll get this more impressive result:',\n",
       " 'Now things are getting interesting! That’s a pretty impressive amount of information we’ve collected automatically.',\n",
       " 'For extra credit, try installing the neuralcoref library and adding Coreference Resolution to your pipeline. That will get you a few more facts since it will catch sentences that talk about “it” instead of mentioning “London” directly.',\n",
       " 'By looking through the spaCy docs and textacy docs, you’ll see lots of examples of the ways you can work with parsed text. What we’ve seen so far is just a tiny sample.',\n",
       " 'Here’s another practical example: Imagine that you were building a website that let’s the user view information for every city in the world using the information we extracted in the last example.',\n",
       " 'If you had a search feature on the website, it might be nice to autocomplete common search queries like Google does:',\n",
       " 'But to do this, we need a list of possible completions to suggest to the user. We can use NLP to quickly generate this data.',\n",
       " 'Here’s one way to extract frequently-mentioned noun chunks from a document:',\n",
       " 'If you run that on the London Wikipedia article, you’ll get output like this:',\n",
       " 'This is just a tiny taste of what you can do with NLP. In future posts, we’ll talk about other applications of NLP like Text Classification and how systems like Amazon Alexa parse questions.',\n",
       " 'But until then, install spaCy and start playing around! Or if you aren’t a Python user and end up using a different NLP library, the ideas should all work roughly the same way.',\n",
       " 'This article is part of an on-going series on NLP. You can continue on to Part 2.',\n",
       " 'If you liked this article, consider signing up for my Machine Learning is Fun! newsletter:',\n",
       " 'You can also follow me on Twitter at @ageitgey, email me directly or find me on linkedin. I’d love to hear from you if I can help you or your team with machine learning.',\n",
       " 'Written by',\n",
       " '\\n\\n\\n  Sign in with a different account\\n  \\n\\n\\n\\n  Create account\\n  \\n\\n',\n",
       " '\\n  One Google Account for everything Google\\n']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = [my_tokenizer(s) for s in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA on web data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora import dictionary\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "id2word = corpora.Dictionary(final_text)\n",
    "\n",
    "mycorpus = [id2word.doc2bow(s) for s in final_text]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=mycorpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=42,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.021*\"text\" + 0.021*\"data\" + 0.019*\"model\" + 0.015*\"algorithm\" + '\n",
      "  '0.013*\"tree\" + 0.012*\"parse\" + 0.012*\"based\" + 0.012*\"one\" + 0.011*\"way\" + '\n",
      "  '0.011*\"thing\"'),\n",
      " (1,\n",
      "  '0.018*\"system\" + 0.018*\"want\" + 0.015*\"work\" + 0.015*\"great\" + 0.012*\"idea\" '\n",
      "  '+ 0.011*\"see\" + 0.010*\"using\" + 0.010*\"algorithm\" + 0.010*\"data\" + '\n",
      "  '0.010*\"field\"'),\n",
      " (2,\n",
      "  '0.036*\"nlp\" + 0.025*\"language\" + 0.020*\"learning\" + 0.019*\"machine\" + '\n",
      "  '0.016*\"use\" + 0.014*\"word\" + 0.014*\"sentence\" + 0.013*\"like\" + 0.012*\"task\" '\n",
      "  '+ 0.011*\"english\"'),\n",
      " (3,\n",
      "  '0.031*\"lot\" + 0.029*\"topic\" + 0.019*\"know\" + 0.015*\"...\" + 0.014*\"help\" + '\n",
      "  '0.013*\"find\" + 0.012*\"project\" + 0.009*\"resolution\" + 0.009*\"london\" + '\n",
      "  '0.009*\"right\"'),\n",
      " (4,\n",
      "  '0.028*\"london\" + 0.024*\"get\" + 0.023*\"python\" + 0.018*\"spacy\" + '\n",
      "  '0.017*\"library\" + 0.014*\"http\" + 0.014*\"start\" + 0.012*\"capital\" + '\n",
      "  '0.011*\"course\" + 0.010*\"sheet\"'),\n",
      " (5,\n",
      "  '0.063*\"language\" + 0.045*\"natural\" + 0.032*\"processing\" + 0.021*\"nlp\" + '\n",
      "  '0.019*\"human\" + 0.018*\"data\" + 0.016*\"computer\" + 0.015*\"look\" + '\n",
      "  '0.013*\"linguistics\" + 0.011*\"text\"'),\n",
      " (6,\n",
      "  '0.013*\"break\" + 0.013*\"peck\" + 0.013*\"study\" + 0.012*\"already\" + '\n",
      "  '0.010*\"time\" + 0.010*\"pronoun\" + 0.009*\"includes\" + 0.009*\"wa\" + '\n",
      "  '0.008*\"certain\" + 0.008*\"future\"'),\n",
      " (7,\n",
      "  '0.071*\"word\" + 0.038*\"sentence\" + 0.014*\"meaning\" + 0.012*\"entity\" + '\n",
      "  '0.012*\"noun\" + 0.012*\"form\" + 0.011*\"like\" + 0.009*\"context\" + '\n",
      "  '0.009*\"analysis\" + 0.009*\"named\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lda = lda_model[mycorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.609877562088082\n",
      "\n",
      "Coherence Score:  0.3969295670616164\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(mycorpus)) \n",
    "from gensim.models import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=final_text, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pyLDAvis) (0.33.6)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pyLDAvis) (1.17.3)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pyLDAvis) (1.3.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pyLDAvis) (0.25.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pyLDAvis) (0.14.0)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pyLDAvis) (2.10.3)\n",
      "Collecting numexpr\n",
      "  Downloading https://files.pythonhosted.org/packages/03/a6/f36ea88aee29550dafda4f9db1d547518f24c1a4a364a56e4744ca805c2a/numexpr-2.7.0-cp37-none-win_amd64.whl (90kB)\n",
      "Collecting pytest\n",
      "  Downloading https://files.pythonhosted.org/packages/17/18/8bfa28d47cd71d5155fbd3b393c75e8f7966bef5f32637333e76ee74ce04/pytest-5.2.4-py3-none-any.whl (227kB)\n",
      "Requirement already satisfied: future in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pyLDAvis) (0.17.1)\n",
      "Collecting funcy\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/3a/fc8323f913e8a9c6f33f7203547f8a2171223da5ed965f2541dafb10aa09/funcy-1.13-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pytest->pyLDAvis) (0.4.1)\n",
      "Collecting pluggy<1.0,>=0.12\n",
      "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pytest->pyLDAvis) (7.2.0)\n",
      "Collecting py>=1.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/76/bc/394ad449851729244a97857ee14d7cba61ddb268dce3db538ba2f2ba1f0f/py-1.8.0-py2.py3-none-any.whl (83kB)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pytest->pyLDAvis) (0.23)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pytest->pyLDAvis) (0.1.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pytest->pyLDAvis) (19.3.0)\n",
      "Collecting atomicwrites>=1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/52/90/6155aa926f43f2b2a22b01be7241be3bfd1ceaf7d0b3267213e8127d41f4/atomicwrites-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pytest->pyLDAvis) (19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.17.0->pyLDAvis) (1.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->pyLDAvis) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from packaging->pytest->pyLDAvis) (2.4.2)\n",
      "Building wheels for collected packages: pyLDAvis\n",
      "  Building wheel for pyLDAvis (setup.py): started\n",
      "  Building wheel for pyLDAvis (setup.py): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97715 sha256=09834e7ac55d723f0dfd7ec940195f50e33cb9bf0603e6499c597fc7620ebb51\n",
      "  Stored in directory: C:\\Users\\Acer\\AppData\\Local\\pip\\Cache\\wheels\\98\\71\\24\\513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
      "Successfully built pyLDAvis\n",
      "Installing collected packages: numexpr, pluggy, py, atomicwrites, pytest, funcy, pyLDAvis\n",
      "Successfully installed atomicwrites-1.3.0 funcy-1.13 numexpr-2.7.0 pluggy-0.13.0 py-1.8.0 pyLDAvis-2.1.2 pytest-5.2.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1518425091471922005158974038\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1518425091471922005158974038_data = {\"mdsDat\": {\"x\": [0.2527126170275011, 0.027154707930058475, 0.01687286510917302, 0.033993667740010135, 0.09997538654658727, -0.16387396900902265, -0.1656255702392137, -0.1012097051050945], \"y\": [0.020697546609416227, 0.276709369323767, -0.07616569637729752, -0.1445774839610054, -0.07198311719979533, -0.01052060492286157, 0.007468514235523106, -0.0016285277077463356], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [27.79778480529785, 15.534156799316406, 15.27437973022461, 12.373360633850098, 11.352109909057617, 7.17631721496582, 5.305255889892578, 5.186627388000488]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"Freq\": [204.0, 199.0, 103.0, 180.0, 150.0, 73.0, 93.0, 34.0, 61.0, 60.0, 22.0, 24.0, 23.0, 30.0, 23.0, 97.0, 64.0, 107.0, 26.0, 35.0, 85.0, 34.0, 52.0, 56.0, 65.0, 42.0, 26.0, 49.0, 26.0, 17.0, 59.52526092529297, 42.050537109375, 35.0650634765625, 33.49065017700195, 32.76161193847656, 30.220542907714844, 26.00958251953125, 26.012493133544922, 25.709741592407227, 24.651254653930664, 22.11208724975586, 19.181997299194336, 18.700313568115234, 17.34621238708496, 17.276350021362305, 16.968414306640625, 16.442203521728516, 16.267621994018555, 16.22130584716797, 15.697680473327637, 15.383369445800781, 15.122163772583008, 15.047297477722168, 14.633702278137207, 13.954471588134766, 14.414161682128906, 13.333535194396973, 13.078932762145996, 12.774301528930664, 12.1527738571167, 46.787384033203125, 69.77298736572266, 135.73822021484375, 36.96041488647461, 76.45634460449219, 33.59334945678711, 25.110319137573242, 31.78076171875, 26.53504753112793, 31.397886276245117, 21.69955825805664, 91.98902893066406, 50.431114196777344, 32.07402420043945, 25.68227767944336, 23.544984817504883, 51.47410583496094, 53.96472930908203, 31.231447219848633, 29.894527435302734, 34.058013916015625, 29.250858306884766, 25.747522354125977, 25.0620174407959, 19.117307662963867, 18.45268440246582, 16.863563537597656, 15.851243019104004, 11.783740997314453, 11.245122909545898, 10.995525360107422, 10.599056243896484, 10.425848007202148, 10.279092788696289, 10.11137580871582, 9.986350059509277, 9.896063804626465, 9.873411178588867, 9.593721389770508, 8.88725757598877, 8.887186050415039, 8.810590744018555, 8.444326400756836, 8.094599723815918, 7.954291343688965, 7.8120341300964355, 7.52842903137207, 7.236725807189941, 6.69672966003418, 6.508853912353516, 24.855850219726562, 6.216060161590576, 149.41477966308594, 30.0042667388916, 80.37992095947266, 9.234257698059082, 18.981130599975586, 10.105415344238281, 17.675891876220703, 17.492801666259766, 22.184438705444336, 13.421608924865723, 11.361067771911621, 13.384724617004395, 12.20191478729248, 12.54227066040039, 25.955652236938477, 25.686988830566406, 22.67291259765625, 20.86024284362793, 20.85147476196289, 19.151893615722656, 14.401628494262695, 12.939659118652344, 12.3725004196167, 11.054134368896484, 10.983994483947754, 10.029196739196777, 9.646291732788086, 9.27332592010498, 9.123533248901367, 8.727879524230957, 8.552680969238281, 8.19692611694336, 7.888810634613037, 7.855390548706055, 7.849680423736572, 7.813749313354492, 7.587092876434326, 7.346197128295898, 7.337839603424072, 7.293934345245361, 7.163507461547852, 6.8153839111328125, 6.440591335296631, 6.399402618408203, 12.600984573364258, 22.65189552307129, 25.392196655273438, 13.850374221801758, 14.65877628326416, 38.33838653564453, 14.490771293640137, 18.16722869873047, 31.18743324279785, 21.790733337402344, 23.244876861572266, 42.51932144165039, 43.23719024658203, 24.561054229736328, 21.946237564086914, 14.493035316467285, 11.948911666870117, 18.605632781982422, 13.66733169555664, 13.718056678771973, 12.401649475097656, 29.960058212280273, 25.44061851501465, 20.071887969970703, 14.426177024841309, 14.023421287536621, 13.156384468078613, 12.86966609954834, 12.481776237487793, 11.480131149291992, 10.927446365356445, 10.8718900680542, 10.491159439086914, 10.286111831665039, 9.422099113464355, 9.075085639953613, 8.457908630371094, 7.7875213623046875, 7.2433977127075195, 7.14459228515625, 11.370111465454102, 6.819276332855225, 6.54936408996582, 6.327878475189209, 6.270708084106445, 6.226545333862305, 6.224188327789307, 6.180598735809326, 6.10368537902832, 6.356403350830078, 5.61454963684082, 16.431852340698242, 12.587754249572754, 25.6627254486084, 18.82020378112793, 30.279741287231445, 17.367414474487305, 17.339141845703125, 8.785050392150879, 11.951737403869629, 17.017595291137695, 13.00566291809082, 15.315853118896484, 8.711186408996582, 11.858153343200684, 9.702159881591797, 20.272136688232422, 15.926031112670898, 10.167495727539062, 9.305061340332031, 9.246499061584473, 8.426704406738281, 7.767210006713867, 7.715081691741943, 7.60826301574707, 7.607856273651123, 7.4120965003967285, 7.322113513946533, 6.967246055603027, 6.83212947845459, 6.795024394989014, 6.480443000793457, 6.445550918579102, 6.055174350738525, 5.693523406982422, 5.690637111663818, 5.541042327880859, 5.3913798332214355, 5.3913798332214355, 5.336544990539551, 15.330389022827148, 4.940872669219971, 4.700272560119629, 4.684336185455322, 4.630228042602539, 4.548191547393799, 13.641104698181152, 68.74066925048828, 49.67096710205078, 22.69816780090332, 97.22135162353516, 29.505878448486328, 24.169443130493164, 13.223060607910156, 27.40492820739746, 32.03471374511719, 11.990503311157227, 13.129570960998535, 12.709053039550781, 12.537703514099121, 17.164775848388672, 10.810193061828613, 10.329336166381836, 8.335567474365234, 8.269264221191406, 7.673640727996826, 22.90412139892578, 22.579750061035156, 17.021230697631836, 16.55274200439453, 13.696937561035156, 13.663430213928223, 11.13425064086914, 9.918910026550293, 9.918910026550293, 9.475658416748047, 8.355888366699219, 8.265689849853516, 7.979969501495361, 7.979716777801514, 7.238567352294922, 5.561141490936279, 5.119338035583496, 4.82690954208374, 4.840665340423584, 4.724388122558594, 4.718440532684326, 4.609771251678467, 4.406182289123535, 4.252206325531006, 4.027551174163818, 3.9664077758789062, 3.703670024871826, 3.7036705017089844, 3.7027056217193604, 3.565425395965576, 26.62801742553711, 10.374561309814453, 6.019976615905762, 4.722019672393799, 4.722019672393799, 7.142293453216553, 5.512739181518555, 6.505650997161865, 5.156872272491455, 21.96898651123047, 13.903369903564453, 11.035100936889648, 9.54417610168457, 8.515203475952148, 6.344144821166992, 6.025091171264648, 5.9682722091674805, 5.5722222328186035, 5.300927639007568, 4.92808198928833, 4.760212421417236, 4.750283241271973, 4.720674514770508, 4.6642351150512695, 20.517349243164062, 4.0497870445251465, 3.9882733821868896, 3.972445011138916, 3.9605696201324463, 3.855362892150879, 3.6166694164276123, 3.5814876556396484, 3.4730019569396973, 3.3805460929870605, 3.2390050888061523, 2.9359309673309326, 2.8375768661499023, 2.832645893096924, 2.6925089359283447, 10.360886573791504, 6.5353617668151855, 4.58846378326416, 3.6897900104522705, 4.915024757385254, 6.521522521972656, 3.692038059234619, 3.8381457328796387, 9.223883628845215, 8.992006301879883, 8.753327369689941, 6.870033264160156, 6.228646278381348, 5.864468097686768, 5.6798906326293945, 5.493663311004639, 4.7578959465026855, 4.676297187805176, 4.591358661651611, 4.542328834533691, 4.225742340087891, 4.196833610534668, 3.9855453968048096, 3.9245333671569824, 3.775020122528076, 3.75809383392334, 3.709567070007324, 3.7154533863067627, 3.438101053237915, 3.427340507507324, 2.8838655948638916, 2.8654515743255615, 2.7212941646575928, 2.6148388385772705, 2.5757253170013428, 2.56620717048645, 2.3162052631378174, 2.2537264823913574, 8.64162826538086, 3.7396163940429688, 3.9238877296447754, 7.1625518798828125, 4.110398292541504, 4.900967121124268, 6.208579063415527, 3.42916202545166, 3.42916202545166, 4.839072227478027, 3.453029155731201], \"Term\": [\"word\", \"language\", \"natural\", \"nlp\", \"sentence\", \"processing\", \"data\", \"london\", \"human\", \"use\", \"lot\", \"topic\", \"get\", \"want\", \"python\", \"learning\", \"model\", \"text\", \"great\", \"work\", \"machine\", \"look\", \"computer\", \"algorithm\", \"system\", \"english\", \"tree\", \"one\", \"parse\", \"spacy\", \"use\", \"english\", \"technique\", \"pipeline\", \"deep\", \"parsing\", \"list\", \"let\", \"step\", \"two\", \"simple\", \"would\", \"code\", \"type\", \"e.g\", \"useful\", \"could\", \"piece\", \"dependency\", \"fact\", \"complex\", \"year\", \"neural\", \"following\", \"case\", \"separate\", \"goal\", \"token\", \"classification\", \"together\", \"task\", \"machine\", \"nlp\", \"understand\", \"learning\", \"article\", \"application\", \"approach\", \"called\", \"also\", \"translation\", \"language\", \"like\", \"used\", \"problem\", \"learn\", \"sentence\", \"word\", \"example\", \"human\", \"natural\", \"text\", \"entity\", \"noun\", \"context\", \"named\", \"verb\", \"stop\", \"pony\", \"around\", \"involves\", \"figure\", \"level\", \"affix\", \"ner\", \"group\", \"us\", \"create\", \"relationship\", \"medium\", \"concept\", \"lemmatization\", \"talking\", \"conversation\", \"done\", \"source\", \"value\", \"single\", \"think\", \"probably\", \"form\", \"lemma\", \"word\", \"meaning\", \"sentence\", \"root\", \"analysis\", \"next\", \"different\", \"document\", \"like\", \"new\", \"speech\", \"example\", \"ha\", \"text\", \"tree\", \"parse\", \"thing\", \"mean\", \"phrase\", \"name\", \"knowledge\", \"analytics\", \"several\", \"sequence\", \"represent\", \"said\", \"symbol\", \"feature\", \"string\", \"small\", \"raw\", \"working\", \"really\", \"thousand\", \"whole\", \"best\", \"base\", \"sometimes\", \"tag\", \"parsed\", \"rewrite\", \"traditional\", \"trying\", \"analyzing\", \"since\", \"set\", \"based\", \"written\", \"search\", \"model\", \"world\", \"input\", \"algorithm\", \"information\", \"way\", \"data\", \"text\", \"one\", \"rule\", \"different\", \"structure\", \"sentence\", \"ha\", \"system\", \"like\", \"want\", \"great\", \"idea\", \"able\", \"build\", \"read\", \"perform\", \"basic\", \"building\", \"detail\", \"try\", \"practical\", \"consider\", \"generate\", \"assignment\", \"complicated\", \"module\", \"extremely\", \"organization\", \"output\", \"team\", \"unsupervised\", \"finally\", \"entire\", \"band\", \"demo\", \"must\", \"corresponding\", \"interpret\", \"computing\", \"field\", \"nlg\", \"work\", \"see\", \"system\", \"using\", \"algorithm\", \"user\", \"result\", \"data\", \"ha\", \"learning\", \"grammar\", \"nlp\", \"language\", \"linguistics\", \"computational\", \"important\", \"unstructured\", \"wikipedia\", \"interaction\", \"syntactic\", \"post\", \"analyze\", \"website\", \"reading\", \"inference\", \"continue\", \"access\", \"note\", \"hand\", \"typical\", \"role\", \"consists\", \"summarization\", \"huge\", \"owner\", \"regulator\", \"hear\", \"science\", \"volume\", \"focus\", \"series\", \"domain\", \"discipline\", \"business\", \"natural\", \"processing\", \"look\", \"language\", \"human\", \"computer\", \"speech\", \"data\", \"nlp\", \"statistical\", \"part\", \"using\", \"rule\", \"text\", \"understanding\", \"analysis\", \"grammar\", \"process\", \"large\", \"get\", \"python\", \"spacy\", \"library\", \"http\", \"start\", \"capital\", \"sheet\", \"cheat\", \"write\", \"city\", \"united\", \"england\", \"kingdom\", \"free\", \"amazing\", \"line\", \"populous\", \"frequent\", \"workshop\", \"certificate\", \"speak\", \"textacy\", \"numpy\", \"recognize\", \"performance\", \"handle\", \"unique\", \"version\", \"beetle\", \"london\", \"course\", \"run\", \"bird\", \"grain\", \"work\", \"term\", \"data\", \"example\", \"lot\", \"know\", \"...\", \"find\", \"project\", \"right\", \"seen\", \"cloud\", \"check\", \"founded\", \"statement\", \"give\", \"care\", \"experience\", \"facebook\", \"topic\", \"discus\", \"box\", \"everything\", \"mark\", \"yet\", \"linkedin\", \"scale\", \"previous\", \"twitter\", \"point\", \"ability\", \"top\", \"face\", \"co-reference\", \"help\", \"resolution\", \"roman\", \"bot\", \"run\", \"london\", \"software\", \"customer\", \"break\", \"peck\", \"study\", \"pronoun\", \"includes\", \"certain\", \"future\", \"parser\", \"hidden\", \"comment\", \"referring\", \"var\", \"required\", \"object\", \"error\", \"requires\", \"unit\", \"nice\", \"according\", \"show\", \"power\", \"primitive\", \"plan\", \"among\", \"exactly\", \"tay\", \"lexicon\", \"strategy\", \"pecking\", \"nuance\", \"already\", \"released\", \"present\", \"time\", \"actually\", \"still\", \"wa\", \"bird\", \"grain\", \"text\", \"question\"], \"Total\": [204.0, 199.0, 103.0, 180.0, 150.0, 73.0, 93.0, 34.0, 61.0, 60.0, 22.0, 24.0, 23.0, 30.0, 23.0, 97.0, 64.0, 107.0, 26.0, 35.0, 85.0, 34.0, 52.0, 56.0, 65.0, 42.0, 26.0, 49.0, 26.0, 17.0, 60.25886535644531, 42.784088134765625, 35.79821014404297, 34.22418212890625, 33.49435043334961, 30.954513549804688, 26.74346160888672, 26.74700164794922, 26.443147659301758, 25.38553810119629, 22.845182418823242, 19.91584587097168, 19.434053421020508, 18.07945442199707, 18.01038932800293, 17.702186584472656, 17.17566680908203, 17.000553131103516, 16.955209732055664, 16.431102752685547, 16.11672019958496, 15.855754852294922, 15.78059196472168, 15.366722106933594, 14.687843322753906, 15.193316459655762, 14.068428993225098, 13.813427925109863, 13.50722885131836, 12.88635540008545, 54.980628967285156, 85.46092987060547, 180.1212921142578, 43.30064010620117, 97.9284896850586, 39.401248931884766, 28.66358184814453, 38.14408493041992, 32.20691680908203, 41.40562438964844, 25.358057022094727, 199.40249633789062, 85.53047943115234, 46.34016036987305, 33.3592529296875, 32.5217399597168, 150.97280883789062, 204.01065063476562, 60.78868103027344, 61.34550094604492, 103.41322326660156, 107.3357925415039, 26.506515502929688, 25.82158851623535, 19.87582015991211, 19.21179962158203, 17.622140884399414, 16.609357833862305, 12.542348861694336, 12.00501537322998, 11.754739761352539, 11.358061790466309, 11.184000015258789, 11.037955284118652, 10.871511459350586, 10.744794845581055, 10.655240058898926, 10.632740020751953, 10.352087020874023, 9.646288871765137, 9.646684646606445, 9.56881332397461, 9.203546524047852, 8.852986335754395, 8.714430809020996, 8.57101821899414, 8.287891387939453, 7.997014999389648, 7.460229873657227, 7.271362781524658, 27.77985382080078, 6.974081039428711, 204.01065063476562, 40.4509162902832, 150.97280883789062, 11.119124412536621, 30.70221710205078, 12.642568588256836, 32.809932708740234, 33.638763427734375, 85.53047943115234, 29.367633819580078, 25.22446060180664, 60.78868103027344, 51.804039001464844, 107.3357925415039, 26.698381423950195, 26.43187141418457, 23.417325973510742, 21.60365104675293, 21.594966888427734, 19.895816802978516, 15.144559860229492, 13.683296203613281, 13.115851402282715, 11.797736167907715, 11.726962089538574, 10.774126052856445, 10.388872146606445, 10.01599407196045, 9.8675537109375, 9.4708833694458, 9.295973777770996, 8.939597129821777, 8.631690979003906, 8.598073959350586, 8.592905044555664, 8.556705474853516, 8.329913139343262, 8.088851928710938, 8.080517768859863, 8.038021087646484, 7.908496379852295, 7.561748504638672, 7.1831865310668945, 7.143100738525391, 14.561383247375488, 28.692434310913086, 34.8775634765625, 17.382431030273438, 18.755949020385742, 64.48017883300781, 19.623748779296875, 26.544200897216797, 56.685115814208984, 35.67584228515625, 39.110137939453125, 93.8506851196289, 107.3357925415039, 49.15012741088867, 42.086708068847656, 32.809932708740234, 20.210161209106445, 150.97280883789062, 51.804039001464844, 65.05992889404297, 85.53047943115234, 30.696895599365234, 26.177391052246094, 20.811107635498047, 15.163854598999023, 14.759876251220703, 13.893933296203613, 13.607193946838379, 13.218945503234863, 12.216055870056152, 11.663712501525879, 11.6151704788208, 11.227505683898926, 11.023336410522461, 10.158132553100586, 9.812000274658203, 9.196263313293457, 8.528959274291992, 7.986132621765137, 7.881844520568848, 12.570281982421875, 7.557125091552734, 7.285125255584717, 7.0651631355285645, 7.008346080780029, 6.962957859039307, 6.961461067199707, 6.916794300079346, 6.842498779296875, 7.167013645172119, 6.351219654083252, 19.57079315185547, 14.799934387207031, 35.98491668701172, 27.23076820373535, 65.05992889404297, 43.386375427246094, 56.685115814208984, 15.363510131835938, 34.25515365600586, 93.8506851196289, 51.804039001464844, 97.9284896850586, 18.474700927734375, 180.1212921142578, 199.40249633789062, 21.014236450195312, 16.668270111083984, 10.911237716674805, 10.047286033630371, 9.991689682006836, 9.168937683105469, 8.510629653930664, 8.4577054977417, 8.350824356079102, 8.3526611328125, 8.158027648925781, 8.064476013183594, 7.712689399719238, 7.580800533294678, 7.544137954711914, 7.223387241363525, 7.188431739807129, 6.800464630126953, 6.437350749969482, 6.43546199798584, 6.286701202392578, 6.133216381072998, 6.133216381072998, 6.079953193664551, 17.525964736938477, 5.6840338706970215, 5.44304084777832, 5.426368713378906, 5.373053550720215, 5.29058837890625, 16.477977752685547, 103.41322326660156, 73.97785186767578, 34.12749481201172, 199.40249633789062, 61.34550094604492, 52.053199768066406, 25.22446060180664, 93.8506851196289, 180.1212921142578, 29.871971130371094, 38.02886199951172, 43.386375427246094, 42.086708068847656, 107.3357925415039, 33.31821060180664, 30.70221710205078, 18.474700927734375, 33.27352523803711, 16.577850341796875, 23.669204711914062, 23.343809127807617, 17.78656768798828, 17.31661033630371, 14.460370063781738, 14.430336952209473, 11.898689270019531, 10.682589530944824, 10.682589530944824, 10.240318298339844, 9.12141227722168, 9.03012466430664, 8.744335174560547, 8.744215965270996, 8.002446174621582, 6.325893402099609, 5.8835859298706055, 5.590466499328613, 5.606827259063721, 5.489649295806885, 5.483947277069092, 5.375219345092773, 5.170029640197754, 5.015631675720215, 4.797738075256348, 4.7325544357299805, 4.469424724578857, 4.469508171081543, 4.468649864196777, 4.328824043273926, 34.24544143676758, 18.656347274780273, 11.619922637939453, 8.821903228759766, 8.821903228759766, 35.98491668701172, 21.3315372467041, 93.8506851196289, 60.78868103027344, 22.750598907470703, 14.68668270111084, 11.815716743469238, 10.325531959533691, 9.296799659729004, 7.125209808349609, 6.806958198547363, 6.748474597930908, 6.353121757507324, 6.085423469543457, 5.708276748657227, 5.540843963623047, 5.532101631164551, 5.501506328582764, 5.4446492195129395, 24.168386459350586, 4.83049201965332, 4.768646240234375, 4.753850936889648, 4.74390983581543, 4.636451721191406, 4.397446632385254, 4.362581253051758, 4.2600603103637695, 4.1629533767700195, 4.020656585693359, 3.7171194553375244, 3.618307590484619, 3.6145761013031006, 3.473066806793213, 13.805893898010254, 8.98263931274414, 7.938907623291016, 5.8157124519348145, 11.619922637939453, 34.24544143676758, 6.3994269371032715, 10.531047821044922, 9.99425983428955, 9.759191513061523, 9.521807670593262, 7.638223648071289, 6.9969706535339355, 6.63340425491333, 6.447869777679443, 6.262294769287109, 5.527103424072266, 5.44605016708374, 5.359586715698242, 5.309369087219238, 4.993720531463623, 4.966245651245117, 4.753058910369873, 4.694436550140381, 4.543460845947266, 4.527493476867676, 4.477531433105469, 4.48569917678833, 4.206307411193848, 4.195254325866699, 3.652769088745117, 3.635871648788452, 3.4887657165527344, 3.382274866104126, 3.344435453414917, 3.3360114097595215, 3.0835251808166504, 3.0217628479003906, 11.941933631896973, 5.681058883666992, 6.113092422485352, 16.666698455810547, 6.958096504211426, 10.19968032836914, 38.32251739501953, 8.821903228759766, 8.821903228759766, 107.3357925415039, 12.439168930053711], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2680000066757202, 1.2628999948501587, 1.2595000267028809, 1.2584999799728394, 1.2581000328063965, 1.2561999559402466, 1.2524000406265259, 1.2524000406265259, 1.2520999908447266, 1.2509000301361084, 1.2475999593734741, 1.2426999807357788, 1.2417000532150269, 1.238800048828125, 1.2386000156402588, 1.2379000186920166, 1.2366000413894653, 1.2360999584197998, 1.2359999418258667, 1.2345999479293823, 1.2336000204086304, 1.232800006866455, 1.2325999736785889, 1.2312999963760376, 1.2289999723434448, 1.2275999784469604, 1.2266000509262085, 1.225600004196167, 1.2244000434875488, 1.22160005569458, 1.1188000440597534, 1.0773999691009521, 0.9973000288009644, 1.121899962425232, 1.0326999425888062, 1.1207000017166138, 1.1478999853134155, 1.0976999998092651, 1.0865000486373901, 1.003499984741211, 1.124400019645691, 0.506600022315979, 0.7519000172615051, 0.9122999906539917, 1.0187000036239624, 0.9571999907493591, 0.20419999957084656, -0.04960000142455101, 0.6141999959945679, 0.5613999962806702, 0.16949999332427979, -0.01979999989271164, 1.8330999612808228, 1.8322999477386475, 1.823199987411499, 1.8217999935150146, 1.8180999755859375, 1.8154000043869019, 1.7997000217437744, 1.7967000007629395, 1.7954000234603882, 1.7929999828338623, 1.7919000387191772, 1.7908999919891357, 1.7896000146865845, 1.7889000177383423, 1.7882000207901, 1.7879999876022339, 1.7860000133514404, 1.7802000045776367, 1.7800999879837036, 1.7796000242233276, 1.7760000228881836, 1.7726000547409058, 1.770900011062622, 1.7694000005722046, 1.7660000324249268, 1.7621999979019165, 1.7541999816894531, 1.7512999773025513, 1.7509000301361084, 1.7470999956130981, 1.5506999492645264, 1.5634000301361084, 1.2317999601364136, 1.6763999462127686, 1.3811999559402466, 1.638100028038025, 1.2436000108718872, 1.2081999778747559, 0.5126000046730042, 1.0791000127792358, 1.0644999742507935, 0.34880000352859497, 0.4162999987602234, -0.2847000062465668, 1.8508000373840332, 1.8503999710083008, 1.8466999530792236, 1.843999981880188, 1.843999981880188, 1.84089994430542, 1.8286999464035034, 1.823099970817566, 1.8206000328063965, 1.8138999938964844, 1.8135000467300415, 1.8072999715805054, 1.804800033569336, 1.8020000457763672, 1.8006000518798828, 1.7972999811172485, 1.795699954032898, 1.7922999858856201, 1.7890000343322754, 1.788699984550476, 1.7884999513626099, 1.7882000207901, 1.785599946975708, 1.7826999425888062, 1.7826000452041626, 1.7819000482559204, 1.7800999879837036, 1.7750999927520752, 1.7698999643325806, 1.7690999507904053, 1.7344000339508057, 1.6426000595092773, 1.5615999698638916, 1.6518000364303589, 1.6325000524520874, 1.3590999841690063, 1.5757999420166016, 1.4997999668121338, 1.281499981880188, 1.3860000371932983, 1.3587000370025635, 1.0872000455856323, 0.9696999788284302, 1.1852999925613403, 1.2279000282287598, 1.061900019645691, 1.3533999919891357, -0.21459999680519104, 0.546500027179718, 0.3224000036716461, -0.05209999904036522, 2.0652999877929688, 2.0611000061035156, 2.053499937057495, 2.039799928665161, 2.0383999347686768, 2.035099983215332, 2.033900022506714, 2.0322000980377197, 2.0274999141693115, 2.024399995803833, 2.0234999656677246, 2.0218000411987305, 2.020400047302246, 2.014400005340576, 2.0116000175476074, 2.0058999061584473, 1.9987000226974487, 1.9919999837875366, 1.9914000034332275, 1.989300012588501, 1.986899971961975, 1.983199954032898, 1.9794000387191772, 1.9783999919891357, 1.9778000116348267, 1.9776999950408936, 1.9771000146865845, 1.9753999710083008, 1.969599962234497, 1.9663000106811523, 1.9148000478744507, 1.9277000427246094, 1.7516000270843506, 1.7201999425888062, 1.3248000144958496, 1.1741000413894653, 0.9050999879837036, 1.5306999683380127, 1.0367000102996826, 0.3822000026702881, 0.7074999809265137, 0.23430000245571136, 1.3378000259399414, -0.6309999823570251, -0.9333999752998352, 2.1398000717163086, 2.130199909210205, 2.1052000522613525, 2.0989999771118164, 2.098299980163574, 2.091399908065796, 2.084399938583374, 2.083899974822998, 2.0826001167297363, 2.08240008354187, 2.079900026321411, 2.079200029373169, 2.0741000175476074, 2.0717999935150146, 2.071199893951416, 2.067199945449829, 2.066699981689453, 2.0597000122070312, 2.052999973297119, 2.052799940109253, 2.049499988555908, 2.046799898147583, 2.046799898147583, 2.045300006866455, 2.0418999195098877, 2.035599946975708, 2.0290000438690186, 2.028700113296509, 2.0269999504089355, 2.024600028991699, 1.986799955368042, 1.7674000263214111, 1.777400016784668, 1.767899990081787, 1.4573999643325806, 1.4437999725341797, 1.4085999727249146, 1.5298999547958374, 0.9448000192642212, 0.4490000009536743, 1.2630000114440918, 1.1123000383377075, 0.9478999972343445, 0.9648000001907349, 0.3427000045776367, 1.0501999855041504, 1.086400032043457, 1.3798999786376953, 0.7835000157356262, 1.405500054359436, 2.6015000343322754, 2.601099967956543, 2.590399980545044, 2.5892999172210693, 2.5801000595092773, 2.5797998905181885, 2.568000078201294, 2.5601999759674072, 2.5601999759674072, 2.55679988861084, 2.5467000007629395, 2.5459001064300537, 2.5429000854492188, 2.5429000854492188, 2.53410005569458, 2.505500078201294, 2.4951999187469482, 2.487499952316284, 2.487499952316284, 2.484299898147583, 2.4839999675750732, 2.480799913406372, 2.4744999408721924, 2.4693000316619873, 2.459399938583374, 2.4577999114990234, 2.4463999271392822, 2.4463999271392822, 2.4463999271392822, 2.4403998851776123, 2.3828001022338867, 2.047600030899048, 1.976699948310852, 2.009399890899658, 2.009399890899658, 1.017300009727478, 1.2812999486923218, -0.034699998795986176, 0.1673000007867813, 2.9014999866485596, 2.881700038909912, 2.8680999279022217, 2.857800006866455, 2.8487000465393066, 2.8203999996185303, 2.814500093460083, 2.8136000633239746, 2.805299997329712, 2.7985000610351562, 2.7894999980926514, 2.784600019454956, 2.78410005569458, 2.783400058746338, 2.7818000316619873, 2.772700071334839, 2.760200023651123, 2.7578001022338867, 2.7569000720977783, 2.75600004196167, 2.752000093460083, 2.740999937057495, 2.7392001152038574, 2.7321999073028564, 2.728300094604492, 2.7202999591827393, 2.700500011444092, 2.6933999061584473, 2.692699909210205, 2.6819000244140625, 2.649399995803833, 2.6184000968933105, 2.388200044631958, 2.4814999103546143, 2.0759999752044678, 1.277999997138977, 2.386399984359741, 1.9270999431610107, 2.8789000511169434, 2.87719988822937, 2.8749001026153564, 2.853100061416626, 2.8427999019622803, 2.835900068283081, 2.8322999477386475, 2.8280999660491943, 2.8092000484466553, 2.8066999912261963, 2.8043999671936035, 2.803100109100342, 2.792099952697754, 2.790800094604492, 2.7829999923706055, 2.7799999713897705, 2.7737998962402344, 2.7727999687194824, 2.770900011062622, 2.770699977874756, 2.7574000358581543, 2.7569000720977783, 2.7227001190185547, 2.7209999561309814, 2.710599899291992, 2.70169997215271, 2.6979000568389893, 2.696700096130371, 2.6728999614715576, 2.665800094604492, 2.6356000900268555, 2.5408999919891357, 2.515700101852417, 2.114500045776367, 2.4326999187469482, 2.2262001037597656, 1.1390000581741333, 2.01419997215271, 2.01419997215271, -0.14020000398159027, 1.6775000095367432], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.14300012588501, -4.490499973297119, -4.6722002029418945, -4.718200206756592, -4.740200042724609, -4.820899963378906, -4.9710001945495605, -4.970799922943115, -4.982500076293945, -5.024600028991699, -5.133299827575684, -5.275400161743164, -5.300899982452393, -5.375999927520752, -5.380099773406982, -5.398099899291992, -5.429599761962891, -5.440199851989746, -5.4430999755859375, -5.475900173187256, -5.496099948883057, -5.513299942016602, -5.518199920654297, -5.54610013961792, -5.593599796295166, -5.561200141906738, -5.639100074768066, -5.658400058746338, -5.682000160217285, -5.731900215148926, -4.383800029754639, -3.9842000007629395, -3.318700075149536, -4.61959981918335, -3.892699956893921, -4.715099811553955, -5.006100177764893, -4.770599842071533, -4.951000213623047, -4.782700061798096, -5.152100086212158, -3.70770001411438, -4.308800220489502, -4.76140022277832, -4.98360013961792, -5.070499897003174, -4.288300037384033, -4.241099834442139, -4.788000106811523, -4.831699848175049, -4.701399803161621, -4.853499889373779, -4.399199962615967, -4.42609977722168, -4.696899890899658, -4.7322998046875, -4.822299957275391, -4.884300231933594, -5.180799961090088, -5.22760009765625, -5.25, -5.2866997718811035, -5.303199768066406, -5.317399978637695, -5.333799839019775, -5.34630012512207, -5.355400085449219, -5.357699871063232, -5.38640022277832, -5.462900161743164, -5.462900161743164, -5.471499919891357, -5.513999938964844, -5.556300163269043, -5.573800086975098, -5.591800212860107, -5.628799915313721, -5.668300151824951, -5.7459001541137695, -5.7743000984191895, -4.4344000816345215, -5.820400238037109, -2.6407999992370605, -4.246200084686279, -3.260699987411499, -5.424600124359131, -4.704100131988525, -5.334400177001953, -4.775300025939941, -4.785699844360352, -4.548099994659424, -5.050600051879883, -5.217299938201904, -5.053400039672852, -5.145899772644043, -5.1184000968933105, -4.374199867248535, -4.384699821472168, -4.509500026702881, -4.592800140380859, -4.593200206756592, -4.678199768066406, -4.9633002281188965, -5.070300102233887, -5.115200042724609, -5.227799892425537, -5.2342000007629395, -5.325099945068359, -5.364099979400635, -5.403500080108643, -5.4197998046875, -5.464099884033203, -5.484399795532227, -5.526899814605713, -5.565199851989746, -5.569399833679199, -5.570199966430664, -5.57480001449585, -5.6041998863220215, -5.636499881744385, -5.637599945068359, -5.643599987030029, -5.661600112915039, -5.71150016784668, -5.76800012588501, -5.774400234222412, -5.09689998626709, -4.51039981842041, -4.396200180053711, -5.002299785614014, -4.9456000328063965, -3.9842000007629395, -4.957099914550781, -4.730999946594238, -4.1905999183654785, -4.549200057983398, -4.484600067138672, -3.88070011138916, -3.8638999462127686, -4.429500102996826, -4.541999816894531, -4.956999778747559, -5.150000095367432, -4.707200050354004, -5.015600204467773, -5.011899948120117, -5.112800121307373, -4.020100116729736, -4.183700084686279, -4.4207000732421875, -4.750999927520752, -4.779300212860107, -4.843100070953369, -4.865099906921387, -4.895699977874756, -4.979400157928467, -5.02869987487793, -5.03380012512207, -5.069499969482422, -5.089200019836426, -5.1768999099731445, -5.2144999504089355, -5.284900188446045, -5.367499828338623, -5.439899921417236, -5.45359992980957, -4.988999843597412, -5.50029993057251, -5.540599822998047, -5.574999809265137, -5.584099769592285, -5.59119987487793, -5.591599941253662, -5.598599910736084, -5.611100196838379, -5.570499897003174, -5.6946001052856445, -4.620800018310547, -4.88730001449585, -4.175000190734863, -4.485099792480469, -4.009500026702881, -4.565400123596191, -4.566999912261963, -5.247000217437744, -4.9390997886657715, -4.5858001708984375, -4.854599952697754, -4.691100120544434, -5.25540018081665, -4.947000026702881, -5.14769983291626, -4.3246002197265625, -4.565899848937988, -5.014699935913086, -5.103300094604492, -5.109600067138672, -5.202499866485596, -5.283999919891357, -5.2906999588012695, -5.304599761962891, -5.304699897766113, -5.3308000564575195, -5.3429999351501465, -5.392600059509277, -5.412199974060059, -5.417699813842773, -5.465099811553955, -5.4704999923706055, -5.5329999923706055, -5.5945000648498535, -5.59499979019165, -5.621699810028076, -5.649099826812744, -5.649099826812744, -5.659299850463867, -4.604000091552734, -5.736299991607666, -5.786200046539307, -5.789599895477295, -5.801300048828125, -5.8190999031066895, -4.720799922943115, -3.1034998893737793, -3.4284000396728516, -4.211599826812744, -2.7569000720977783, -3.9493000507354736, -4.148799896240234, -4.7519001960754395, -4.023099899291992, -3.867000102996826, -4.849699974060059, -4.758999824523926, -4.791500091552734, -4.805099964141846, -4.491000175476074, -4.953400135040283, -4.998899936676025, -5.2133002281188965, -5.22130012512207, -5.29610013961792, -3.7439000606536865, -3.75819993019104, -4.040800094604492, -4.068699836730957, -4.2581000328063965, -4.260499954223633, -4.465199947357178, -4.5808000564575195, -4.5808000564575195, -4.626500129699707, -4.752299785614014, -4.7631001472473145, -4.798299789428711, -4.798299789428711, -4.8958001136779785, -5.15939998626709, -5.242199897766113, -5.301000118255615, -5.2982001304626465, -5.322500228881836, -5.323800086975098, -5.347099781036377, -5.392199993133545, -5.427800178527832, -5.482100009918213, -5.497399806976318, -5.565899848937988, -5.565899848937988, -5.566199779510498, -5.604000091552734, -3.5933001041412354, -4.535900115966797, -5.0802001953125, -5.322999954223633, -5.322999954223633, -4.909200191497803, -5.1682000160217285, -5.002600193023682, -5.234899997711182, -3.4835000038146973, -3.940999984741211, -4.172100067138672, -4.317200183868408, -4.431300163269043, -4.725599765777588, -4.777200222015381, -4.7866997718811035, -4.855400085449219, -4.905300140380859, -4.9781999588012695, -5.012899875640869, -5.014999866485596, -5.021200180053711, -5.033199787139893, -3.5518999099731445, -5.174499988555908, -5.189799785614014, -5.19379997253418, -5.196800231933594, -5.223700046539307, -5.287600040435791, -5.297399997711182, -5.328100204467773, -5.355100154876709, -5.397900104522705, -5.496099948883057, -5.530200004577637, -5.531899929046631, -5.582699775695801, -4.235099792480469, -4.695899963378906, -5.049600124359131, -5.267600059509277, -4.980899810791016, -4.697999954223633, -5.267000198364258, -5.2281999588012695, -4.328700065612793, -4.3541998863220215, -4.381100177764893, -4.6234002113342285, -4.721399784088135, -4.781599998474121, -4.813600063323975, -4.84689998626709, -4.990699768066406, -5.007999897003174, -5.026400089263916, -5.037099838256836, -5.109300136566162, -5.116199970245361, -5.167900085449219, -5.183300018310547, -5.222099781036377, -5.226600170135498, -5.23960018157959, -5.23799991607666, -5.3155999183654785, -5.31879997253418, -5.491399765014648, -5.497799873352051, -5.5493998527526855, -5.589300155639648, -5.604400157928467, -5.608099937438965, -5.710599899291992, -5.73799991607666, -4.394000053405762, -5.231599807739258, -5.183499813079834, -4.581699848175049, -5.13700008392334, -4.961100101470947, -4.724599838256836, -5.31820011138916, -5.31820011138916, -4.973800182342529, -5.311299800872803]}, \"token.table\": {\"Topic\": [7, 7, 4, 5, 8, 3, 8, 2, 2, 3, 4, 5, 7, 8, 1, 2, 6, 8, 2, 5, 8, 3, 5, 3, 1, 4, 1, 3, 8, 2, 1, 4, 4, 4, 3, 1, 2, 3, 4, 6, 3, 6, 8, 2, 7, 7, 8, 4, 4, 3, 5, 1, 4, 6, 7, 1, 8, 6, 6, 7, 6, 1, 7, 7, 1, 8, 1, 4, 5, 1, 2, 3, 5, 4, 2, 4, 5, 2, 5, 2, 4, 1, 1, 6, 2, 1, 2, 7, 3, 4, 5, 6, 1, 4, 1, 4, 2, 3, 5, 7, 2, 4, 5, 6, 5, 2, 1, 6, 1, 4, 2, 8, 7, 8, 1, 2, 3, 5, 6, 8, 7, 4, 7, 7, 1, 3, 4, 8, 2, 4, 7, 5, 1, 2, 5, 7, 6, 6, 8, 4, 6, 7, 1, 6, 8, 4, 5, 8, 4, 2, 1, 2, 3, 4, 5, 7, 5, 6, 5, 3, 7, 8, 6, 5, 1, 3, 5, 4, 5, 8, 5, 2, 3, 5, 6, 3, 4, 5, 4, 2, 6, 7, 3, 1, 4, 5, 3, 5, 1, 2, 4, 5, 1, 3, 4, 5, 2, 2, 1, 2, 8, 6, 1, 2, 3, 6, 5, 7, 1, 2, 6, 7, 3, 5, 7, 1, 3, 4, 5, 7, 3, 1, 2, 3, 2, 1, 3, 4, 4, 4, 3, 2, 1, 5, 2, 1, 1, 2, 3, 8, 2, 7, 8, 3, 4, 1, 4, 5, 5, 2, 8, 6, 8, 1, 3, 4, 2, 4, 5, 3, 3, 8, 1, 1, 2, 5, 8, 8, 4, 6, 3, 1, 1, 8, 7, 2, 6, 5, 8, 4, 5, 8, 7, 8, 2, 1, 5, 7, 1, 2, 5, 1, 5, 7, 8, 6, 1, 8, 3, 4, 5, 3, 6, 8, 5, 2, 2, 8, 3, 8, 8, 6, 7, 1, 3, 4, 3, 7, 5, 2, 7, 2, 5, 3, 4, 5, 8, 6, 7, 3, 7, 2, 5, 3, 7, 2, 4, 5, 7, 1, 2, 3, 1, 3, 5, 3, 4, 5, 3, 6, 8, 1, 3, 5, 2, 3, 2, 4, 7, 3, 2, 6, 6, 2, 5, 6, 7, 1, 3, 4, 5, 1, 2, 8, 2, 8, 3, 1, 3, 4, 8, 5, 3, 5, 1, 2, 3, 4, 5, 3, 2, 1, 3, 4, 8, 4, 1, 1, 6, 1, 2, 3, 5, 8, 6, 3, 2, 3, 2, 3, 8, 1, 1, 7, 3, 7, 3, 1, 4, 3, 4, 3, 7, 1, 1, 5, 1, 2, 1, 4, 5, 6, 8, 6, 5, 4, 2, 1, 1, 2, 3, 1, 2, 4, 1, 3, 4, 5, 8, 2, 8, 2, 6, 5, 1, 2, 4, 6, 8, 4, 1, 3, 5, 3, 5, 1, 2, 2, 4, 6, 3, 6, 3, 4, 1, 6, 3, 6, 1, 7], \"Freq\": [0.930963397026062, 0.8070765733718872, 0.9232481122016907, 0.9233853220939636, 0.8933494091033936, 0.2874349355697632, 0.5748698711395264, 0.9059649109840393, 0.08820657432079315, 0.5468807816505432, 0.2999023497104645, 0.05292394757270813, 0.2512156069278717, 0.7536467909812927, 0.7486905455589294, 0.21736177802085876, 0.9484826326370239, 0.8251116275787354, 0.6188477873802185, 0.32570937275886536, 0.032570939511060715, 0.9500634670257568, 0.9579892754554749, 0.8399713635444641, 0.8721868991851807, 0.10466242581605911, 0.8389242887496948, 0.07864915579557419, 0.07864915579557419, 0.9162837266921997, 0.8629168272018433, 0.12689952552318573, 0.9172441363334656, 0.8617027401924133, 0.9603941440582275, 0.05734345689415932, 0.20070208609104156, 0.7167931795120239, 0.9077879786491394, 0.9240384697914124, 0.9349392652511597, 0.5667711496353149, 0.34006267786026, 0.17194798588752747, 0.6877919435501099, 0.8388124704360962, 0.900516927242279, 0.9485174417495728, 0.9004542827606201, 0.12137411534786224, 0.8496187925338745, 0.8383292555809021, 0.15524615347385406, 0.9244715571403503, 0.9038156270980835, 0.9531692266464233, 0.9045129418373108, 0.9117520451545715, 0.9361026287078857, 0.9444175958633423, 0.8770571947097778, 0.9624475836753845, 0.889089822769165, 0.8637899160385132, 0.9776653051376343, 0.9180966019630432, 0.9307104349136353, 0.8699185252189636, 0.9599076509475708, 0.4226445257663727, 0.05763334408402443, 0.05763334408402443, 0.46106675267219543, 0.9447004199028015, 0.9329630136489868, 0.9071663618087769, 0.9320604205131531, 0.9559354186058044, 0.9075952172279358, 0.9036498665809631, 0.8768726587295532, 0.9315504431724548, 0.4288084805011749, 0.5360106229782104, 0.9404913187026978, 0.2848719358444214, 0.2848719358444214, 0.3798292577266693, 0.45817458629608154, 0.1811387985944748, 0.28769102692604065, 0.07458656281232834, 0.9852407574653625, 0.86188805103302, 0.9436627626419067, 0.9430959224700928, 0.5486143231391907, 0.42670005559921265, 0.9450744390487671, 0.8280730247497559, 0.5053693652153015, 0.23782086372375488, 0.11891043186187744, 0.11891043186187744, 0.9305695295333862, 0.9180175065994263, 0.9438996315002441, 0.9148780107498169, 0.9816733598709106, 0.8561220765113831, 0.9808909296989441, 0.8415632843971252, 0.8414230942726135, 0.8599029779434204, 0.50996333360672, 0.21385560929775238, 0.09870258718729019, 0.0658017247915268, 0.0822521522641182, 0.0164504311978817, 0.9088419675827026, 0.8765193819999695, 0.8299728631973267, 0.9183328151702881, 0.9737629890441895, 0.8985628485679626, 0.8175448179244995, 0.10219310224056244, 0.9684751033782959, 0.8492372632026672, 0.9684730768203735, 0.9186041951179504, 0.9761353135108948, 0.8999327421188354, 0.07199461758136749, 0.8216354846954346, 0.8747325539588928, 0.8917699456214905, 0.9305399060249329, 0.8859896063804626, 0.9717267751693726, 0.9023895859718323, 0.9240548610687256, 0.5667711496353149, 0.34006267786026, 0.48715266585350037, 0.4330246150493622, 0.05412807688117027, 0.9550225734710693, 0.9306831955909729, 0.15442810952663422, 0.23164217174053192, 0.2702491879463196, 0.25094568729400635, 0.07721405476331711, 0.019303513690829277, 0.8306352496147156, 0.8949697613716125, 0.8223747611045837, 0.2172984927892685, 0.724328339099884, 0.9046329855918884, 0.9681633114814758, 0.954395592212677, 0.48903343081474304, 0.016301114112138748, 0.48903343081474304, 0.9610252380371094, 0.9164863228797913, 0.857513964176178, 0.868004322052002, 0.14015085995197296, 0.6166638135910034, 0.16818103194236755, 0.08409051597118378, 0.6781142354011536, 0.3013840913772583, 0.872511088848114, 0.8371687531471252, 0.9357927441596985, 0.914890468120575, 0.9532445073127747, 0.9244243502616882, 0.4613783657550812, 0.0501498244702816, 0.4864532947540283, 0.4825716018676758, 0.4825716018676758, 0.7379679083824158, 0.06149732321500778, 0.09224598854780197, 0.12299464643001556, 0.7760764956474304, 0.030634598806500435, 0.15317299962043762, 0.030634598806500435, 0.8603283762931824, 0.9405555129051208, 0.9720715880393982, 0.8941344618797302, 0.8970123529434204, 0.9817163944244385, 0.5845869183540344, 0.25721824169158936, 0.14030085504055023, 0.8498218655586243, 0.9517357349395752, 0.9096187949180603, 0.9722002744674683, 0.029200967401266098, 0.7884261012077332, 0.2044067680835724, 0.32232075929641724, 0.6739434003829956, 0.9670075178146362, 0.8190877437591553, 0.011701253242790699, 0.08190877735614777, 0.08190877735614777, 0.8431863188743591, 0.9720579385757446, 0.07416395843029022, 0.7416395545005798, 0.1730492264032364, 0.9330012798309326, 0.294664204120636, 0.589328408241272, 0.10856049507856369, 0.9379807710647583, 0.8674538731575012, 0.9549745917320251, 0.9369242191314697, 0.32877805829048157, 0.6672260761260986, 0.9198353290557861, 0.9505347013473511, 0.34051090478897095, 0.4426642060279846, 0.13620436191558838, 0.06810218095779419, 0.7909784913063049, 0.15819570422172546, 0.883491039276123, 0.1351357400417328, 0.8783822655677795, 0.7550467848777771, 0.06662177294492722, 0.1776580661535263, 0.9278727173805237, 0.9681820869445801, 0.6618652939796448, 0.7975067496299744, 0.8054373860359192, 0.4882998466491699, 0.5086456537246704, 0.8881170153617859, 0.07955271005630493, 0.8750798106193542, 0.8152329325675964, 0.9836609363555908, 0.8708611130714417, 0.7984293699264526, 0.9691640138626099, 0.4207330644130707, 0.236662358045578, 0.34184563159942627, 0.9222075343132019, 0.6486082673072815, 0.9553769826889038, 0.8452094793319702, 0.9724488258361816, 0.9411458373069763, 0.964230477809906, 0.8212947249412537, 0.7461467981338501, 0.9567586183547974, 0.894379734992981, 0.94588303565979, 0.713214635848999, 0.8906697630882263, 0.3271666467189789, 0.6543332934379578, 0.704215407371521, 0.715093731880188, 0.9626806378364563, 0.7793939709663391, 0.1498834490776062, 0.08993007242679596, 0.4808627963066101, 0.2704853117465973, 0.24043139815330505, 0.3244214355945587, 0.6758779883384705, 0.9680750966072083, 0.9164434671401978, 0.9852719306945801, 0.6431297659873962, 0.2411736696958542, 0.9681611061096191, 0.935660183429718, 0.858050525188446, 0.9268172383308411, 0.8337262272834778, 0.93290776014328, 0.8152329325675964, 0.96598881483078, 0.17602352797985077, 0.7040941119194031, 0.9380093216896057, 0.8010059595108032, 0.8520724177360535, 0.22265170514583588, 0.779280960559845, 0.5254683494567871, 0.08757806569337845, 0.3503122627735138, 0.8851240277290344, 0.8420804738998413, 0.882292628288269, 0.37788572907447815, 0.629809558391571, 0.8094162344932556, 0.08993513882160187, 0.5227303504943848, 0.14256282150745392, 0.3088861107826233, 0.023760471493005753, 0.5163545608520508, 0.430295467376709, 0.9281495213508606, 0.9168883562088013, 0.11411640048027039, 0.8558729887008667, 0.7997462749481201, 0.15994925796985626, 0.11016949266195297, 0.6977401375770569, 0.18361583352088928, 0.8814510107040405, 0.33780917525291443, 0.5298967361450195, 0.12585048377513885, 0.921457827091217, 0.9323822855949402, 0.92142653465271, 0.8016050457954407, 0.10455717891454697, 0.10455717891454697, 0.9149234294891357, 0.9361026287078857, 0.8917227387428284, 0.963003933429718, 0.8927723169326782, 0.06867479532957077, 0.8753266334533691, 0.9502809643745422, 0.15626399219036102, 0.15626399219036102, 0.6250559687614441, 0.8653885722160339, 0.9333780407905579, 0.9557774066925049, 0.930194616317749, 0.43608465790748596, 0.5153727531433105, 0.9701783061027527, 0.8759210705757141, 0.40171435475349426, 0.10042858868837357, 0.10042858868837357, 0.40171435475349426, 0.9832414984703064, 0.4902114272117615, 0.4902114272117615, 0.9633123874664307, 0.8992775082588196, 0.9120801687240601, 0.19792024791240692, 0.5937607288360596, 0.1484401822090149, 0.945198655128479, 0.9323340058326721, 0.9625684022903442, 0.9400009512901306, 0.2459271103143692, 0.015370444394648075, 0.2151862233877182, 0.4611133337020874, 0.0461113341152668, 0.8662811517715454, 0.8692301511764526, 0.8548465371131897, 0.05456467345356941, 0.07275289297103882, 0.8869770169258118, 0.9262781739234924, 0.9777024984359741, 0.703184187412262, 0.2812736928462982, 0.2701801359653473, 0.12111523747444153, 0.400611937046051, 0.15838146209716797, 0.04658278450369835, 0.7736899256706238, 0.9821787476539612, 0.9383088946342468, 0.9304409623146057, 0.2999994158744812, 0.23999954760074615, 0.41999921202659607, 0.9312175512313843, 0.9411132335662842, 0.8291168808937073, 0.12412909418344498, 0.8689036965370178, 0.9257118105888367, 0.8675743341445923, 0.11830559372901917, 0.9738417863845825, 0.9470373392105103, 0.8352838754653931, 0.7206422090530396, 0.9848126769065857, 0.9402938485145569, 0.8346744179725647, 0.8544908165931702, 0.13856607675552368, 0.42019063234329224, 0.2401089370250702, 0.33014976978302, 0.8949530720710754, 0.8803861737251282, 0.8859235644340515, 0.8957642912864685, 0.9608619809150696, 0.9385053515434265, 0.9957041144371033, 0.6905457377433777, 0.12947732210159302, 0.15105688571929932, 0.9603333473205566, 0.39053574204444885, 0.5858036279678345, 0.06914613395929337, 0.16134096682071686, 0.39182808995246887, 0.2996332347393036, 0.06914613395929337, 0.9652636051177979, 0.9417314529418945, 0.9646955132484436, 0.8951249718666077, 0.879656970500946, 0.49579206109046936, 0.18266023695468903, 0.05218863859772682, 0.10437727719545364, 0.15656591951847076, 0.9772975444793701, 0.38353225588798523, 0.5880827903747559, 0.9577785730361938, 0.9310006499290466, 0.9007485508918762, 0.2646920680999756, 0.7303540110588074, 0.08336826413869858, 0.7225249409675598, 0.19452594220638275, 0.8948948979377747, 0.9108049869537354, 0.7134212851524353, 0.25479331612586975, 0.9540141820907593, 0.8788789510726929, 0.8054109215736389, 0.172588050365448, 0.9460287690162659, 0.8627287149429321], \"Term\": [\"...\", \"ability\", \"able\", \"access\", \"according\", \"actually\", \"actually\", \"affix\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"already\", \"already\", \"also\", \"also\", \"amazing\", \"among\", \"analysis\", \"analysis\", \"analysis\", \"analytics\", \"analyze\", \"analyzing\", \"application\", \"application\", \"approach\", \"approach\", \"approach\", \"around\", \"article\", \"article\", \"assignment\", \"band\", \"base\", \"based\", \"based\", \"based\", \"basic\", \"beetle\", \"best\", \"bird\", \"bird\", \"bot\", \"bot\", \"box\", \"break\", \"build\", \"building\", \"business\", \"business\", \"called\", \"called\", \"capital\", \"care\", \"case\", \"certain\", \"certificate\", \"cheat\", \"check\", \"city\", \"classification\", \"cloud\", \"co-reference\", \"code\", \"comment\", \"complex\", \"complicated\", \"computational\", \"computer\", \"computer\", \"computer\", \"computer\", \"computing\", \"concept\", \"consider\", \"consists\", \"context\", \"continue\", \"conversation\", \"corresponding\", \"could\", \"course\", \"course\", \"create\", \"customer\", \"customer\", \"customer\", \"data\", \"data\", \"data\", \"data\", \"deep\", \"demo\", \"dependency\", \"detail\", \"different\", \"different\", \"discipline\", \"discus\", \"document\", \"document\", \"document\", \"document\", \"domain\", \"done\", \"e.g\", \"england\", \"english\", \"entire\", \"entity\", \"error\", \"everything\", \"exactly\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"experience\", \"extremely\", \"face\", \"facebook\", \"fact\", \"feature\", \"field\", \"field\", \"figure\", \"finally\", \"find\", \"focus\", \"following\", \"form\", \"form\", \"founded\", \"free\", \"frequent\", \"future\", \"generate\", \"get\", \"give\", \"goal\", \"grain\", \"grain\", \"grammar\", \"grammar\", \"grammar\", \"great\", \"group\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"hand\", \"handle\", \"hear\", \"help\", \"help\", \"hidden\", \"http\", \"huge\", \"human\", \"human\", \"human\", \"idea\", \"important\", \"includes\", \"inference\", \"information\", \"information\", \"information\", \"information\", \"input\", \"input\", \"interaction\", \"interpret\", \"involves\", \"kingdom\", \"know\", \"knowledge\", \"language\", \"language\", \"language\", \"large\", \"large\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"learning\", \"lemma\", \"lemmatization\", \"let\", \"level\", \"lexicon\", \"library\", \"like\", \"like\", \"like\", \"line\", \"linguistics\", \"linkedin\", \"list\", \"london\", \"london\", \"london\", \"look\", \"look\", \"lot\", \"machine\", \"machine\", \"machine\", \"machine\", \"mark\", \"mean\", \"meaning\", \"meaning\", \"meaning\", \"medium\", \"model\", \"model\", \"model\", \"module\", \"must\", \"name\", \"named\", \"natural\", \"natural\", \"ner\", \"neural\", \"new\", \"new\", \"new\", \"new\", \"next\", \"next\", \"nice\", \"nlg\", \"nlg\", \"nlp\", \"nlp\", \"nlp\", \"note\", \"noun\", \"nuance\", \"numpy\", \"object\", \"one\", \"one\", \"organization\", \"output\", \"output\", \"owner\", \"parse\", \"parsed\", \"parser\", \"parsing\", \"part\", \"part\", \"part\", \"peck\", \"pecking\", \"perform\", \"performance\", \"phrase\", \"piece\", \"pipeline\", \"plan\", \"point\", \"pony\", \"populous\", \"post\", \"power\", \"practical\", \"present\", \"present\", \"previous\", \"primitive\", \"probably\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"processing\", \"processing\", \"project\", \"pronoun\", \"python\", \"question\", \"question\", \"raw\", \"read\", \"reading\", \"really\", \"recognize\", \"referring\", \"regulator\", \"relationship\", \"released\", \"released\", \"represent\", \"required\", \"requires\", \"resolution\", \"resolution\", \"result\", \"result\", \"result\", \"rewrite\", \"right\", \"role\", \"roman\", \"roman\", \"root\", \"root\", \"rule\", \"rule\", \"rule\", \"rule\", \"run\", \"run\", \"said\", \"scale\", \"science\", \"science\", \"search\", \"search\", \"see\", \"see\", \"see\", \"seen\", \"sentence\", \"sentence\", \"sentence\", \"separate\", \"sequence\", \"series\", \"set\", \"set\", \"set\", \"several\", \"sheet\", \"show\", \"simple\", \"since\", \"since\", \"single\", \"small\", \"software\", \"software\", \"software\", \"sometimes\", \"source\", \"spacy\", \"speak\", \"speech\", \"speech\", \"start\", \"statement\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"step\", \"still\", \"still\", \"stop\", \"strategy\", \"string\", \"structure\", \"structure\", \"structure\", \"study\", \"summarization\", \"symbol\", \"syntactic\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tag\", \"talking\", \"task\", \"task\", \"task\", \"tay\", \"team\", \"technique\", \"term\", \"term\", \"text\", \"text\", \"text\", \"text\", \"text\", \"textacy\", \"thing\", \"think\", \"thousand\", \"time\", \"time\", \"time\", \"together\", \"token\", \"top\", \"topic\", \"topic\", \"traditional\", \"translation\", \"translation\", \"tree\", \"try\", \"trying\", \"twitter\", \"two\", \"type\", \"typical\", \"understand\", \"understand\", \"understanding\", \"understanding\", \"understanding\", \"unique\", \"unit\", \"united\", \"unstructured\", \"unsupervised\", \"us\", \"use\", \"used\", \"used\", \"used\", \"useful\", \"user\", \"user\", \"using\", \"using\", \"using\", \"using\", \"using\", \"value\", \"var\", \"verb\", \"version\", \"volume\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"want\", \"way\", \"way\", \"website\", \"whole\", \"wikipedia\", \"word\", \"word\", \"work\", \"work\", \"work\", \"working\", \"workshop\", \"world\", \"world\", \"would\", \"write\", \"written\", \"written\", \"year\", \"yet\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 8, 1, 2, 6, 5, 4, 7]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1518425091471922005158974038\", ldavis_el1518425091471922005158974038_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1518425091471922005158974038\", ldavis_el1518425091471922005158974038_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1518425091471922005158974038\", ldavis_el1518425091471922005158974038_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2      0.252713  0.020698       1        1  27.797785\n",
       "7      0.027155  0.276709       2        1  15.534157\n",
       "0      0.016873 -0.076166       3        1  15.274380\n",
       "1      0.033994 -0.144577       4        1  12.373361\n",
       "5      0.099975 -0.071983       5        1  11.352110\n",
       "4     -0.163874 -0.010521       6        1   7.176317\n",
       "3     -0.165626  0.007469       7        1   5.305256\n",
       "6     -0.101210 -0.001629       8        1   5.186627, topic_info=     Category        Freq      Term       Total  loglift  logprob\n",
       "363   Default  204.000000      word  204.000000  30.0000  30.0000\n",
       "11    Default  199.000000  language  199.000000  29.0000  29.0000\n",
       "14    Default  103.000000   natural  103.000000  28.0000  28.0000\n",
       "15    Default  180.000000       nlp  180.000000  27.0000  27.0000\n",
       "80    Default  150.000000  sentence  150.000000  26.0000  26.0000\n",
       "...       ...         ...       ...         ...      ...      ...\n",
       "89     Topic8    6.208579        wa   38.322517   1.1390  -4.7246\n",
       "2840   Topic8    3.429162      bird    8.821903   2.0142  -5.3182\n",
       "2841   Topic8    3.429162     grain    8.821903   2.0142  -5.3182\n",
       "441    Topic8    4.839072      text  107.335793  -0.1402  -4.9738\n",
       "346    Topic8    3.453029  question   12.439169   1.6775  -5.3113\n",
       "\n",
       "[390 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "1971      7  0.930963        ...\n",
       "1532      7  0.807077    ability\n",
       "239       4  0.923248       able\n",
       "2401      5  0.923385     access\n",
       "626       8  0.893349  according\n",
       "...     ...       ...        ...\n",
       "158       6  0.878879      write\n",
       "129       3  0.805411    written\n",
       "129       6  0.172588    written\n",
       "92        1  0.946029       year\n",
       "541       7  0.862729        yet\n",
       "\n",
       "[480 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 8, 1, 2, 6, 5, 4, 7])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pyLDAvis\n",
    "import os\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, mycorpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=mycorpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=mycorpus, texts=final_text, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.4074\n",
      "Num Topics = 8  has Coherence Value of 0.4262\n",
      "Num Topics = 14  has Coherence Value of 0.4099\n",
      "Num Topics = 20  has Coherence Value of 0.4364\n",
      "Num Topics = 26  has Coherence Value of 0.4064\n",
      "Num Topics = 32  has Coherence Value of 0.4125\n",
      "Num Topics = 38  has Coherence Value of 0.4159\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.014*\"word\" + 0.011*\"sentence\" + 0.009*\"data\" + 0.008*\"term\" + 0.007*\"wa\" '\n",
      "  '+ 0.006*\"example\" + 0.006*\"language\" + 0.006*\"understanding\" + 0.005*\"like\" '\n",
      "  '+ 0.005*\"poetry\"'),\n",
      " (1,\n",
      "  '0.027*\"language\" + 0.014*\"natural\" + 0.013*\"learning\" + 0.012*\"nlp\" + '\n",
      "  '0.011*\"machine\" + 0.010*\"word\" + 0.009*\"use\" + 0.008*\"model\" + '\n",
      "  '0.008*\"processing\" + 0.007*\"deep\"'),\n",
      " (2,\n",
      "  '0.015*\"data\" + 0.012*\"system\" + 0.010*\"language\" + 0.010*\"computational\" + '\n",
      "  '0.009*\"linguistics\" + 0.009*\"natural\" + 0.008*\"wa\" + 0.008*\"processing\" + '\n",
      "  '0.008*\"input\" + 0.008*\"model\"'),\n",
      " (3,\n",
      "  '0.012*\"language\" + 0.011*\"text\" + 0.010*\"algorithm\" + 0.009*\"data\" + '\n",
      "  '0.009*\"input\" + 0.009*\"natural\" + 0.007*\"different\" + 0.006*\"nlp\" + '\n",
      "  '0.006*\"co-reference\" + 0.006*\"play\"'),\n",
      " (4,\n",
      "  '0.015*\"word\" + 0.012*\"published\" + 0.010*\"ha\" + 0.009*\"first\" + '\n",
      "  '0.008*\"like\" + 0.007*\"system\" + 0.007*\"...\" + 0.006*\"rule\" + '\n",
      "  '0.005*\"company\" + 0.005*\"road\"'),\n",
      " (5,\n",
      "  '0.022*\"word\" + 0.020*\"language\" + 0.013*\"natural\" + 0.011*\"ha\" + '\n",
      "  '0.010*\"computer\" + 0.008*\"processing\" + 0.007*\"form\" + 0.007*\"rule\" + '\n",
      "  '0.006*\"linguistics\" + 0.006*\"speech\"'),\n",
      " (6,\n",
      "  '0.041*\"language\" + 0.025*\"natural\" + 0.016*\"processing\" + 0.015*\"system\" + '\n",
      "  '0.012*\"human\" + 0.010*\"rule\" + 0.009*\"nlp\" + 0.009*\"word\" + 0.009*\"machine\" '\n",
      "  '+ 0.008*\"statistical\"'),\n",
      " (7,\n",
      "  '0.008*\"sentence\" + 0.008*\"workshop\" + 0.007*\"nlp\" + 0.007*\"need\" + '\n",
      "  '0.007*\"text\" + 0.007*\"understand\" + 0.007*\"tree\" + 0.007*\"start\" + '\n",
      "  '0.005*\"break\" + 0.005*\"algorithm\"'),\n",
      " (8,\n",
      "  '0.026*\"language\" + 0.019*\"nlp\" + 0.017*\"learning\" + 0.017*\"natural\" + '\n",
      "  '0.013*\"processing\" + 0.010*\"approach\" + 0.010*\"machine\" + 0.009*\"task\" + '\n",
      "  '0.008*\"deep\" + 0.007*\"intelligence\"'),\n",
      " (9,\n",
      "  '0.016*\"data\" + 0.011*\"learning\" + 0.011*\"nlp\" + 0.011*\"language\" + '\n",
      "  '0.010*\"algorithm\" + 0.009*\"level\" + 0.009*\"system\" + 0.009*\"model\" + '\n",
      "  '0.008*\"sheet\" + 0.008*\"cheat\"'),\n",
      " (10,\n",
      "  '0.017*\"nlp\" + 0.010*\"word\" + 0.010*\"use\" + 0.009*\"simple\" + 0.009*\"need\" + '\n",
      "  '0.008*\"name\" + 0.006*\"database\" + 0.006*\"processing\" + 0.006*\"application\" '\n",
      "  '+ 0.006*\"example\"'),\n",
      " (11,\n",
      "  '0.021*\"wa\" + 0.020*\"translation\" + 0.017*\"machine\" + 0.013*\"part\" + '\n",
      "  '0.011*\"nlp\" + 0.011*\"word\" + 0.010*\"statistical\" + 0.009*\"research\" + '\n",
      "  '0.008*\"text\" + 0.007*\"would\"'),\n",
      " (12,\n",
      "  '0.032*\"word\" + 0.020*\"sentence\" + 0.011*\"text\" + 0.010*\"data\" + '\n",
      "  '0.010*\"information\" + 0.010*\"new\" + 0.009*\"topic\" + 0.008*\"wa\" + '\n",
      "  '0.007*\"document\" + 0.006*\"example\"'),\n",
      " (13,\n",
      "  '0.009*\"help\" + 0.009*\"machine\" + 0.008*\"text\" + 0.008*\"language\" + '\n",
      "  '0.007*\"rating\" + 0.007*\"metric\" + 0.007*\"result\" + 0.006*\"learning\" + '\n",
      "  '0.006*\"word\" + 0.006*\"nlp\"'),\n",
      " (14,\n",
      "  '0.024*\"language\" + 0.016*\"nlp\" + 0.015*\"learning\" + 0.013*\"machine\" + '\n",
      "  '0.013*\"natural\" + 0.012*\"processing\" + 0.011*\"system\" + 0.009*\"sentence\" + '\n",
      "  '0.008*\"model\" + 0.007*\"result\"'),\n",
      " (15,\n",
      "  '0.015*\"nlp\" + 0.015*\"word\" + 0.014*\"language\" + 0.011*\"human\" + '\n",
      "  '0.010*\"system\" + 0.009*\"data\" + 0.009*\"many\" + 0.008*\"example\" + '\n",
      "  '0.007*\"use\" + 0.007*\"machine\"'),\n",
      " (16,\n",
      "  '0.019*\"word\" + 0.019*\"data\" + 0.018*\"text\" + 0.016*\"language\" + 0.012*\"nlp\" '\n",
      "  '+ 0.012*\"natural\" + 0.012*\"like\" + 0.011*\"processing\" + 0.008*\"learning\" + '\n",
      "  '0.006*\"approach\"'),\n",
      " (17,\n",
      "  '0.021*\"word\" + 0.013*\"algorithm\" + 0.012*\"nlg\" + 0.011*\"system\" + '\n",
      "  '0.010*\"learning\" + 0.008*\"text\" + 0.007*\"pony\" + 0.007*\"example\" + '\n",
      "  '0.007*\"machine\" + 0.007*\"one\"'),\n",
      " (18,\n",
      "  '0.023*\"learning\" + 0.021*\"language\" + 0.016*\"sentence\" + 0.013*\"data\" + '\n",
      "  '0.010*\"task\" + 0.010*\"machine\" + 0.009*\"london\" + 0.009*\"nlp\" + '\n",
      "  '0.009*\"computer\" + 0.008*\"word\"'),\n",
      " (19,\n",
      "  '0.014*\"data\" + 0.013*\"system\" + 0.011*\"nlp\" + 0.009*\"sentence\" + '\n",
      "  '0.009*\"language\" + 0.008*\"like\" + 0.008*\"word\" + 0.007*\"algorithm\" + '\n",
      "  '0.007*\"http\" + 0.006*\"topic\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>language, natural, processing, system, human, ...</td>\n",
       "      <td>[natural, language, processing, nlp, subfield,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9367</td>\n",
       "      <td>language, natural, processing, system, human, ...</td>\n",
       "      <td>[challenge, natural, language, processing, fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>language, nlp, learning, natural, processing, ...</td>\n",
       "      <td>[history, natural, language, processing, nlp, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>wa, translation, machine, part, nlp, word, sta...</td>\n",
       "      <td>[georgetown, experiment, involved, fully, auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>language, natural, processing, system, human, ...</td>\n",
       "      <td>[notably, successful, natural, language, proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>nlp, word, language, human, system, data, many...</td>\n",
       "      <td>[many, programmer, began, write, conceptual, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5169</td>\n",
       "      <td>language, natural, processing, system, human, ...</td>\n",
       "      <td>[natural, language, processing, system, based,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>language, nlp, learning, machine, natural, pro...</td>\n",
       "      <td>[many, notable, early, success, occurred, fiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>data, learning, nlp, language, algorithm, leve...</td>\n",
       "      <td>[recent, research, ha, increasingly, focused, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>language, natural, learning, nlp, machine, wor...</td>\n",
       "      <td>[representation, learning, deep, neural, netwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             6.0              0.9672   \n",
       "1            1             6.0              0.9367   \n",
       "2            2             8.0              0.9672   \n",
       "3            3            11.0              0.9827   \n",
       "4            4             6.0              0.9824   \n",
       "5            5            15.0              0.9736   \n",
       "6            6             6.0              0.5169   \n",
       "7            7            14.0              0.9866   \n",
       "8            8             9.0              0.9852   \n",
       "9            9             1.0              0.8820   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  language, natural, processing, system, human, ...   \n",
       "1  language, natural, processing, system, human, ...   \n",
       "2  language, nlp, learning, natural, processing, ...   \n",
       "3  wa, translation, machine, part, nlp, word, sta...   \n",
       "4  language, natural, processing, system, human, ...   \n",
       "5  nlp, word, language, human, system, data, many...   \n",
       "6  language, natural, processing, system, human, ...   \n",
       "7  language, nlp, learning, machine, natural, pro...   \n",
       "8  data, learning, nlp, language, algorithm, leve...   \n",
       "9  language, natural, learning, nlp, machine, wor...   \n",
       "\n",
       "                                                Text  \n",
       "0  [natural, language, processing, nlp, subfield,...  \n",
       "1  [challenge, natural, language, processing, fre...  \n",
       "2  [history, natural, language, processing, nlp, ...  \n",
       "3  [georgetown, experiment, involved, fully, auto...  \n",
       "4  [notably, successful, natural, language, proce...  \n",
       "5  [many, programmer, began, write, conceptual, o...  \n",
       "6  [natural, language, processing, system, based,...  \n",
       "7  [many, notable, early, success, occurred, fiel...  \n",
       "8  [recent, research, ha, increasingly, focused, ...  \n",
       "9  [representation, learning, deep, neural, netwo...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=mycorpus, texts=text):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=mycorpus, texts=final_text)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>word, sentence, data, term, wa, example, language, understanding, like, poetry</td>\n",
       "      <td>[ross, goodwin, former, ghostwriter, obama, administration, creative, technologist, ha, often, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>language, natural, learning, nlp, machine, word, use, model, processing, deep</td>\n",
       "      <td>[nlu, post-processing, text, use, nlp, algorithm, identifying, parts-of-speech, etc, utilizes, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>data, system, language, computational, linguistics, natural, wa, processing, input, model</td>\n",
       "      <td>[emulating, jack, kerouac, novel, road, ross, goodwin, traveled, new, york, new, orleans, march,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>language, text, algorithm, data, input, natural, different, nlp, co-reference, play</td>\n",
       "      <td>[royal, bank, scotland, us, text, analytics, nlp, technique, extract, important, trend, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>word, published, ha, first, like, system, ..., rule, company, road</td>\n",
       "      <td>[company, like, winterlight, lab, making, huge, improvement, treatment, alzheimer, disease, moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>word, language, natural, ha, computer, processing, form, rule, linguistics, speech</td>\n",
       "      <td>[program, student, written, daniel, bobrow, phd, dissertation, mit, one, earliest, known, attemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>language, natural, processing, system, human, rule, nlp, word, machine, statistical</td>\n",
       "      <td>[many, different, class, machine-learning, algorithm, applied, natural-language-processing, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>sentence, workshop, nlp, need, text, understand, tree, start, break, algorithm</td>\n",
       "      <td>[nlp, particularly, booming, healthcare, industry, technology, improving, care, delivery, diseas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>language, nlp, learning, natural, processing, approach, machine, task, deep, intelligence</td>\n",
       "      <td>[supervised, unsupervised, learning, specifically, deep, learning, widely, used, modeling, human...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>data, learning, nlp, language, algorithm, level, system, model, sheet, cheat</td>\n",
       "      <td>[recent, research, ha, increasingly, focused, unsupervised, semi-supervised, learning, algorithm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.9884   \n",
       "1        1.0              0.9905   \n",
       "2        2.0              0.9847   \n",
       "3        3.0              0.9750   \n",
       "4        4.0              0.9762   \n",
       "5        5.0              0.9793   \n",
       "6        6.0              0.9860   \n",
       "7        7.0              0.9762   \n",
       "8        8.0              0.9774   \n",
       "9        9.0              0.9852   \n",
       "\n",
       "                                                                                    Keywords  \\\n",
       "0             word, sentence, data, term, wa, example, language, understanding, like, poetry   \n",
       "1              language, natural, learning, nlp, machine, word, use, model, processing, deep   \n",
       "2  data, system, language, computational, linguistics, natural, wa, processing, input, model   \n",
       "3        language, text, algorithm, data, input, natural, different, nlp, co-reference, play   \n",
       "4                         word, published, ha, first, like, system, ..., rule, company, road   \n",
       "5         word, language, natural, ha, computer, processing, form, rule, linguistics, speech   \n",
       "6        language, natural, processing, system, human, rule, nlp, word, machine, statistical   \n",
       "7             sentence, workshop, nlp, need, text, understand, tree, start, break, algorithm   \n",
       "8  language, nlp, learning, natural, processing, approach, machine, task, deep, intelligence   \n",
       "9               data, learning, nlp, language, algorithm, level, system, model, sheet, cheat   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0  [ross, goodwin, former, ghostwriter, obama, administration, creative, technologist, ha, often, u...  \n",
       "1  [nlu, post-processing, text, use, nlp, algorithm, identifying, parts-of-speech, etc, utilizes, c...  \n",
       "2  [emulating, jack, kerouac, novel, road, ross, goodwin, traveled, new, york, new, orleans, march,...  \n",
       "3  [royal, bank, scotland, us, text, analytics, nlp, technique, extract, important, trend, customer...  \n",
       "4  [company, like, winterlight, lab, making, huge, improvement, treatment, alzheimer, disease, moni...  \n",
       "5  [program, student, written, daniel, bobrow, phd, dissertation, mit, one, earliest, known, attemp...  \n",
       "6  [many, different, class, machine-learning, algorithm, applied, natural-language-processing, task...  \n",
       "7  [nlp, particularly, booming, healthcare, industry, technology, improving, care, delivery, diseas...  \n",
       "8  [supervised, unsupervised, learning, specifically, deep, learning, widely, used, modeling, human...  \n",
       "9  [recent, research, ha, increasingly, focused, unsupervised, semi-supervised, learning, algorithm...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from wordcloud) (1.17.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\acer\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from wordcloud) (6.1.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=custom,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
