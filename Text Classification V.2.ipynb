{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from string import punctuation\n",
    "custom = stop_words+list(punctuation)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Consumer_Complaints.csv\",encoding = 'ISO-8859-1')\n",
    "df.head()\n",
    "df = df.drop(['Unnamed: 18'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:\n",
      " (1025010, 18) \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025010 entries, 0 to 1025009\n",
      "Data columns (total 18 columns):\n",
      "Date received                   1025010 non-null object\n",
      "Product                         1025010 non-null object\n",
      "Sub-product                     789840 non-null object\n",
      "Issue                           1025010 non-null object\n",
      "Sub-issue                       528853 non-null object\n",
      "Consumer Complaint              277814 non-null object\n",
      "Company Public Response         318364 non-null object\n",
      "Company                         1025010 non-null object\n",
      "State                           1012650 non-null object\n",
      "ZIP code                        1008292 non-null object\n",
      "Tags                            141588 non-null object\n",
      "Consumer consent provided?      491911 non-null object\n",
      "Submitted via                   1025010 non-null object\n",
      "Date Sent to Company            1025010 non-null object\n",
      "Company Response to Consumer    1025007 non-null object\n",
      "Timely response?                1025010 non-null object\n",
      "Consumer disputed?              768554 non-null object\n",
      "Complaint ID                    1025010 non-null int64\n",
      "dtypes: int64(1), object(17)\n",
      "memory usage: 140.8+ MB\n",
      "Info:\n",
      " None \n",
      " \n",
      "\n",
      "Class counts:\n",
      "\n",
      " Mortgage                                                                        254165\n",
      "Debt collection                                                                 196212\n",
      "Credit reporting                                                                140433\n",
      "Credit reporting, credit repair services, or other personal consumer reports    110756\n",
      "Credit card                                                                      89191\n",
      "Bank account or service                                                          86206\n",
      "Student loan                                                                     42969\n",
      "Consumer Loan                                                                    31606\n",
      "Credit card or prepaid card                                                      22913\n",
      "Checking or savings account                                                      18982\n",
      "Money transfer, virtual currency, or money service                                5785\n",
      "Vehicle loan or lease                                                             5628\n",
      "Payday loan                                                                       5546\n",
      "Money transfers                                                                   5354\n",
      "Payday loan, title loan, or personal loan                                         4367\n",
      "Prepaid card                                                                      3819\n",
      "Other financial service                                                           1060\n",
      "Virtual currency                                                                    18\n",
      "Name: Product, dtype: int64 \n",
      "\n",
      "\n",
      "Null Values\n",
      "\n",
      " Date received                        0\n",
      "Product                              0\n",
      "Sub-product                     235170\n",
      "Issue                                0\n",
      "Sub-issue                       496157\n",
      "Consumer Complaint              747196\n",
      "Company Public Response         706646\n",
      "Company                              0\n",
      "State                            12360\n",
      "ZIP code                         16718\n",
      "Tags                            883422\n",
      "Consumer consent provided?      533099\n",
      "Submitted via                        0\n",
      "Date Sent to Company                 0\n",
      "Company Response to Consumer         3\n",
      "Timely response?                     0\n",
      "Consumer disputed?              256456\n",
      "Complaint ID                         0\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Columns:\n",
      " Index(['Date received', 'Product', 'Sub-product', 'Issue', 'Sub-issue',\n",
      "       'Consumer Complaint', 'Company Public Response', 'Company', 'State',\n",
      "       'ZIP code', 'Tags', 'Consumer consent provided?', 'Submitted via',\n",
      "       'Date Sent to Company', 'Company Response to Consumer',\n",
      "       'Timely response?', 'Consumer disputed?', 'Complaint ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Information\n",
    "\n",
    "print('Dataframe shape:\\n',df.shape,'\\n\\n')\n",
    "print('Info:\\n',df.info(),'\\n','\\n')\n",
    "print('Class counts:\\n\\n',df['Product'].value_counts(),'\\n\\n')\n",
    "print('Null Values\\n\\n',df.isnull().sum(),'\\n\\n')\n",
    "print('Columns:\\n',df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer function\n",
    "\n",
    "def my_tokenizer(s):\n",
    "    try:\n",
    "        s = s.lower() # downcase\n",
    "    except:\n",
    "        s = str(s).lower()\n",
    "    tokens = nltk.word_tokenize(s) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # remove short words, they're probably not useful\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [t for t in tokens if t not in custom] # remove stopwords\n",
    "    tokens = [t for t in tokens if not any(c.isdigit() for c in t)] # remove any digits, i.e. \"3rd edition\"\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(df1, column_1, column_2):    #column_1 - reviews/msgs/complaints, column_2 - class/sentiments/Products\n",
    "    \n",
    "    # Remove Null values\n",
    "    df1.dropna(inplace = True)\n",
    "    df1 = df1[[column_1, column_2]]\n",
    "    \n",
    "    # Convert to list and tokenize\n",
    "    text = df1[column_1].tolist()\n",
    "    cleaned_text = []\n",
    "    for x in text:\n",
    "        cleaned_text.append(my_tokenizer(x))\n",
    "    joined_text = []\n",
    "    for x in cleaned_text:\n",
    "        joined_text.append(' '.join(x))\n",
    "        \n",
    "    #Create New Dataframe    \n",
    "    df2 = pd.DataFrame({column_1:joined_text}) #mention column_1\n",
    "    df2[column_2] = pd.Series(df1[column_2].tolist())\n",
    "    df2[column_2] = df2[column_2].str.lower() # mention column_2\n",
    "    \n",
    "    #check if the dataframe is proper\n",
    "    print(df2.head())\n",
    "    \n",
    "    \n",
    "    # Information\n",
    "\n",
    "    print('Dataframe shape:\\n',df2.shape,'\\n\\n')\n",
    "    print('Info:\\n',df2.info(),'\\n','\\n')\n",
    "    print('Class counts:\\n\\n',df2['Product'].value_counts(),'\\n\\n')\n",
    "    print('Null Values\\n\\n',df2.isnull().sum(),'\\n\\n')\n",
    "    print('Columns:\\n',df2.columns,'\\n\\n')\n",
    "    \n",
    "    # TF-IDF\n",
    "    tfidf = TfidfVectorizer()\n",
    "    vector = tfidf.fit_transform(df2[column_1])\n",
    "    vector_values_array = vector.toarray()\n",
    "    X = vector_values_array\n",
    "    \n",
    "    \n",
    "    # Label Encoding\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df2[column_2])\n",
    "    \n",
    "    #Train & Test split\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Consumer Complaint          Product\n",
      "0  wa called cell phone first national debt inc. ...  debt collection\n",
      "1  sent cease desist letter medical debt collecti...  debt collection\n",
      "2  phoenix financial service llc continues report...  debt collection\n",
      "3  broke rib fishing trip xxxx xxxx wa taken loca...  debt collection\n",
      "4  name xxxx xxxx xxxx company reported acct xxxx...  debt collection\n",
      "Dataframe shape:\n",
      " (3105, 2) \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3105 entries, 0 to 3104\n",
      "Data columns (total 2 columns):\n",
      "Consumer Complaint    3105 non-null object\n",
      "Product               3105 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 48.6+ KB\n",
      "Info:\n",
      " None \n",
      " \n",
      "\n",
      "Class counts:\n",
      "\n",
      " debt collection    2969\n",
      "student loan        136\n",
      "Name: Product, dtype: int64 \n",
      "\n",
      "\n",
      "Null Values\n",
      "\n",
      " Consumer Complaint    0\n",
      "Product               0\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Columns:\n",
      " Index(['Consumer Complaint', 'Product'], dtype='object') \n",
      "\n",
      "\n",
      "X_train: (2484, 8723)\n",
      "y_train: (2484,)\n",
      "X_test: (621, 8723)\n",
      "y_test: (621,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = Preprocessing(df,'Consumer Complaint','Product')\n",
    "\n",
    "print('X_train:',X_train.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "print('X_test:',X_test.shape)\n",
    "print('y_test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# LogisticRegression\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train,y_train)\n",
    "logitc_acc = logit.score(X_test,y_test)\n",
    "logit_d = pd.DataFrame(report).transpose().iloc[0:2,0:3]\n",
    "\n",
    "# MultinomialNB\n",
    "mul = MultinomialNB()\n",
    "mul.fit(X_train, y_train)\n",
    "mul_acc = mul.score(X_test,y_test)\n",
    "mul_d = pd.DataFrame(report).transpose().iloc[0:2,0:3]\n",
    "\n",
    "# SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc_acc = svc.score(X_test,y_test)\n",
    "svc_d = pd.DataFrame(report).transpose().iloc[0:2,0:3]\n",
    "\n",
    "# RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_acc = rfc.score(X_test,y_test)\n",
    "rfc_d = pd.DataFrame(report).transpose().iloc[0:2,0:3]\n",
    "\n",
    "\n",
    "# xgboost\n",
    "xg = xgboost.XGBClassifier()\n",
    "xg.fit(X_train,y_train)\n",
    "xg_acc = xg.score(X_train,y_train)\n",
    "xg_d = pd.DataFrame(report).transpose().iloc[0:2,0:3]\n",
    "\n",
    "\n",
    "#AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train,y_train)\n",
    "ada_acc = ada.score(X_test,y_test)\n",
    "ada_d = pd.DataFrame(report).transpose().iloc[0:2,0:3]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data = pd.concat([logit_d,mul_d,svc_d,rfc_d,xg_d,ada_d])\n",
    "Model_data['Models'] = ['LogisticRegression','LogisticRegression','MultinomialNB','MultinomialNB','SVC','SVC','RandomForestClassifier'\n",
    "                        ,'RandomForestClassifier','xgboost','xgboost','AdaBoostClassifier','AdaBoostClassifier']\n",
    "Model_data['accuracy'] = [logitc_acc,logitc_acc,mul_acc,mul_acc,svc_acc,svc_acc,rfc_acc,rfc_acc,xg_acc,xg_acc,ada_acc,ada_acc]\n",
    "Model_data = Model_data[['Models','accuracy','precision','recall','f1-score']]\n",
    "Model_data.index.name = 'Product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
